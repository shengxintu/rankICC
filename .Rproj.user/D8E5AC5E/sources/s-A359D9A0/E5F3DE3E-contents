---
title: "Rank-based Intraclass Correlation Coefficient"
author: "Shengxin Tu"
date: "`r Sys.Date()`"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_float: 
      collapsed: true
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = T,
                      echo = TRUE,
                      warning = F,
                      message = F)
library(rms)
library(dplyr)
library(lme4)
library(parallel)
library(kableExtra)
library(latex2exp)
library(tidyr)
library(RColorBrewer)
library(coxed)
```

In the presence of clustering, observations in the same cluster are often more similar than those from other clusters. The degree of similarity between observations in the same cluster can be evaluated by the intraclass correlation coefficient (ICC). 

# Intraclass correlation coefficient  

## Early ICC definition 

The first intraclass correlation statistics were proposed by Ronald Fisher for unordered pairs. Consider a data set consisting of $n$ unordered pairs $(x_{k,1},x_{k,2})$, for $k=1,2,...,n$. The intraclass correlation is  

$$r = \frac{1}{ns^2}\sum_{k=1}^n(x_{k,1}-\bar x)(x_{k,2}-\bar x)$$
where 

- $\bar x = \frac{1}{2n}\sum_{k=1}^n(x_{k,1}+x_{k,2})$
- $s^2 = \frac{1}{2n}\{\sum_{k=1}^n(x_{k,1}-\bar x)^2+\sum_{k=1}^n(x_{k,2}-\bar x)^2\}$

Later versions used $2n-1$ in the denominator for calculating $s^2$ and $n-1$ in the denominator for calculating $r$, so that $s^2$ becomes unbiased, and $r$ becomes unbiased if $s$ is known. 

For data with groups having more than 2 values, it is defined as
$$r = \frac{1}{3ns^2}\sum_{k=1}^n\{(x_{k,1}-\bar x)(x_{k,2}-\bar x)+(x_{k,1}-\bar x)(x_{k,3}-\bar x)+(x_{k,2}-\bar x)(x_{k,3}-\bar x)\}$$
where 

- $\bar x = \frac{1}{3n}\sum_{k=1}^n(x_{k,1}+x_{k,2}+x_{k,3})$
- $s^2 = \frac{1}{3n}\{\sum_{k=1}^n(x_{k,1}-\bar x)^2+\sum_{k=1}^n(x_{k,2}-\bar x)^2+\sum_{k=1}^n(x_{k,3}-\bar x)^2\}$

As the cluster size $K$ grows, there is an equivalent form to simply calculate ICC (Harris, 1913),

$$r = \frac{K}{K-1}\frac{n^{-1}\sum_{i=1}^n(\bar x_i-\bar x)^2}{s^2}-\frac{1}{K-1}$$

The left term is non-negative; consequently the intraclass correlation must satisfy $r \geq -\frac{1}{K-1}$. This ICC is nearly equal to $\frac{n^{-1}\sum_{i=1}^n(\bar x_i-\bar x)^2}{s^2}$ for large $K$, which can be interpreted as the fraction of the total variance that is due to variation between groups. 

## Modern ICC definitions

ICC has been discussed within the framework of ANOVA, and more recently within the framework of random effects models. With a one-way random effects ANOVA model $Y_{ij} = \mu + a_i + e_{ij}$, the population ICC is defined as 

$$\rho_I = \frac{\text{population variance between clusters}}{\text{total variance}} = \frac{\text{variance of the cluster effect}}{\text{sum of variances of the cluster effect and the residual}}$$

This ANOVA framework has the advantage of allowing unequal cluster sizes, which is difficult to handle with the early ICC statistics. The expression of ICC can never be negative (unlike Fisher's original formula) and therefore, it would have a positive bias for independent data. 

A variety of ICC statistics have been proposed, not all of which estimate the same population parameter.There has been substantial dispute regarding whether ICC statistics are appropriate for a given usage, because they can generate drastically different answers for the same data.

However, ICC is very sensitive to scale of interest. Because the between-cluster variance and total variance differ by scales. We need rank-based ICC which is robust to different scales. Also, rank-based ICC preferable when working with ordered categorical data and skewed distributions.

### Comparison of Fisher's ICC and the ratio of variances

Suppose $X$ is a random variable drawn from a two-level hierarchical distribution. Let $\mu_i$ be the cluster mean of the $i$th cluster, $\sigma^2_b$ denote the between-cluster variance (specifically, the variance of cluster means), and $\sigma^2_w$ denote the within-cluster variance (particularly, the expectation of the variance of within-cluster residuals. Note $var(X_{ij}) = var[E(X_{ij}|\mu_i)] + E[var(X_{ij}|\mu_i)] = \sigma^2_b + \sigma^2_w$. 

$$\begin{align*}
\rho_I & = corr(X_{ij},X_{ij'}) \\
& = \frac{cov(X_{ij},X_{ij'})}{\sqrt{var(X_{ij})var(X_{ij'})}}\\
& = \frac{cov(X_{ij},X_{ij'})}{\sigma^2_b + \sigma^2_w}\\
cov(X_{ij},X_{ij'}) & = E[cov(X_{ij},X_{ij'}|\mu_i)] + cov[E(X_{ij}|\mu_i), E(X_{ij'}|\mu_i)]\\
& = E[cov(X_{ij},X_{ij'}|\mu_i)] + var(\mu_i)\\
& =  E[cov(X_{ij},X_{ij'}|\mu_i)] + \sigma^2_b\\
\Rightarrow \rho_I & = \frac{E[cov(X_{ij},X_{ij'}|\mu_i)] + \sigma^2_b}{\sigma^2_b + \sigma^2_w}
\end{align*}$$



With observations, let $\hat \rho_I = \frac{ \frac{1}{n} \sum_i \frac{1}{k_i(k-1)} \sum_{j \neq j'} (X_{ij}-\bar X)(X_{ij'} - \bar X)}{\frac{1}{n} \sum_i \frac{1}{k_i} \sum_j(X_{ij}-\bar X)^2}$, and $\hat \rho^*_I = \frac{ \frac{1}{n} \sum_i(\bar X_{i} - \bar X)^2}{\frac{1}{n} \sum_i \frac{1}{k_i} \sum_j(X_{ij}-\bar X)^2}$.



$$
\begin{align*}
\frac{1}{n} \sum_i(\bar X_{i} - \bar X)^2 & = \frac{1}{n} \sum_i \frac{1}{k_i^2} \sum_j\sum_{j'}(X_{ij}-\bar X)(X_{ij'} - \bar X)\\
& = \frac{1}{n} \sum_i \frac{1}{k_i^2} \sum_{j \neq j'} (X_{ij}-\bar X)(X_{ij'} - \bar X) +  \frac{1}{n} \sum_i \frac{1}{k_i^2} \sum_j (X_{ij}-\bar X)^2 
\end{align*}
$$


$$
\begin{align*}
\hat \rho^*_I & = \frac{ \frac{1}{n} \sum_i \frac{1}{k_i^2} \sum_{j \neq j'} (X_{ij}-\bar X)(X_{ij'} - \bar X)}{\frac{1}{n} \sum_i \frac{1}{k_i} \sum_j(X_{ij}-\bar X)^2} + \frac{ \frac{1}{n} \sum_i \frac{1}{k_i^2} \sum_j (X_{ij}-\bar X)^2 }{ \frac{1}{n} \sum_i \frac{1}{k_i} \sum_j (X_{ij}-\bar X)^2 } \\
& \text{If cluster sizes are equal then} \\
& = \frac{k-1}{k} \hat \rho_I + \frac{1}{k}\\
\Rightarrow & \hat \rho_I = \frac{k}{k-1}\hat \rho^*_I - \frac{1}{k-1}
\end{align*}
$$



# Rank-based ICC

We propose a rank-based ICC using cumulative probability functions, which maintains the spirit of Fisher's ICC definition and the nonparametric nature of Spearman's rank correlation. Let $F$ be the cumulative probability of $X$, and $F(x-)=\lim_{t \uparrow x} F(t)$. We define the population version of the rank-based ICC as 
$$\gamma_I = corr[\{F(X_{ij})+F(X_{ij}^-)\}/2, \{F(X_{ij'})+F(X_{ij'}^-)\}/2]$$
where $(X_{ij}, X_{ij'})$ is a random pair drawn from a random cluster, $j\neq j'$. When $X$ is continuous, $\gamma_I = 12cov[F(X_{ij}), F(X_{ij'})]$, because the continuous $F$ follows an uniform distribution over $[0,1]$ and the inverse of its variance is $12$.


# Estimation

Here we focus on nonparametric estimation. 

Given two-level nested data$\{x_{ij};i=1,2,...,n, j=1,2,...,k_i\}$, a nonparametric estimator for the cumulative probability function could be $\hat F(x) = \sum_{i=1}^n \sum_{j=1}^{k_i} p_{ij}I(x_{ij} \leq x)$, where the probability $p_{ij}$ depends on how we believe the data reflect the composition of the underlying hierarchical distribution, and $\sum_{i=1}^n \sum_{j=1}^{k_i} p_{ij} = 1$. The probability of a cluster is denoted as $p_{i.} = \sum_{j=1}^{k_i} p_{ij}$, which represents the degree of the cluster's contribution to the underlying distribution. Similarly, $\hat F(x^-) = \sum_{i=1}^n \sum_{j=1}^{k_i} p_{ij}I(x_{ij} < x)$. To simplify the denotation, we denote $\{\hat F(x) + \hat F(x-)\}/2$ as $\hat F^*(x)$. Then, the estimator of rank-based ICC is the ICC of $\hat F^*(x)$. 

In accordance with Fisher's definition for ICC, we pool the data to estimate the mean and variance. The total variance is estimated by $\sum_{i=1}^n \sum_{j=1}^{k_i} p_{ij} [\hat F^*(x_{ij}) - \bar F^*]^2$, where $\bar F^* =  \sum_{i=1}^n \sum_{j=1}^{k_i} p_{ij} \hat F^* (x_{ij})$. There are $k_i(k_i-1)/2$ combinations of unordered pairs in a cluster with $k_i$ observations. Then, the covariance is estimated by $\sum_{i=1}^n p_{i.} \sum_{j=1}^{k_i-1}\sum_{j'=j+1}^{k_i} \frac{2}{k_i(k_i-1)} [\hat F^*(x_{ij}) - \bar F^*][\hat F^*(x_{ij'}) - \bar F^*]$.


The general form of the estimator is
$$\hat \gamma_I = \frac{\sum_{i=1}^n p_{i.} \sum_{j=1}^{k_i-1}\sum_{j'=j+1}^{k_i} \frac{2}{k_i(k_i-1)} [\hat F^*(x_{ij}) - \bar F^*][\hat F^*(x_{ij'}) - \bar F^*]}{\sum_{i=1}^n \sum_{j=1}^{k_i} p_{ij} [\hat F^*(x_{ij}) - \bar F^*]^2}$$

We consider two methods of weighting:

- Equal probability of observations: when all the observations are treated equally, we assume that cluster sizes determine the contributions of clusters to the underlying hierarchical distribution. We assign equal probabilities to observations, $p_{ij} = 1/N$ where $N$ is the total number of observations. The corresponding $\hat F$ is the empirical distribution of the data ignoring the nested structure. 
- Equal probability of clusters: when all the clusters are treated equally, we suppose the sampled clusters contribute equally to the underlying distribution. In this case, the probability of each observation 
is proportional to the size of its cluster, $p_{ij} = 1/(nk_i)$.

The two methods are extreme cases for optimal weighting; equal probability for observations when ICC is zero, equal probability for clusters when ICC is one. The optimal weighting depends on true ICC. 

## Other weighting methods 

- We consider estimating the optimal weights of clusters through effective sample sizes. For a cluster, the variance of the sample mean is the population variance divided by the effective sample size. Given the intraclass correlation is the same for any random pair in a random cluster, the effective sample size of the $i$th cluster is $\frac{k_i}{1+(k_i-1)\gamma_I}$ where $k_i$ is the cluster size. Then, the probability of a cluster is $p_{i.} = \frac{k_i}{(1+(k_i-1)\gamma_I)\sum_{i=1}^n \frac{k_i}{1+(k_i-1)\gamma_I}}$, the probability of an observation in the cluster is $p_{ij} = p_{i.}/k_i$.  

- Since equal observations and equal clusters are two extreme cases for intraclass correlation, we can form a weight which is a linear combination of them. That is, $p_{ij} = \frac{1-\gamma_I}{N} + \frac{\gamma_I}{nk_i}$. 


To gain more efficiency, we consider two-step estimators for ICC. 

- Step 1: Obtain $\tilde \gamma_I$ and $p_{ij}(\tilde \gamma_I)$
- Step 2: Obtain $\hat \gamma_I|p_{ij}(\tilde \gamma_I)$
- Step 1 and 2 are iterated until the estimate converges. 


## Alternative estimation methods

There are other estimation methods we've considered,

- Using ranked data
- Bootstrap 

Using ranked data is very easy but it's hard to interpret variance of ranking. The bootstrap method keeps the definition of rank-based ICC but maybe computational. 


## Variance Estimation 

The rank-based ICC estimator is $$\hat \gamma_I = \frac{\sum_{i=1}^n p_{i.} \sum_{j=1}^{k_i-1}\sum_{j'=j+1}^{k_i} \frac{2}{k_i(k_i-1)} [\hat F^*(x_{ij}) - \bar F^*][\hat F^*(x_{ij'}) - \bar F^*]}{\sum_{i=1}^n \sum_{j=1}^{k_i} p_{ij} [\hat F^*(x_{ij}) - \bar F^*]^2}$$
Let $A_n = \frac{1}{n}\sum_{i=1}^n \sum\limits_{j'>j} p_{i.} \frac{2}{k_i(k_i-1)} [\hat F^*(x_{ij}) - \bar F^*][\hat F^*(x_{ij'}) - \bar F^*]$, $B_n = \frac{1}{n}\sum_{i=1}^n \sum_{j=1}^{k_i} p_{ij} [\hat F^*(x_{ij}) - \bar F^*]^2$.
 
- I = $p_{i.} \frac{2}{k_i(k_i-1)} \sum\limits_{j'>j}[\hat F^*(x_{ij}) - \bar F^*][\hat F^*(x_{ij'}) - \bar F^*]/ B_n$
- II = $-\frac{A_n}{B_n^2} \sum_{j=1}^{k_i} p_{ij} [\hat F^*(x_{ij}) - \bar F^*]^2$
- III = $\frac{1}{nB_n} \sum\limits_{i'=1}^n \frac{2p_{i'.} }{k_{i'}(k_{i'}-1)} \sum\limits_{j'>j} \{\hat F^*(x_{i'j'}) - \bar F^*\}\{\sum\limits_{\tilde j=1}^{k_i} p_{i \tilde j} [ I(x_{i\tilde j} \leq x_{i'j})+I(x_{i\tilde j} < x_{i'j})]/2 \}$
- IV = $\frac{1}{nB_n} \sum\limits_{i'=1}^n \frac{2p_{i'.} }{k_{i'}(k_{i'}-1)} \sum\limits_{j'>j} \{\hat F^*(x_{i'j}) - \bar F^*\}\{\sum\limits_{\tilde j=1}^{k_i} p_{i \tilde j} [ I(x_{i\tilde j} \leq x_{i'j'})+I(x_{i\tilde j} < x_{i'j'})]/2 \}$
- V = $- \frac{C_{ni}}{nB_n} \sum\limits_{i=1}^n \frac{2 p_{i.}}{k_i(k_i-1)} \sum\limits_{j'>j}[\hat F^*(x_{ij}) - \bar F^*+\hat F^*(x_{ij'}) - \bar F^*]$, where $C_{ni} = \sum_{j=1}^{k_i} p_{ij} \hat F^*(x_{ij}) + \frac{1}{n} \sum\limits_{i'=1}^n \sum\limits_{j'=1}^{k_{i'}} p_{i'j'}  \big\{\sum\limits_{j=1}^{k_i} p_{ij} [I(x_{ij} \leq x_{i'j'})+I(x_{ij} < x_{i'j'})]/2\big\}$
- VI = $-\frac{2A_n}{nB_n^2}  \sum\limits_{i'=1}^n \sum\limits_{j'=1}^{k_{i'}} p_{i'j'}[\hat F^*(x_{i'j'}) - \bar F^*] \Big\{ \sum\limits_{j=1}^{k_i} p_{ij}[I(x_{ij} \leq x_{i'j'})+I(x_{ij} < x_{i'j'})]/2 - C_{ni} \Big\}$
- The asymptotic variance is the variance of $(I+II+III+IV+V+VI)/\sqrt{n}$


# Simulations

```{r}
generate.data <- function(seed=1234, n=30, cluster.limit=c(10,10), mu=1, vu=1,vr=1, hlf=F){
  set.seed(seed)
  #cluster size
  if(hlf) size.cluster <- rep(cluster.limit, each = n/2)
  else{
      if(cluster.limit[1] == cluster.limit[2]){
        size.cluster <- rep(cluster.limit[1], n)
        }else size.cluster <- replicate(n, sample(cluster.limit[1]:cluster.limit[2], 1))
  }
  #generate data for each cluster
  x <- NULL
  cluster <- NULL
  id <- NULL
  #generate cluster means
  u <- rnorm(n, mean = mu, sd = sqrt(vu))
  for(i in 1:n){
    n.cluster <- size.cluster[i]
    r <- rnorm(n.cluster, mean = 0, sd = sqrt(vr))
    x <- c(x, r+u[i])
    cluster <- c(cluster, rep(i, n.cluster))
    id <- c(id, 1:n.cluster)
  }
  dat <- data.frame("x"=x,
                    "cluster"=as.factor(cluster),
                    "id"=as.factor(id))
  return(dat)
}


est.icc <- function(x, cluster){
  dat <- data.frame("x"=x, "cluster"=cluster)
  #within var
  m <- nrow(dat)
  n.cls  <- length(unique(dat$cluster))
  tb <- dat %>% group_by(cluster) %>%
    mutate(xd = x - mean(x), xb = mean(x))
  swx <- var(tb$xd) * (m-1)/(m-n.cls)
  #between var
  nj <- dat %>% group_by(cluster) %>% summarise(nj = length(x)) %>% pull(nj)
  nt <- 1/(n.cls - 1) * (m - sum(nj^2) / m)
  sbx <- var(tb$xb) * (m-1)/(n.cls-1)/nt
  stx <- sbx - swx/nt +swx
  #ICC
  irx <- (sbx - swx/nt)/stx
  return(list("bVar"=sbx - swx/nt, 
              "wVar"=swx,
              "icc"=irx))
}
est.lmer <- function(x, cluster){
  dat <- data.frame("x"=x, "cluster"=cluster)
  m <- lmer(x ~ (1|cluster), data = dat, REML = T)
  sx <- as.data.frame(VarCorr(m))[,"vcov"]
  return(list("bVar"=sx[1], 
              "wVar"=sx[2],
              "icc"=sx[1]/sum(sx)))
}

aggrMean <- function(mat,cluster){
    ucl <- unique(cluster)
    nid <- ncol(mat)
    nucl <- length(ucl)
    out <- matrix(NA, nucl, nid)
    for (i in 1:nucl){
      nl = sum(cluster == ucl[i])
      out[i,] <- colMeans(matrix(mat[cluster == ucl[i],], nrow = nl)) 
    }
    out
}

aggrCDF <- function(m, type){
  mat <- outer(m,m, "*")
  s <- sum(mat) - sum(diag(mat))
  if(type=="EC") r <- s / (nrow(mat) * (nrow(mat)-1))
  if(type=="EI") r <- s / (nrow(mat)-1)
  return(r)
}

est.cdf <- function(x, cluster){
  dat <- data.frame("x"=x, "cluster"=cluster)
  cls.size <- table(dat$cluster)
  ############ equal weights for cluster
  dat <- dat %>% group_by(cluster) %>% mutate(size=n())
  dat$f <- (colMeans(aggrMean(outer(x, x, "<="), cluster)) + colMeans(aggrMean(outer(x, x, "<"), cluster)))/2
  ncl <- length(unique(cluster))
  avg <- sum(dat$f/dat$size)/ncl
  cl <- unique(dat$cluster)
  tv <- sum((dat$f - avg)^2/dat$size)/ncl
  cv <- sapply(cl, function(i) aggrCDF(dat[dat$cluster==i,"f",drop=T] - avg, type="EC"))
  nvEC <- sum(cv)/ncl/tv
  ############ equal weights for obs
  f <- ecdf(dat$x)
  g <- function(a) 1 - (ecdf(-x))(-a)
  dat$fh <- (f(dat$x)+g(dat$x))/2
  avg <- mean(dat$fh)
  cl <- unique(dat$cluster)
  tv <- mean((dat$fh - avg)^2)
  cv <- sapply(cl, function(i) aggrCDF(dat[dat$cluster==i,"fh",drop=T] - avg, type="EI"))
  nvEI <- sum(cv)/nrow(dat)/tv  
  c(nvEI, nvEC)
}

#functions for Method 5.1 and 5.2
CDF.mean <- function(x, pij){
  mat <- outer(x, x, "<=")
  ef <- t(mat) %*% pij
  mat <- outer(x, x, "<")
  ef <- (ef + t(mat) %*% pij)/2
  ef
}
CDF.cov <- function(ef, pci){
  mat <- outer(ef,ef, "*")
  s <- sum(mat) - sum(diag(mat)) 
  r <- s / (nrow(mat) * (nrow(mat)-1)) * pci
  return(r)
}
est.Wcdf <- function(x, cluster, ri){
  dat <- data.frame("x"=x, "cluster"=cluster)
  cpsum <- sum(dat %>% group_by(cluster) %>% summarise(size=n(), c=size/(1+(size-1)*ri)) %>% pull(c))
  dat <- dat %>% group_by(cluster) %>% mutate(size=n(), ci=size/(1+(size-1)*ri), pci=ci/cpsum, pij=ci/cpsum/size)
  dat$ef <- CDF.mean(dat$x, dat$pij)
  avg <- sum(dat$ef * dat$pij)  
  tv <- sum((dat$ef - avg)^2 * dat$pij)
  cl <- unique(dat$cluster)
  cv <- sapply(cl, function(i){
     l <- as.vector(dat[dat$cluster==i,"ef",drop=T]) - avg
     p <-  unique(dat[dat$cluster==i,"pci",drop=T])
     CDF.cov(l, p)
  })
  est <- sum(cv)/tv
  return(est)
}
est.Wcdf2 <- function(x, cluster, ri){
  dat <- data.frame("x"=x, "cluster"=cluster)
  cpsum <- sum(dat %>% group_by(cluster) %>% summarise(size=n(), c=size/(1+(size-1)*ri)) %>% pull(c))
  N <- nrow(dat); n <- length(unique(dat$cluster))
  dat <- dat %>% group_by(cluster) %>% mutate(size=n(),pij=(1-ri)/N + ri/size/n, pci=sum(pij))
  dat$ef <- CDF.mean(dat$x, dat$pij)
  avg <- sum(dat$ef * dat$pij)  
  tv <- sum((dat$ef - avg)^2 * dat$pij)
  cl <- unique(dat$cluster)
  cv <- sapply(cl, function(i){
     l <- as.vector(dat[dat$cluster==i,"ef",drop=T]) - avg
     p <-  unique(dat[dat$cluster==i,"pci",drop=T])
     CDF.cov(l, p)
  })
  est <- sum(cv)/tv
  return(est)
}

est.iter <- function(x, cluster, ri=0, tol=1e-5, maxIter=100){
  i <- 0; d <- 10
  ri1 <- ri2 <- ri
  while(i < maxIter & d > tol){
    rnew <- est.Wcdf(x, cluster, ri1)
    d <- abs(rnew - ri1)
    ri1 <- rnew
    i <- i + 1
  }
  n1 <- i
  i <- 0; d <- 10
  while(i < maxIter & d > tol){
    rnew <- est.Wcdf2(x, cluster, ri2)
    d <- abs(rnew - ri2)
    ri2 <- rnew
    i <- i + 1
  }
  n2 <- i
  c(ri1, ri2, n1, n2)
}
```

## Scenario 1


- $X_{ij} = U_i + R_{ij}$, where $i=1,2,...,100$, $j=1,2,...,k_i$, $k_i \in\{2,30,[2,50], \{2,30\}\}$ 
- $U_i \stackrel{i.i.d}{\sim} N(\mu,\sigma^2_u)$, for $i=1,2,...,100$
- $R_{ij} \stackrel{i.i.d}{\sim} N(0,\sigma^2_r)$, for $i=1,2,...,100$ and $j=1,2,...,k_i$. 
- $\rho_I=corr(X_{ij},X_{ij'})=\frac{\sigma^2_u}{\sigma^2_u+\sigma^2_r}$
- Set $\mu=1$, $\sigma_u^2=1$, $\rho_I \in \{0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1\}$, $\sigma_r^2 = \frac{(1-\rho_I)\sigma_u^2}{\rho_I}$ (for $\rho_I$=0, $\sigma_u^2=0$,$\sigma_r^2=10$). Under normality, we can have $\gamma_I = 6\text{arcsin}(\rho_I/2)/\pi$. 
- 2/30(2): the within-cluster variance of clusters with 2 observations is $0.5\sigma_r^2$ and its contribution to the underlying distribution is $2/32$, the within-cluster variance of clusters with 30 observations is $1.5\sigma^2_r$ and its contribution to the underlying distribution is $30/32$. The population ICC is $\frac{\sigma^2_u}{\sigma^2_u + 0.5\sigma^2_r\times2/32 + 1.5\sigma^2_r\times30/32}$.
- 2/30(3): the within-cluster variance of clusters with 2 observations is $0.5\sigma_r^2$ and its contribution to the underlying distribution is $1/2$, the within-cluster variance of clusters with 30 observations is $1.5\sigma^2_r$ and its contribution to the underlying distribution is $1/2$. The population ICC is $\frac{\sigma^2_u}{\sigma^2_u + 0.5\sigma^2_r\times1/2 + 1.5\sigma^2_r\times1/2}$.
- For Method 5.1 and 5.2, the iteration is stopped when either the tolerance (tol=1e-5) or the maximum iteration time (maxIter=100) is achieved. 
- 1000 simulations. 


```{r}
load("data/sim_RankICC_S1.RData")
est <- NULL
std <- NULL
simest <- NULL
mse <- NULL
iterN <- NULL
r <-  6 * asin(rep(seq(0,1,0.1), 6)/2)/pi 
for(i in 1:length(ans)){
  t <- do.call(rbind,ans[[i]])
  iterN <- rbind(iterN, t[,c(5:6,9:10)])
  t <- t[,c(1:4,7:8)]
  simest <- rbind(simest,t)
  est <- rbind(est, colMeans(t))
  std <- rbind(std, apply(t,2, sd))
  mse <- rbind(mse, apply(t,2, function(x) mean((x-r[i])^2)))
}
est <- as.data.frame(est)
colnames(est) <- c("Equal Obs","Equal Clusters","ESS","Combo","EC+OPT1","EC+OPT2")
est$pearson <- seq(0,1,0.1)
est$spearman <- 6 * asin(est$pearson/2)/pi
est$size <- rep(c("2","30","2-50","2/30(1)","2/30(2)","2/30(3)"), each = 11)
est <- est %>% gather(key="Methods",value = "EST", "Equal Obs":"EC+OPT2")
est$Methods <- factor(est$Methods, levels = c("Equal Obs","Equal Clusters","ESS","Combo","EC+OPT1","EC+OPT2"))
est$MSE <- c(mse)
est$Std <- c(std) 
est$pb <- (est$EST - est$spearman)/est$spearman * 100
est$size <- factor(est$size, levels = c("2","30","2-50","2/30(1)","2/30(2)","2/30(3)"))
```



```{r s1mse,fig.width=8, fig.height=6}
p <- est %>% filter(Methods %in% c("Equal Obs","Equal Clusters","ESS","Combo"))
ggplot(p, aes(x=spearman, y=MSE, color=Methods)) + 
  scale_color_manual(values=brewer.pal(4,"Dark2")) +
  geom_point(aes(shape=Methods))+geom_line(aes(linetype=Methods),size=0.4) + facet_wrap(~size, ncol=3) + theme_classic() +
  xlab(TeX("$\\gamma_I$"))+theme(legend.position="top")+ 
  guides(color = guide_legend(keywidth = 3)) + theme(text = element_text(size=15))
```

```{r s1se,fig.width=8, fig.height=6}
ggplot(p, aes(x=spearman, y=Std, color=Methods)) + 
  scale_color_manual(values=brewer.pal(4,"Dark2")) +
  geom_point(aes(shape=Methods))+geom_line(aes(linetype=Methods),size=0.4)  + facet_wrap(~size, ncol=3) + theme_classic() +
  xlab(TeX("$\\gamma_I$"))+ylab("Empirical SE")+theme(legend.position="none")+ 
  guides(color = guide_legend(keywidth = 5)) + theme(text = element_text(size=15))
```


```{r s1bias,fig.width=8, fig.height=6}
ggplot(p[p$spearman!=0,], aes(x=spearman, y=pb, color=Methods)) + 
  scale_color_manual(values=brewer.pal(4,"Dark2")) +
  geom_point(aes(shape=Methods))+geom_line(aes(linetype=Methods),size=0.4) + facet_wrap(~size, ncol=3) + theme_classic() +
  geom_hline(yintercept=0, linetype="dashed", color = "black")+ 
  geom_hline(yintercept=-10, linetype="dashed", color = "black")+
  geom_hline(yintercept=10, linetype="dashed", color = "black")+ 
  xlab(TeX("$\\gamma_I$"))+ylab("Percent Bias (%)")+theme(legend.position="none") +
  guides(color = guide_legend(keywidth = 5)) + theme(text = element_text(size=15))

```


```{r}
iterN <- as.data.frame(iterN)
colnames(iterN) <- c("EO+OPT1","EO+OPT2","EC+OPT1","EC+OPT2")
iterN$size <- rep(c("2","30","2-50","2/30(1)","2-30(2)","2/30(3)"), each = 11000)
iterN$size <- factor(iterN$size, levels = c("2","30","2-50","2/30(1)","2/30(2)","2/30(3)"))
r <-  6 * asin(seq(0,1,0.1)/2)/pi
iterN$gI <- rep(rep(r, each=1000), 6)
# iterN <- iterN %>% gather(key="Methods", value="N", "EO+OPT1":"EC+OPT2") %>% 
#   group_by(size, gI, Methods) %>% 
#   summarise(Max=max(N), Median=median(N)) %>% 
#   gather(key="Type",value="Iterations", "Max":"Median")
# iterN$subtype <- "EO"
# iterN$subtype[grep("EC",iterN$Methods)] <- "EC"
# ggplot(iterN[iterN$size %in% c("2-50","2/30"),], aes(x=gI,y=Iterations,color=Methods)) + 
#   geom_point(pch=19,alpha=0.7) + facet_wrap(~Type+size, scales="free_y",ncol=2) + theme_classic() +
#   xlab("ICC")
```

There is only one time when the iteration time of EC/EO+OPT1 reached 100 (cluster size is 2/30(1), true ICC is 0). 


```{r s1mseSub,fig.width=6, fig.height=6}
p <- est %>% filter(Methods %in% c("Equal Obs","Equal Clusters","ESS","Combo")) %>% filter(size %in% c("2","30","2-50","2/30(1)"))
ggplot(p, aes(x=spearman, y=MSE, color=Methods)) + 
  scale_color_manual(values=brewer.pal(4,"Dark2")) +
  geom_point(aes(shape=Methods))+geom_line(aes(linetype=Methods),size=0.4)  + facet_wrap(~size, ncol=2) + theme_classic() +
  xlab(TeX("$\\gamma_I$"))+theme(legend.position="bottom")+
    guides(color = guide_legend(keywidth = 5,nrow=2,byrow=TRUE)) + theme(text = element_text(size=15))
```


```{r s1seSub,fig.width=6, fig.height=6}
ggplot(p, aes(x=spearman, y=Std, color=Methods)) + 
  scale_color_manual(values=brewer.pal(4,"Dark2")) +
   geom_point(aes(shape=Methods))+geom_line(aes(linetype=Methods),size=0.4)  + facet_wrap(~size, ncol=2) + theme_classic() +
  xlab(TeX("$\\gamma_I$"))+ylab("Empirical SE")+theme(legend.position="bottom")+    guides(color = guide_legend(keywidth = 5,nrow=2,byrow=TRUE)) + theme(text = element_text(size=15))
```

```{r s1biasSub,fig.width=6, fig.height=6}
ggplot(p[p$spearman!=0,], aes(x=spearman, y=pb, color=Methods)) + 
  scale_color_manual(values=brewer.pal(4,"Dark2")) +
   geom_point(aes(shape=Methods))+geom_line(aes(linetype=Methods),size=0.4)  + facet_wrap(~size, ncol=2) + theme_classic() +
  geom_hline(yintercept=0, linetype="dashed", color = "black")+ 
  ylim(c(-4,3)) + 
  xlab(TeX("$\\gamma_I$"))+ylab("Percent Bias (%)")+theme(legend.position="bottom")+    guides(color = guide_legend(keywidth = 5,nrow=2,byrow=TRUE)) + theme(text = element_text(size=15))
```


```{r s1extramse,fig.width=6, fig.height=3.5}
p <- est %>% filter(Methods %in% c("Equal Obs","Equal Clusters","ESS","Combo")) %>% filter(size %in% c("2/30(2)","2/30(3)"))
ggplot(p, aes(x=spearman, y=MSE, color=Methods)) + 
  scale_color_manual(values=brewer.pal(4,"Dark2")) +
   geom_point(aes(shape=Methods))+geom_line(aes(linetype=Methods),size=0.4) + facet_wrap(~size, ncol=2) + theme_classic() +
  xlab(TeX("$\\gamma_I$"))+theme(legend.position="bottom")+ guides(color = guide_legend(keywidth = 5,nrow=2,byrow=TRUE)) + theme(text = element_text(size=15))
```

```{r s1extrase,fig.width=6, fig.height=3.5}
ggplot(p, aes(x=spearman, y=Std, color=Methods)) + 
  scale_color_manual(values=brewer.pal(4,"Dark2")) +
  geom_point(aes(shape=Methods))+geom_line(aes(linetype=Methods),size=0.4) + facet_wrap(~size, ncol=2) + theme_classic() +
  xlab(TeX("$\\gamma_I$"))+ylab("Empirical SE")+theme(legend.position="bottom")+ guides(color = guide_legend(keywidth = 5,nrow=2,byrow=TRUE)) + theme(text = element_text(size=15))
```

```{r s1extrabias,fig.width=6, fig.height=3.5}
ggplot(p[p$spearman!=0,], aes(x=spearman, y=pb, color=Methods)) + 
  scale_color_manual(values=brewer.pal(4,"Dark2")) +
  geom_point(aes(shape=Methods))+geom_line(aes(linetype=Methods),size=0.4) +facet_wrap(~size, ncol=2) + theme_classic() +
  geom_hline(yintercept=0, linetype="dashed", color = "black")+ 
  geom_hline(yintercept=-10, linetype="dashed", color = "black")+
  geom_hline(yintercept=10, linetype="dashed", color = "black")+ 
  xlab(TeX("$\\gamma_I$"))+ylab("Percent Bias (%)")+theme(legend.position="bottom")+ guides(color = guide_legend(keywidth = 5,nrow=2,byrow=TRUE)) + theme(text = element_text(size=15))
```




```{r,fig.width=8, fig.height=8}
simest <- as.data.frame(simest)
colnames(simest) <- c("Equal Obs","Equal Clusters","ESS","Combo","EC+OPT1","EC+OPT2")
simest$size <- rep(c("2","30","2-50","2/30(1)","2/30(2)","2/30(3)"), each = 11000)
simest$size <- factor(simest$size, levels = c("2","30","2-50","2/30(1)","2/30(2)","2/30(3)"))
r <-  6 * asin(seq(0,1,0.1)/2)/pi 
simest$gI <- round(rep(rep(r, each=1000), 6),2)
simest$rI <- rep(rep(seq(0,1,0.1), each=1000), 6)
diag_line <- function(x,y,...){
    points(x,y,...)
    abline(a = 0,b = 1,col="black", lty="dashed", lwd=2)
}
d <- simest %>% filter(size=="2") %>% select("Equal Obs":"Combo")
pairs(d,pch=19,
      cex.labels=1.5, cex=0.8,cex.axis=1,
      xlim=c(min(d),max(d)),ylim=c(min(d),max(d)),
      col=alpha(brewer.pal(12,"Paired")[c(1:10,12)][factor(simest$rI)], 0.6),
      lower.panel = diag_line, upper.panel = NULL,
      main="Cluster size: 2")
legend(0.9,0.8,title = TeX("$\\gamma_I$"), legend=round(r,2), col=brewer.pal(12,"Paired")[c(1:10,12)], pch=19, cex=1, y.intersp = 1,bty="n")
```

```{r,fig.width=8, fig.height=8}
d <- simest %>% filter(size=="30") %>% select("Equal Obs":"Combo")
pairs(d,pch=19,
      cex.labels=1.5, cex=0.8,cex.axis=1,
      xlim=c(min(d),max(d)),ylim=c(min(d),max(d)),
      col=alpha(brewer.pal(12,"Paired")[c(1:10,12)][factor(simest$rI)], 0.6),
      lower.panel = diag_line, upper.panel = NULL,
      main="Cluster size: 2")
legend(0.9,0.8,title = TeX("$\\gamma_I$"), legend=round(r,2), col=brewer.pal(12,"Paired")[c(1:10,12)], pch=19, cex=1, y.intersp = 1,bty="n")
```

```{r,fig.width=8, fig.height=8}
d <- simest %>% filter(size=="2-50") %>% select("Equal Obs":"Combo")
pairs(d,pch=19,
      cex.labels=1.5, cex=0.8,cex.axis=1,
      xlim=c(min(d),max(d)),ylim=c(min(d),max(d)),
      col=alpha(brewer.pal(12,"Paired")[c(1:10,12)][factor(simest$rI)], 0.6),
      lower.panel = diag_line, upper.panel = NULL,
      main="Cluster size: 2")
legend(0.9,0.8,title = TeX("$\\gamma_I$"), legend=round(r,2), col=brewer.pal(12,"Paired")[c(1:10,12)], pch=19, cex=1, y.intersp = 1,bty="n")
```


```{r,fig.width=8, fig.height=8}
d <- simest %>% filter(size=="2/30(1)") %>% select("Equal Obs":"Combo")
pairs(d,pch=19,
      cex.labels=1.5, cex=0.8,cex.axis=1,
      xlim=c(min(d),max(d)),ylim=c(min(d),max(d)),
      col=alpha(brewer.pal(12,"Paired")[c(1:10,12)][factor(simest$rI)], 0.6),
      lower.panel = diag_line, upper.panel = NULL,
      main="Cluster size: 2")
legend(0.9,0.8,title = TeX("$\\gamma_I$"), legend=round(r,2), col=brewer.pal(12,"Paired")[c(1:10,12)], pch=19, cex=1, y.intersp = 1,bty="n")
```

```{r,fig.width=8, fig.height=8}
d <- simest %>% filter(size=="2/30(2)") %>% select("Equal Obs":"Combo")
pairs(d,pch=19,
      cex.labels=1.5, cex=0.8,cex.axis=1,
      xlim=c(min(d),max(d)),ylim=c(min(d),max(d)),
      col=alpha(brewer.pal(12,"Paired")[c(1:10,12)][factor(simest$rI)], 0.6),
      lower.panel = diag_line, upper.panel = NULL,
      main="Cluster size: 2")
legend(0.9,0.8,title = TeX("$\\gamma_I$"), legend=round(r,2), col=brewer.pal(12,"Paired")[c(1:10,12)], pch=19, cex=1, y.intersp = 1,bty="n")
```

```{r}
load("data/sim_RankICC_S1.RData")
est <- NULL
std <- NULL
simest <- NULL
mse <- NULL
iterN <- NULL
r <-  6 * asin(rep(seq(0,1,0.1), 6)/2)/pi 
for(i in 1:length(ans)){
  t <- do.call(rbind,ans[[i]])
  iterN <- rbind(iterN, t[,c(5:6,9:10)])
  t <- t[,c(1:4,7:8)]
  simest <- rbind(simest,t)
  est <- rbind(est, colMeans(t))
  std <- rbind(std, apply(t,2, sd))
  mse <- rbind(mse, apply(t,2, function(x) sqrt(mean((x-r[i])^2))))
}
est <- as.data.frame(est)
colnames(est) <-  c("EO","EC","EO+OPT1","EO+OPT2","EC+OPT1","EC+OPT2")
est$pearson <- seq(0,1,0.1)
est$spearman <- 6 * asin(est$pearson/2)/pi
est$size <- rep(c("2","30","2-50","2/30(1)","2/30(2)","2/30(3)"), each = 11)
format_bias_var <- function(idx,a, b){
  t <- NULL
  for(i in seq_along(a)){
    if(b[i] != 0){
      t <- c(t, paste(round(a[i],3), " (", round(std[i,idx],3),", ",
                      round((a[i] - b[i])/b[i]*100,3),"%",
                      ", ",round(mse[i,idx],3),")", sep = ""))}
    else t <- c(t, paste(round(a[i],3), " (", round(std[i,idx],3),
                         ", ","NA%",", ",round(mse[i,idx],3),")",sep=""))
  }
  t
}
est$EO <- format_bias_var(1, est$EO, est$spearman)
est$EC <- format_bias_var(2, est$EC, est$spearman)
est$`EO+OPT1` <- format_bias_var(3, est$`EO+OPT1`, est$spearman)
est$`EO+OPT2` <- format_bias_var(4, est$`EO+OPT2`, est$spearman)
est$`EC+OPT1` <- format_bias_var(5, est$`EC+OPT1`, est$spearman)
est$`EC+OPT2` <- format_bias_var(6, est$`EC+OPT2`, est$spearman)
est <- est[,c("pearson","spearman","EO","EC","EC+OPT1","EC+OPT2")]
colnames(est) <- c("Intraclass Pearson Correlation", "Intraclass Spearman Correlation",  "Equal Observations","Equal Clusters","ESS", "Combo")
rownames(est) <- NULL
est %>% 
  kbl(digits = 3, align = "c", full.width = F) %>% 
  kable_styling(full_width = F) %>%
  add_header_above(c(" "= 2,"Estimates (SD, % Bias, RMSE)"=4)) %>%
  pack_rows("2 obs per cluster", 1, 11) %>%
  pack_rows("30 obs per cluster", 12, 22) %>%
  pack_rows("2-50 obs per cluster", 23, 33) %>%
  pack_rows("2 or 30 obs per cluster", 34, 44) %>% 
  pack_rows("2 or 30 obs per cluster (different within variances and cluster contributions)", 45, 55)  %>% 
  pack_rows("2 or 30 obs per cluster (different within variances but same cluster contributions)", 56, 66)   

```

## Scenario 2 Exponentiation 

- $log(X_{ij}) = U_i + R_{ij}$, where $i=1,2,...,100$, $j=1,2,...,k_i$, $k_i \in\{2,30,[2,50], \{2,30\}\}$ 
- $U_i \stackrel{i.i.d}{\sim} N(\mu,\sigma^2_u)$, for $i=1,2,...,100$
- $R_{ij} \stackrel{i.i.d}{\sim} N(0,\sigma^2_r)$, for $i=1,2,...,100$ and $j=1,2,...,k_i$. 
- $\rho_I=corr(log(X_{ij}),log(X_{ij'}))=\frac{\sigma^2_u}{\sigma^2_u+\sigma^2_r}$
- Set $\mu=1$, $\sigma_u^2=1$, $\rho_I \in \{0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1\}$, $\sigma_r^2 = \frac{(1-\rho_I)\sigma_u^2}{\rho_I}$ (for $\rho_I$=0, $\sigma_u^2=0$,$\sigma_r^2=10$). Under normality, we can have $\gamma_I = 6\text{arcsin}(\rho_I/2)/\pi$. 
- 2/30(2): the within-cluster variance of clusters with 2 observations is $0.5\sigma_r^2$ and its contribution to the underlying distribution is $2/32$, the within-cluster variance of clusters with 30 observations is $1.5\sigma^2_r$ and its contribution to the underlying distribution is $30/32$. The population ICC is $\frac{\sigma^2_u}{\sigma^2_u + 0.5\sigma^2_r\times2/32 + 1.5\sigma^2_r\times30/32}$.
- 2/30(3): the within-cluster variance of clusters with 2 observations is $0.5\sigma_r^2$ and its contribution to the underlying distribution is $1/2$, the within-cluster variance of clusters with 30 observations is $1.5\sigma^2_r$ and its contribution to the underlying distribution is $1/2$. The population ICC is $\frac{\sigma^2_u}{\sigma^2_u + 0.5\sigma^2_r\times1/2 + 1.5\sigma^2_r\times1/2}$.
- For optimization, the iteration is stopped when either the tolerance (tol=1e-5) or the maximum iteration time (maxIter=100) is achieved. 
- 1000 simulations. 

```{r}
load("data/sim_RankICC_S2.RData")
est <- NULL
std <- NULL
simest <- NULL
mse <- NULL
iterN <- NULL
r <-  6 * asin(rep(seq(0,1,0.1), 6)/2)/pi 
for(i in 1:length(ans)){
  t <- do.call(rbind,ans[[i]])
  iterN <- rbind(iterN, t[,c(5:6,9:10)])
  t <- t[,c(1:4,7:8)]
  simest <- rbind(simest,t)
  est <- rbind(est, colMeans(t))
  std <- rbind(std, apply(t,2, sd))
  mse <- rbind(mse, apply(t,2, function(x) sqrt(mean((x-r[i])^2))))
}
est <- as.data.frame(est)
colnames(est) <-  c("EO","EC","EO+OPT1","EO+OPT2","EC+OPT1","EC+OPT2")
est$pearson <- seq(0,1,0.1)
est$spearman <- 6 * asin(est$pearson/2)/pi
est$size <- rep(c("2","30","2-50","2/30(1)","2/30(2)","2/30(3)"), each = 11)
format_bias_var <- function(idx,a, b){
  t <- NULL
  for(i in seq_along(a)){
    if(b[i] != 0){
      t <- c(t, paste(round(a[i],3), " (", round(std[i,idx],3),", ",
                      round((a[i] - b[i])/b[i]*100,3),"%",
                      ", ",round(mse[i,idx],3),")", sep = ""))}
    else t <- c(t, paste(round(a[i],3), " (", round(std[i,idx],3),
                         ", ","NA%",", ",round(mse[i,idx],3),")",sep=""))
  }
  t
}
est$EO <- format_bias_var(1, est$EO, est$spearman)
est$EC <- format_bias_var(2, est$EC, est$spearman)
est$`EO+OPT1` <- format_bias_var(3, est$`EO+OPT1`, est$spearman)
est$`EO+OPT2` <- format_bias_var(4, est$`EO+OPT2`, est$spearman)
est$`EC+OPT1` <- format_bias_var(5, est$`EC+OPT1`, est$spearman)
est$`EC+OPT2` <- format_bias_var(6, est$`EC+OPT2`, est$spearman)
est <- est[,c("pearson","spearman","EO","EC","EC+OPT1","EC+OPT2")]
colnames(est) <- c("Intraclass Pearson Correlation", "Intraclass Spearman Correlation",  "Equal Observations","Equal Clusters","ESS", "Combo")
rownames(est) <- NULL
est %>% 
  kbl(digits = 3, align = "c", full.width = F) %>% 
  kable_styling(full_width = F) %>%
  add_header_above(c(" "= 2,"Estimates (SD, % Bias, RMSE)"=4)) %>%
  pack_rows("2 obs per cluster", 1, 11) %>%
  pack_rows("30 obs per cluster", 12, 22) %>%
  pack_rows("2-50 obs per cluster", 23, 33) %>%
  pack_rows("2 or 30 obs per cluster", 34, 44) %>% 
  pack_rows("2 or 30 obs per cluster (different within variances and cluster contributions)", 45, 55)  %>% 
  pack_rows("2 or 30 obs per cluster (different within variances but same cluster contributions)", 56, 66)   
```

```{r}
iterN <- as.data.frame(iterN)
colnames(iterN) <- c("EO+OPT1","EO+OPT2","EC+OPT1","EC+OPT2")
iterN$size <- rep(c("2","30","2-50","2/30(1)","2-30(2)","2/30(3)"), each = 11000)
iterN$size <- factor(iterN$size, levels = c("2","30","2-50","2/30(1)","2/30(2)","2/30(3)"))
r <-  6 * asin(seq(0,1,0.1)/2)/pi
iterN$gI <- rep(rep(r, each=1000), 6)
```


There is only one time when the iteration time of EC/EO+OPT1 reached 100 (cluster size is 2/30(1), true ICC is 0).  


## Scenario 3 Log-normal cluster mean


- $X_{ij} = U_i + R_{ij}$, where $i=1,2,...,100$, $j=1,2,...,k_i$, $k_i \in\{2,30,[2,50], \{2,30\}\}$ 
- $log(U_i) \stackrel{i.i.d}{\sim} N(\mu,\sigma^2_{logu})$, for $i=1,2,...,100$
- $R_{ij} \stackrel{i.i.d}{\sim} N(0,\sigma^2_r)$, for $i=1,2,...,100$ and $j=1,2,...,k_i$. 
- $\rho_I=corr(X_{ij},X_{ij'})=\frac{\sigma^2_{u}}{\sigma^2_{u}+\sigma^2_r}$, where $\sigma^2_{u}=(exp(\sigma^2_{logu})-1)exp(2\mu+\sigma^2_{logu})$
- Set $\mu=1$, $\sigma^2_{u}=1$, $\rho_I \in \{0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1\}$, then $\sigma_r^2 = \frac{(1-\rho_I)\sigma^2_{u}}{\rho_I}$ (for $\rho_I$=0, $\sigma^2_{u}=0$,$\sigma_r^2=10$), $\sigma^2_{logu} = log(1/2+\sqrt{\sigma^2_{u}exp(-2\mu)+1/4})$. We use an empirical estimate for the value of $\gamma_I$. 
- 2/30(2): the within-cluster variance of clusters with 2 observations is $0.5\sigma_r^2$ and its contribution to the underlying distribution is $2/32$, the within-cluster variance of clusters with 30 observations is $1.5\sigma^2_r$ and its contribution to the underlying distribution is $30/32$. The population ICC is $\frac{\sigma^2_u}{\sigma^2_u + 0.5\sigma^2_r\times2/32 + 1.5\sigma^2_r\times30/32}$.
- 2/30(3): the within-cluster variance of clusters with 2 observations is $0.5\sigma_r^2$ and its contribution to the underlying distribution is $1/2$, the within-cluster variance of clusters with 30 observations is $1.5\sigma^2_r$ and its contribution to the underlying distribution is $1/2$. The population ICC is $\frac{\sigma^2_u}{\sigma^2_u + 0.5\sigma^2_r\times1/2 + 1.5\sigma^2_r\times1/2}$.
- For optimization, the iteration is stopped when either the tolerance (tol=1e-5) or the maximum iteration time (maxIter=100) is achieved. 
- 1000 simulations. 

```{r, eval=F}
generate.data.log <- function(seed=1234, n=30, cluster.limit=c(10,10), mu=1, vu=1,vr=1, hlf=F){
  set.seed(seed)
  #cluster size
  if(hlf) size.cluster <- rep(cluster.limit, each = n/2)
  else{
    if(cluster.limit[1] == cluster.limit[2]){
      size.cluster <- rep(cluster.limit[1], n)
    }else size.cluster <- replicate(n, sample(cluster.limit[1]:cluster.limit[2], 1))
  }
  #generate data for each cluster
  x <- list()
  cluster <- list()
  id <- list()
  #generate cluster means
  u <- exp(rnorm(n, mean = mu, sd = sqrt(vu)))
  for(i in 1:n){
    n.cluster <- size.cluster[i]
    r <- rnorm(n.cluster, mean = 0, sd = sqrt(vr))
    x[[i]] <- r+u[i] 
    cluster[[i]] <- rep(i, n.cluster)
    id[[i]] <- 1:n.cluster
  }
  dat <- data.frame("x"= unlist(x),
                    "cluster"=as.factor(unlist(cluster)),
                    "id"=as.factor(unlist(id)))
  return(dat)
}
est.lmer <- function(x, cluster){
  dat <- data.frame("x"=x, "cluster"=cluster)
  m <- lmer(x ~ (1|cluster), data = dat, REML = T)
  sx <- as.data.frame(VarCorr(m))[,"vcov"]
  return(list("bVar"=sx[1], 
              "wVar"=sx[2],
              "icc"=sx[1]/sum(sx)))
}

CDF.mean <- function(x, pij, tol = 1e-7) {
  vapply(x, function(i) {
    c1 <- x - i
    isEq <- abs(c1) < tol
    isLT <- (!isEq & c1 < 0)
    sum(isLT * pij + (isEq * pij) / 2)
  }, numeric(1))
}

CDF.cov <- function(ef, pci){
  mat <- outer(ef, ef, `*`)
  s <- sum(mat) - sum(diag(mat)) 
  r <- s / (nrow(mat) * (nrow(mat)-1)) * pci
  return(r)
}

est.Wcdf <- function(x, cluster, ri) {
  ####obtain estimates
  #cluster size
  ki <- tabulate(cluster) 
  #effective sample size
  neffi <- ki / (1 + (ki - 1) * ri) 
  #cluster weights
  Pi <- neffi / sum(neffi)
  #individual weights
  pij <- rep(Pi / ki, ki)
  #CDFs of observations
  ef <- CDF.mean(x, pij) 
  #averaged CDF
  avg <- sum(ef * pij) 
  #total variance
  tv <- sum((ef - avg)^2 * pij)  
  cl <- unique(cluster)
  #covariance
  l_l <- tapply(ef - avg, cluster, I) 
  l_p <- as.list(Pi)
  cv <- mapply(CDF.cov, l_l, l_p, USE.NAMES = FALSE) 
  #estimate
  est <- sum(cv) / tv
  
  return(est)
}


mu <- 1
irho <- seq(0,1,0.1);us <- rep(1, length(irho))
rs <- us*(1 - irho)/irho
k <- length(us)
us[rs==Inf] <- 0
rs[rs==Inf] <- 10
us <- log(1/2+sqrt(us*exp(-2*mu) + 1/4))

g <- list()
for(i in seq_along(irho)){
  dat <- generate.data.log(seed = i+1234, n = 100, cluster.limit = c(10, 10), mu = 1, vu = us[i], vr = rs[i])
  g0 <- 6 * asin(irho[i]/2)/pi 
  
  xx <- qnorm(rank(dat$x)/length(dat$x))
  xx[xx==Inf] <- max(xx[xx!=Inf])
  rhoi <- est.lmer(xx, dat$cluster)
  g1 <- 6 * asin(rhoi$icc/2)/pi
  
  cls <- sample(unique(dat$cluster), size = 100, replace = T)
  pairs1 <- pairs2 <- list()
  lx <- tapply(dat$x, dat$cluster, I)
  for(j in seq_along(cls)){
      ix <- lx[[cls[j]]]
      pairs1[[j]] <- sample(ix, 2, replace = T)
      pairs2[[j]] <- sample(ix, 2, replace = F)
  }
  pairs1 <- do.call(rbind, pairs1)
  g2 <- cor(pairs1[,1], pairs1[,2], Methods = "spearman")
  pairs2 <- do.call(rbind, pairs2)
  g3 <- cor(pairs2[,1], pairs2[,2], Methods = "spearman")
  g[[i]] <- c(g0, g1, g2, g3)  
}
g
```

```{r}
load("data/RankICC/gammaLogClmean.RData")
g <- do.call(rbind,g)
r <- g[,4]
r[1] <- 0; r[length(r)] <- 1
r <-  rep(r, 6)
load("data/sim_RankICC_S3.RData")
est <- NULL
std <- NULL
simest <- NULL
mse <- NULL
iterN <- NULL
for(i in 1:length(ans)){
  t <- do.call(rbind,ans[[i]])
  iterN <- rbind(iterN, t[,c(5:6,9:10)])
  t <- t[,c(1:4,7:8)]
  simest <- rbind(simest,t)
  est <- rbind(est, colMeans(t))
  std <- rbind(std, apply(t,2, sd))
  mse <- rbind(mse, apply(t,2, function(x) mean((x-r[i])^2)))
}
est <- as.data.frame(est)
colnames(est) <- c("Equal Obs","Equal Clusters","ESS", "Combo","EC+OPT1","EC+OPT2")
est$pearson <- seq(0,1,0.1)
est$spearman <- 6 * asin(est$pearson/2)/pi
est$size <- rep(c("2","30","2-50","2/30(1)","2/30(2)","2/30(3)"), each = 11)
est <- est %>% gather(key="Methods",value = "EST", "Equal Obs":"EC+OPT2")
est$Methods <- factor(est$Methods, levels = c("Equal Obs","Equal Clusters","ESS","Combo","EC+OPT1","EC+OPT2"))
est$MSE <- c(mse)
est$Std <- c(std) 
est$pb <- (est$EST - est$spearman)/est$spearman * 100
est$size <- factor(est$size, levels = c("2","30","2-50","2/30(1)","2/30(2)","2/30(3)"))
```


```{r s3mse,fig.width=8, fig.height=6}
p <- est %>% filter(Methods %in% c("Equal Obs","Equal Clusters","ESS", "Combo"))
ggplot(p, aes(x=spearman, y=MSE, color=Methods)) + 
  scale_color_manual(values=brewer.pal(4,"Dark2")) +
   geom_point(aes(shape=Methods))+geom_line(aes(linetype=Methods),size=0.4) + facet_wrap(~size, ncol=3) + theme_classic() +
  xlab(TeX("$\\gamma_I$"))+theme(legend.position="top") +
  guides(color = guide_legend(keywidth = 3)) + theme(text = element_text(size=15))
```

```{r s3se,fig.width=8, fig.height=6}
ggplot(p, aes(x=spearman, y=Std, color=Methods)) + 
  scale_color_manual(values=brewer.pal(4,"Dark2")) +
   geom_point(aes(shape=Methods))+geom_line(aes(linetype=Methods),size=0.4) + facet_wrap(~size, ncol=3) + theme_classic() +
 xlab(TeX("$\\gamma_I$"))+ylab("Empirical SE")+theme(legend.position="none")+
    guides(color = guide_legend(keywidth = 5)) + theme(text = element_text(size=15))
```

```{r s3bias,fig.width=8, fig.height=6}
ggplot(p[p$spearman!=0,], aes(x=spearman, y=pb, color=Methods)) + 
  scale_color_manual(values=brewer.pal(4,"Dark2")) +
   geom_point(aes(shape=Methods))+geom_line(aes(linetype=Methods),size=0.4) + facet_wrap(~size, ncol=3) + theme_classic() +
  geom_hline(yintercept=0, linetype="dashed", color = "black")+ 
  geom_hline(yintercept=10, linetype="dashed", color = "black")+
  geom_hline(yintercept=-10, linetype="dashed", color = "black")+ 
  xlab(TeX("$\\gamma_I$"))+ylab("Percent Bias (%)")+theme(legend.position="none")+
      guides(color = guide_legend(keywidth = 5)) + theme(text = element_text(size=15))
```

```{r}
iterN <- as.data.frame(iterN)
colnames(iterN) <- c("EO+OPT1","EO+OPT2","EC+OPT1","EC+OPT2")
iterN$size <- rep(c("2","30","2-50","2/30(1)","2-30(2)","2/30(3)"), each = 11000)
iterN$size <- factor(iterN$size, levels = c("2","30","2-50","2/30(1)","2/30(2)","2/30(3)"))
r <-  6 * asin(seq(0,1,0.1)/2)/pi
iterN$gI <- rep(rep(r, each=1000), 6)
```

There is only one time when the iteration number of EC/EO+OPT1 reached 100 (cluster size=2/30(1), true ICC=0)

```{r s3mseSub,fig.width=6, fig.height=6}
p <- est %>% filter(Methods %in% c("Equal Obs","Equal Clusters","ESS","Combo")) %>% filter(size %in% c("2","30","2-50","2/30(1)"))
ggplot(p, aes(x=spearman, y=MSE, color=Methods)) + 
  scale_color_manual(values=brewer.pal(4,"Dark2")) +
geom_point(aes(shape=Methods))+geom_line(aes(linetype=Methods),size=0.4) + facet_wrap(~size, ncol=2) + theme_classic() +
  xlab(TeX("$\\gamma_I$"))+theme(legend.position="bottom")+
  guides(color = guide_legend(keywidth = 5,nrow=2,byrow=TRUE)) + theme(text = element_text(size=15))
```


```{r s3seSub,fig.width=6, fig.height=6}
ggplot(p, aes(x=spearman, y=Std, color=Methods)) + 
  scale_color_manual(values=brewer.pal(4,"Dark2")) +
geom_point(aes(shape=Methods))+geom_line(aes(linetype=Methods),size=0.4) + facet_wrap(~size, ncol=2) + theme_classic() +
  xlab(TeX("$\\gamma_I$"))+ylab("Empirical SE")+theme(legend.position="bottom")+
    guides(color = guide_legend(keywidth = 5,nrow=2,byrow=TRUE)) + theme(text = element_text(size=15))
```

```{r s3biasSub,fig.width=6, fig.height=6}
ggplot(p[p$spearman!=0,], aes(x=spearman, y=pb, color=Methods)) + 
  scale_color_manual(values=brewer.pal(4,"Dark2")) +
  geom_point(aes(shape=Methods))+geom_line(aes(linetype=Methods),size=0.4) + facet_wrap(~size, ncol=2) + theme_classic() +
  geom_hline(yintercept=0, linetype="dashed", color = "black")+ 
  xlab(TeX("$\\gamma_I$"))+ylab("Percent Bias (%)")+theme(legend.position="bottom")+  guides(color = guide_legend(keywidth = 5,nrow=2,byrow=TRUE)) + theme(text = element_text(size=15))
```


```{r s3extramse,fig.width=6, fig.height=3.5}
p <- est %>% filter(Methods %in% c("Equal Obs","Equal Clusters","ESS","Combo")) %>% filter(size %in% c("2/30(2)","2/30(3)"))
ggplot(p, aes(x=spearman, y=MSE, color=Methods)) + 
  scale_color_manual(values=brewer.pal(4,"Dark2")) +
  geom_point(aes(shape=Methods))+geom_line(aes(linetype=Methods),size=0.4)+ facet_wrap(~size, ncol=2) + theme_classic() +
  xlab(TeX("$\\gamma_I$"))+theme(legend.position="bottom")+  guides(color = guide_legend(keywidth = 5,nrow=2,byrow=TRUE)) + theme(text = element_text(size=15))
```

```{r s3extrase,fig.width=6, fig.height=3.5}
ggplot(p, aes(x=spearman, y=Std, color=Methods)) + 
  scale_color_manual(values=brewer.pal(4,"Dark2")) +
  geom_point(aes(shape=Methods))+geom_line(aes(linetype=Methods),size=0.4) + facet_wrap(~size, ncol=2) + theme_classic() +
  xlab(TeX("$\\gamma_I$"))+ylab("Empirical SE")+theme(legend.position="bottom")+  guides(color = guide_legend(keywidth = 5,nrow=2,byrow=TRUE)) + theme(text = element_text(size=15))
```

```{r s3extrabias,fig.width=6, fig.height=3.5}
ggplot(p[p$spearman!=0,], aes(x=spearman, y=pb, color=Methods)) + 
  scale_color_manual(values=brewer.pal(4,"Dark2")) +
  geom_point(aes(shape=Methods))+geom_line(aes(linetype=Methods),size=0.4) + facet_wrap(~size, ncol=2) + theme_classic() +
  geom_hline(yintercept=0, linetype="dashed", color = "black")+ 
  geom_hline(yintercept=-10, linetype="dashed", color = "black")+
  geom_hline(yintercept=10, linetype="dashed", color = "black")+ 
  xlab(TeX("$\\gamma_I$"))+ylab("Percent Bias (%)")+theme(legend.position="bottom")+  guides(color = guide_legend(keywidth = 5,nrow=2,byrow=TRUE)) + theme(text = element_text(size=15))
```

```{r}
load("data/sim_RankICC_S3.RData")
est <- NULL
std <- NULL
simest <- NULL
mse <- NULL
iterN <- NULL
r <-  6 * asin(rep(seq(0,1,0.1), 6)/2)/pi 
for(i in 1:length(ans)){
  t <- do.call(rbind,ans[[i]])
  iterN <- rbind(iterN, t[,c(5:6,9:10)])
  t <- t[,c(1:4,7:8)]
  simest <- rbind(simest,t)
  est <- rbind(est, colMeans(t))
  std <- rbind(std, apply(t,2, sd))
  mse <- rbind(mse, apply(t,2, function(x) sqrt(mean((x-r[i])^2))))
}
est <- as.data.frame(est)
colnames(est) <-  c("EO","EC","EO+OPT1","EO+OPT2","EC+OPT1","EC+OPT2")
est$pearson <- seq(0,1,0.1)
est$spearman <- 6 * asin(est$pearson/2)/pi
est$size <- rep(c("2","30","2-50","2/30(1)","2/30(2)","2/30(3)"), each = 11)
format_bias_var <- function(idx,a, b){
  t <- NULL
  for(i in seq_along(a)){
    if(b[i] != 0){
      t <- c(t, paste(round(a[i],3), " (", round(std[i,idx],3),", ",
                      round((a[i] - b[i])/b[i]*100,3),"%",
                      ", ",round(mse[i,idx],3),")", sep = ""))}
    else t <- c(t, paste(round(a[i],3), " (", round(std[i,idx],3),
                         ", ","NA%",", ",round(mse[i,idx],3),")",sep=""))
  }
  t
}
est$EO <- format_bias_var(1, est$EO, est$spearman)
est$EC <- format_bias_var(2, est$EC, est$spearman)
est$`EO+OPT1` <- format_bias_var(3, est$`EO+OPT1`, est$spearman)
est$`EO+OPT2` <- format_bias_var(4, est$`EO+OPT2`, est$spearman)
est$`EC+OPT1` <- format_bias_var(5, est$`EC+OPT1`, est$spearman)
est$`EC+OPT2` <- format_bias_var(6, est$`EC+OPT2`, est$spearman)
est <- est[,c("pearson","spearman","EO","EC","EC+OPT1","EC+OPT2")]
colnames(est) <- c("Intraclass Pearson Correlation", "Intraclass Spearman Correlation",  "Equal Observations","Equal Clusters","ESS", "Combo")
rownames(est) <- NULL
est %>% 
  kbl(digits = 3, align = "c", full.width = F) %>% 
  kable_styling(full_width = F) %>%
  add_header_above(c(" "= 2,"Estimates (SD, % Bias, RMSE)"=4)) %>%
  pack_rows("2 obs per cluster", 1, 11) %>%
  pack_rows("30 obs per cluster", 12, 22) %>%
  pack_rows("2-50 obs per cluster", 23, 33) %>%
  pack_rows("2 or 30 obs per cluster", 34, 44) %>% 
  pack_rows("2 or 30 obs per cluster (different within variances and cluster contributions)", 45, 55)  %>% 
  pack_rows("2 or 30 obs per cluster (different within variances but same cluster contributions)", 56, 66) 

```

### Simulations for $\rho_I$ 

- $X_{ij} = U_i + R_{ij}$, where $log(U_i) \stackrel{i.i.d}{\sim} N(\mu,\sigma^2_{logu})$ and $R_{ij} \stackrel{i.i.d}{\sim} N(0,\sigma^2_r)$. We know $\rho_I=corr(X_{ij},X_{ij'})=\frac{\sigma^2_{u}}{\sigma^2_{u}+\sigma^2_r}$, where $\sigma^2_{u}=(exp(\sigma^2_{logu})-1)exp(2\mu+\sigma^2_{logu})$.

- Because $X$ is not normally distributed, $\gamma_I$ may not be $6\text{asin}(\rho_I/2)/\pi$. We consider several ways to assess the true value of $\gamma_I$ through a large sample size ($n=10^6$ and $k_i=100$).

  + Quantiles: The quantiles of the ranked data follow a normal distribution. We can compute $\rho_I$ of the quantiles and then obtain $\gamma_I$ from the $\rho_I$. 
  + Repeated sampling: We randomly draw $10^6$ pairs with replacement from the large data, then calculate the Spearman's correlation. 
  
```{r}
load("data/RankICC/gammaLogClmean.RData")
g <- do.call(rbind,g)
gp <- data.frame("RhoI" = rep(seq(0,1,0.1), 4), "gamma"= c(g), "Methods"=rep(c("6asin(RhoI/2)/pi","Quantiles","Repeated sampling (w/)", "Repeated sampling (w/o)"), each = nrow(g)))
ggplot(data = gp, aes(x = RhoI, y = gamma, color = Methods)) +
  geom_line() + geom_point() + theme_classic()
```


```{r}
colnames(g) <- c("6asin(RhoI/2)/pi", "Quantiles","Repeated sampling (w/)", "Repeated sampling (w/o)")
g %>% kbl(digits = 3, align = "c", full.width = F) %>% 
  kable_styling(full_width = F)             
```

We look at the percent bias of our estimator when $n=100$ and $k_i=30$, for different approximated values of $\gamma_I$.  

```{r}
load("data/sim_RankICC_S3.RData")
est <- NULL
for(i in (nrow(g) + 1):(2*nrow(g))){
  t <- do.call(rbind,ans[[i]])
  est <- c(est, mean(t[,1]))
}
gp$Estimates <- rep(est, 4)
gp$Bias <- (gp$Estimates - gp$gamma)/gp$gamma * 100
ggplot(data = gp[gp$RhoI!=0,], aes(x = RhoI, y = Bias, color = Methods)) +
  geom_line() + geom_point() + theme_classic() + geom_hline(yintercept = 0, linetype="dashed") +
  ylab("% Bias")
```


## Coverage Probability

In this section, we compare asymptotic confidence intervals with bootstrap confidence intervals with respect to coverage probability through simulations.

### Cluster boostrap

There are several methods for bootstrapping clustered data. 

- The cluster bootstrap: clusters are selected by simple random sampling with replacement. 
- The two-stage bootstrap: after selecting clusters as in the randomized cluster bootstrap, observations within clusters are selected by simple random sampling with replacement.
- The reverse two-stage bootstrap: observations within clusters are first selected by simple random sampling with replacement and then clusters are selected by simple random sampling with replacement. With this method, clusters which are selected more than once must contain the same observations each time.

Since the value of the Rank-based ICC is bounded by 0 and 1 (maybe negative in some special cases?), we also can use Fisher transformation to obtain the large-sample confidence interval.   

### Fisher's z transformation 

For a set of sample pairs with an independent and identical bivariate normal distribution, the transformed correlation $z = \frac{1}{2} log(\frac{1+\hat \rho}{1-\hat \rho})$ is approximately normally distributed with mean $\frac{1}{2} log(\frac{1+\rho}{1-\rho})$ and standard error $\frac{1}{\sqrt{N-3}}$, where $N$ is the sample size $\rho$ is the Pearson correlation. 

There are two ways to apply Fisher's z transformation; one is by the delta method, the other is by the effective sample size. 

- With the delta method, we can obtain the SE of the transformed estimate and construct a confidence interval on the transformed scale with normality, then transform the interval back to the original scale. 
- Each cluster has an effective sample size, $n_{effi} = \frac{n_i}{1+(n_i-1) \hat \gamma}$, where $n_i$ is the cluster size. Suppose the data have $k$ independent clusters, the total effective sample size is $n_{eff} = \sum_{i=1}^k n_{effi}$. We use the $n_{eff}$ to obtain the SE of the transformed estimate, which is $\frac{1}{\sqrt{n_{eff}-3}}$, then construct a confidence interval with this SE. 


### Simulations 

#### Scenario I

- $X_{ij} = U_i + R_{ij}$, where $i=1,2,...,100$, $j=1,2,...,30$
- $U_i \stackrel{i.i.d}{\sim} N(1,1)$, for $i=1,2,...,100$
- $R_{ij} \stackrel{i.i.d}{\sim} N(0,1)$, for $i=1,2,...,100$ and $j=1,2,...,30$.
- $\rho = 0.5$, $\gamma=0.48$.
- The number of replicates in a bootstrap is 200. 
- 1000 simulations

```{r}
load("data/RankICC/output-ICC2-kFix-val05.RData")
load("data/RankICC/output-ICC2-Boot200-kFix-val05.RData")

fisherCIef <- function(x, n){
  ki <- 30
  N <- ki/(1+(ki-1)*x) * n 
  l <- log((1+x)/(1-x))/2 - 1.96/sqrt(N-3)#atanh()
  u <- log((1+x)/(1-x))/2 + 1.96/sqrt(N-3)
  l <- (exp(2*l)-1)/(exp(2*l)+1) #tanh()
  u <- (exp(2*u)-1)/(exp(2*u)+1)
  cbind(l,u)
}
fisherCIdelta <- function(x, s){
  tr <- log((1+x)/(1-x))/2 
  ts <- s/((1+x)*(1-x))
  l <- tr - 1.96 * ts
  u <- tr + 1.96 * ts
  l <- (exp(2*l)-1)/(exp(2*l)+1) #tanh()
  u <- (exp(2*u)-1)/(exp(2*u)+1)
  cbind(l,u)
}
n <- c(25, 50, 100, 200, 500, 1000)
r <- 6 * asin(0.5/2)/pi 
lpA <- pA <- matrix(0, ncol = 3, nrow = length(n))
lpB <- pB <- matrix(0, ncol = 4, nrow = length(n))
simest <- matrix(0, ncol = 5, nrow = length(n))
for(i in 1:length(n)){
  t <- output[[i]]
  l <- t[,1] - 1.96 * t[,2]
  u <- t[,1] + 1.96 * t[,2]
  fci1 <- fisherCIef(t[,1], n[i])
  fci2 <- fisherCIdelta(t[,1], t[,2])
  pA[i,] <- c(mean((l<=r)&(r<=u)),
             mean((fci1[,1]<=r)&(r<=fci1[,2])),
             mean((fci2[,1]<=r)&(r<=fci2[,2])))
  lpA[i,] <- c(mean(r<l),
               mean(r<fci1[,1]),
               mean(r<fci2[,1]))
  
  if(n[i] <= 1000){
    tB <- lapply(outputBoot[[i]], function(x){
      c(sd(x[,1]), sd(x[,2]), 
        quantile(x[,1], c(0.025, 0.975)),
        quantile(x[,2], c(0.025, 0.975)))
    })
    tB <- do.call(rbind, tB)
    l1 <- t[,1] - 1.96 * tB[,1]; u1 <- t[,1] + 1.96 * tB[,1]
    l2 <- t[,1] - 1.96 * tB[,2]; u2 <- t[,1] + 1.96 * tB[,2]   
    pB[i,] <- c(mean((l1<=r)&(r<=u1)), 
                mean((l2<=r)&(r<=u2)), 
                mean((tB[,3]<=r)&(r<=tB[,4])),
                mean((tB[,5]<=r)&(r<=tB[,6])))
    
    lpB[i,] <- c(mean(r<l1), 
                mean(r<l2), 
                mean(r<tB[,3]),
                mean(r<tB[,5]))
             
    simest[i, ] <- c((mean(t[,1])-r)/r*100,sd(t[,1]), 
                   mean(t[,2]), mean(tB[,1]), mean(tB[,2]))
  }
  else{
    pB[i,] <- NA
    simest[i, ] <- c((mean(t[,1])-r)/r*100,sd(t[,1]), 
                   mean(t[,2]), NA, NA)
  }
}
df <- data.frame(size=rep(n, ncol(pA)+ncol(pB)),
                 pr=c(pA, pB),
                 Methods=c(rep(c("Asymptotic SE",
                                "Fisher transformation (ESS)",
                                "Fisher transformation",
                                "Bootstrap SE",
                                "Bootstrap SE (Two-stage)",
                                "Bootstrap percentile",
                                "Bootstrap percentile (Two-stage)"),each=length(n)))
                 )

ggplot(df, aes(pr, factor(size), color=Methods)) +
  geom_point() + 
  geom_vline(xintercept = 0.95,linetype="dashed") +
  scale_color_manual(values=c("red","blue","deepskyblue","darkorange3","orange","green","darkgreen")) +
  scale_x_continuous(breaks=seq(0.7,1,0.05),limits=c(0.85,1))+
  xlab("Coverage Probability") + ylab("Sample Size")+
  theme_classic() 

p1 <- df[df$Methods %in% c("Asymptotic SE", "Fisher transformation"),]
```

```{r}
df %>% spread(Methods,pr) %>%
  kbl(digits = 3, align = "c", full.width = F, caption = "Coverage probability") %>% 
  kable_styling(full_width = F)
```


```{r}
simest <- cbind(n,simest)
simest %>%
  kbl(digits = 3, align = "c", full.width = F, col.names = c("Size","Percent Bias (%)","Empirical SE","Averaged Asymptotic SE","Averaged Bootstrap SE", "Averaged Bootstrap SE (two-stage) ")) %>% 
  kable_styling(full_width = F)
```
```{r}
#check for non-coverage at the two tails 
lp <- round(cbind(lpA[,c(1,3)],lpB),3)
rpA <- 1-pA- lpA
rpB <- 1-pB- lpB
rp <- round(cbind(rpA[,c(1,3)],rpB),3)
np <- matrix(NA, ncol = ncol(rp), nrow = nrow(rp))
for(i in 1:nrow(rp)){
  np[i,] <- paste("R=",rp[i,], ", L=",lp[i,], sep="")
}
np <- cbind(n, np)
colnames(np) <- c("Size","Asymptotic SE", "Fisher transformation", "Bootstrap SE",
                                "Bootstrap SE (Two-stage)",
                                "Bootstrap percentile",
                                "Bootstrap percentile (Two-stage)")

np %>%  kbl(digits = 3, position = "c", full.width = F, caption = "Non-coverage at tails") %>% 
  kable_styling(full_width = F)
```




```{r, fig.height=8}
sim_num <- 1000
bootest <- matrix(NA, ncol=3, nrow = sim_num)
par(mfrow=c(3,2))
for(j in seq_along(n)){
  m2 <- m1 <- rep(NA, sim_num)
  for(i in 1:sim_num){
    m1[i] <- median(outputBoot[[j]][[i]][,1])
    m2[i] <- median(outputBoot[[j]][[i]][,2])
  }
  hist(m1, breaks=30, xlab="Bootstrap Median", main = paste("n=",n[j],", Cluster bootstrap",sep=""), xlim=c(0.2,0.7))
  abline(v=r,col="red")
  abline(v=median(m1), col="green")
  
  hist(m2, breaks=30, xlab="Bootstrap Median", main = paste("n=",n[j],", Two-stage bootstrap", sep=""), xlim=c(0.2,0.7))
  abline(v=r,col="red")
  abline(v=median(m2), col="green")
}
```



We increased the number of resamples in a bootstrap from 200 to 1000. 

```{r}
load("data/RankICC/outputBoot1000.RData")
n <- c(25, 50, 100, 200, 500)
r <- 6 * asin(0.5/2)/pi 
lpB <- pB <- matrix(0, ncol = 4, nrow = length(n))
simest <- matrix(0, ncol = 5, nrow = length(n))
for(i in 1:length(n)){
  t <- output[[i]]
  tB <- lapply(outputBoot[[i]], function(x){
      c(sd(x[,1]), sd(x[,2]), 
        quantile(x[,1], c(0.025, 0.975)),
        quantile(x[,2], c(0.025, 0.975)))
    })
  tB <- do.call(rbind, tB)
  l1 <- t[,1] - 1.96 * tB[,1]; u1 <- t[,1] + 1.96 * tB[,1]
  l2 <- t[,1] - 1.96 * tB[,2]; u2 <- t[,1] + 1.96 * tB[,2]   
  pB[i,] <- c(mean((l1<=r)&(r<=u1)), 
                mean((l2<=r)&(r<=u2)), 
                mean((tB[,3]<=r)&(r<=tB[,4])),
                mean((tB[,5]<=r)&(r<=tB[,6])))
  
  lpB[i,] <- c(mean(r<l1), 
                mean(r<l2), 
                mean(r<tB[,3]),
                mean(r<tB[,5]))
  
}
df <- data.frame(size=rep(n, ncol(pB)),
                 pr=c(pB),
                 Methods=c(rep(c("Bootstrap SE",
                                "Bootstrap SE (Two-stage)",
                                "Bootstrap percentile",
                                "Bootstrap percentile (Two-stage)"),each=length(n)))
                 )
# ggplot(df, aes(pr, factor(size), color=Methods)) +
#   geom_point() + 
#   geom_vline(xintercept = 0.95,linetype="dashed") +
#   scale_color_manual(values=c("red","blue","deepskyblue","darkorange3","orange","green","darkgreen")) +
#   scale_x_continuous(breaks=seq(0.7,1,0.05),limits=c(0.85,1))+
#   xlab("Coverage Probability") + ylab("Sample Size")+
#   theme_classic() 
simest <- cbind(n,simest)
df %>% spread(Methods,pr) %>%
  kbl(digits = 3, align = "c", full.width = F, caption = "Coverage probability") %>% 
  kable_styling(full_width = F)
```

```{r}
#check for non-coverage at the two tails 
lp <- round(lpB,3)
rpB <- 1-pB- lpB
rp <- round(rpB,3)
np <- matrix(NA, ncol = ncol(rp), nrow = nrow(rp))
for(i in 1:nrow(rp)){
  np[i,] <- paste("R=",rp[i,], ", L=",lp[i,], sep="")
}
np <- cbind(n, np)
colnames(np) <- c("Size","Bootstrap SE",
                                "Bootstrap SE (Two-stage)",
                                "Bootstrap percentile",
                                "Bootstrap percentile (Two-stage)")

np %>%  kbl(digits = 3, position = "c", full.width = F, caption = "Non-coverage at tails") %>% 
  kable_styling(full_width = F)
```

```{r, fig.height=8}
sim_num <- 1000
bootest <- matrix(NA, ncol=3, nrow = sim_num)
par(mfrow=c(3,2))
for(j in seq_along(n)){
  m2 <- m1 <- rep(NA, sim_num)
  for(i in 1:sim_num){
    m1[i] <- median(outputBoot[[j]][[i]][,1])
    m2[i] <- median(outputBoot[[j]][[i]][,2])
  }
  hist(m1, breaks=30, xlab="Bootstrap Median", main = paste("n=",n[j],", Cluster bootstrap", sep=""), xlim=c(0.2,0.7))
  abline(v=r,col="red")
  abline(v=median(m1), col="green")
  
  hist(m2, breaks=30, xlab="Bootstrap Median", main = paste("n=",n[j],", Two-stage bootstrap", sep=""), xlim=c(0.2,0.7))
  abline(v=r,col="red")
  abline(v=median(m2), col="green")
  
}
```



#### Scenario II Exponentiated X

- $X_{ij} =exp(U_i + R_{ij})$, where $i=1,2,...,100$, $j=1,2,...,30$
- $U_i \stackrel{i.i.d}{\sim} N(1,1)$, for $i=1,2,...,100$
- $R_{ij} \stackrel{i.i.d}{\sim} N(0,1)$, for $i=1,2,...,100$ and $j=1,2,...,30$.
- $\rho_I = 0.5$, $\gamma_I =0.48$.
- 1000 simulations

```{r}
load("data/RankICC/outputSEexp.RData")

fisherCIef <- function(x, n){
  ki <- 30
  N <- ki/(1+(ki-1)*x) * n 
  l <- log((1+x)/(1-x))/2 - 1.96/sqrt(N-3)#atanh()
  u <- log((1+x)/(1-x))/2 + 1.96/sqrt(N-3)
  l <- (exp(2*l)-1)/(exp(2*l)+1) #tanh()
  u <- (exp(2*u)-1)/(exp(2*u)+1)
  cbind(l,u)
}
fisherCIdelta <- function(x, s){
  tr <- log((1+x)/(1-x))/2 
  ts <- s/((1+x)*(1-x))
  l <- tr - 1.96 * ts
  u <- tr + 1.96 * ts
  l <- (exp(2*l)-1)/(exp(2*l)+1) #tanh()
  u <- (exp(2*u)-1)/(exp(2*u)+1)
  cbind(l,u)
}
n <- c(25, 50, 100, 200, 500, 1000)
r <- 6 * asin(0.5/2)/pi 
pA <- matrix(0, ncol = 3, nrow = length(n))
simest <- matrix(0, ncol = 3, nrow = length(n))
for(i in 1:length(n)){
  t <- output[[i]]
  l <- t[,1] - 1.96 * t[,2]
  u <- t[,1] + 1.96 * t[,2]
  fci1 <- fisherCIef(t[,1], n[i])
  fci2 <- fisherCIdelta(t[,1], t[,2])
  pA[i,] <- c(mean((l<=r)&(r<=u)),
             mean((fci1[,1]<=r)&(r<=fci1[,2])),
             mean((fci2[,1]<=r)&(r<=fci2[,2])))
  simest[i,] <- c((mean(t[,1])-r)/r*100,
                  sd(t[,1]),
                  mean(t[,2]))
}
df <- data.frame(size=rep(n, ncol(pA)),
                 pr=c(pA),
                 Methods=c(rep(c("Asymptotic SE",
                                "Fisher transformation (ESS)",
                                "Fisher transformation"),each=length(n)))
                 )
ggplot(df, aes(pr, factor(size), color=Methods)) +
  geom_point() + 
  geom_vline(xintercept = 0.95,linetype="dashed") +
  scale_color_manual(values=c("red","blue","deepskyblue")) +
  scale_x_continuous(breaks=seq(0.7,1,0.05),limits=c(0.85,1))+
  xlab("Coverage Probability") + ylab("Sample Size")+
  theme_classic() 

p2 <- df[df$Methods %in% c("Asymptotic SE", "Fisher transformation"),]
```

```{r}
colnames(simest) <- c("Percent Bias (%)","Empirical SE","Averaged Asymptotic SE")
cbind(df %>% spread(Methods,pr), simest) %>%
  kbl(digits = 3, align = "c", full.width = F) %>% 
  kable_styling(full_width = F)
```

#### Scenario III Extreme values of $\gamma_I$

- $X_{ij} =U_i + R_{ij}$, where $i=1,2,...,100$, $j=1,2,...,30$
- $U_i \stackrel{i.i.d}{\sim} N(1,1)$, for $i=1,2,...,100$
- $R_{ij} \stackrel{i.i.d}{\sim} N(0,9)$, for $i=1,2,...,100$ and $j=1,2,...,30$.
- $\rho_I \in \{0.1,0.9\}$, $\gamma_I \in \{0.096,0.891\}$.
- 1000 simulations


```{r}
load("data/RankICC/output-ICC2-kFix-val01.RData")

fisherCIef <- function(x, n){
  ki <- 30
  N <- ki/(1+(ki-1)*x) * n 
  l <- log((1+x)/(1-x))/2 - 1.96/sqrt(N-3)#atanh()
  u <- log((1+x)/(1-x))/2 + 1.96/sqrt(N-3)
  l <- (exp(2*l)-1)/(exp(2*l)+1) #tanh()
  u <- (exp(2*u)-1)/(exp(2*u)+1)
  cbind(l,u)
}
fisherCIdelta <- function(x, s){
  tr <- log((1+x)/(1-x))/2 
  ts <- s/((1+x)*(1-x))
  l <- tr - 1.96 * ts
  u <- tr + 1.96 * ts
  l <- (exp(2*l)-1)/(exp(2*l)+1) #tanh()
  u <- (exp(2*u)-1)/(exp(2*u)+1)
  cbind(l,u)
}
n <- c(25, 50, 100, 200, 500, 1000)
r <- 6 * asin(0.1/2)/pi 
pA <- matrix(0, ncol = 3, nrow = length(n))
simest <- matrix(0, ncol = 3, nrow = length(n))
for(i in 1:length(n)){
  t <- output[[i]]
  l <- t[,1] - 1.96 * t[,2]
  u <- t[,1] + 1.96 * t[,2]
  fci1 <- fisherCIef(t[,1], n[i])
  fci2 <- fisherCIdelta(t[,1], t[,2])
  pA[i,] <- c(mean((l<=r)&(r<=u)),
             mean((fci1[,1]<=r)&(r<=fci1[,2])),
             mean((fci2[,1]<=r)&(r<=fci2[,2])))
  simest[i,] <- c((mean(t[,1])-r)/r*100,
                  sd(t[,1]),
                  mean(t[,2]))
}
df <- data.frame(size=rep(n, ncol(pA)),
                 pr=c(pA),
                 Methods=c(rep(c("Asymptotic SE",
                                "Fisher transformation (ESS)",
                                "Fisher transformation"),each=length(n)))
                 )
ggplot(df, aes(pr, factor(size), color=Methods)) +
  geom_point() + 
  geom_vline(xintercept = 0.95,linetype="dashed") +
  scale_color_manual(values=c("red","blue","deepskyblue")) +
  scale_x_continuous(breaks=seq(0.7,1,0.05),limits=c(0.85,1))+
  xlab("Coverage Probability") + ylab("Sample Size")+
  theme_classic() + ggtitle(TeX("$\\gamma_I =0.096$"))

p3 <- df[df$Methods %in% c("Asymptotic SE", "Fisher transformation"),]
```

```{r}
colnames(simest) <- c("Percent Bias (%)","Empirical SE","Averaged Asymptotic SE")
cbind(df %>% spread(Methods,pr), simest) %>%
  kbl(digits = 3, align = "c", full.width = F, caption = "Gamma=0.096") %>% 
  kable_styling(full_width = F)
```

```{r}
par(mfrow=c(2,3))
for(i in seq_along(n)){
  x <- output[[i]][,1]
  hist(x,breaks=40, main = paste("n=",n[i],sep=""))
  abline(v=r, col="blue")
}
```

```{r}
load("data/RankICC/output-ICC2-kFix-val09.RData")

n <- c(25, 50, 100, 200, 500, 1000)
r <- 6 * asin(0.9/2)/pi 
pA <- matrix(0, ncol = 3, nrow = length(n))
simest <- matrix(0, ncol = 3, nrow = length(n))
for(i in 1:length(n)){
  t <- output[[i]]
  l <- t[,1] - 1.96 * t[,2]
  u <- t[,1] + 1.96 * t[,2]
  fci1 <- fisherCIef(t[,1], n[i])
  fci2 <- fisherCIdelta(t[,1], t[,2])
  pA[i,] <- c(mean((l<=r)&(r<=u)),
             mean((fci1[,1]<=r)&(r<=fci1[,2])),
             mean((fci2[,1]<=r)&(r<=fci2[,2])))
  simest[i,] <- c((mean(t[,1])-r)/r*100,
                  sd(t[,1]),
                  mean(t[,2]))
}
df <- data.frame(size=rep(n, ncol(pA)),
                 pr=c(pA),
                 Methods=c(rep(c("Asymptotic SE",
                                "Fisher transformation (ESS)",
                                "Fisher transformation"),each=length(n)))
                 )
ggplot(df, aes(pr, factor(size), color=Methods)) +
  geom_point() + 
  geom_vline(xintercept = 0.95,linetype="dashed") +
  scale_color_manual(values=c("red","blue","deepskyblue")) +
  scale_x_continuous(breaks=seq(0.7,1,0.05),limits=c(0.85,1))+
  xlab("Coverage Probability") + ylab("Sample Size")+
  theme_classic() + ggtitle(TeX("$\\gamma_I =0.891$"))

p4 <- df[df$Methods %in% c("Asymptotic SE", "Fisher transformation"),]
```

```{r}
colnames(simest) <- c("Percent Bias (%)","Empirical SE","Averaged Asymptotic SE")
cbind(df %>% spread(Methods,pr), simest) %>%
  kbl(digits = 3, align = "c", full.width = F, caption = "Gamma=0.891") %>% 
  kable_styling(full_width = F)
```

```{r}
par(mfrow=c(2,3))
for(i in seq_along(n)){
  x <- output[[i]][,1]
  hist(x,breaks=40, main = paste("n=",n[i],sep=""))
  abline(v=r, col="blue")
}
```


```{r, fig.height=6, fig.width=6}
lbs <- c("0.48","0.48, Y=exp(X)", "0.096","0.891")
p <- cbind(rbind(p1,p2,p3,p4),rep(lbs, each = nrow(p1)))
colnames(p)[4] <- "Type"
ggplot(p, aes(pr, factor(size), color=Methods)) +
  geom_point() + 
  facet_wrap(~ Type, ncol=2) +
  geom_vline(xintercept = 0.95,linetype="dashed") +
  scale_color_manual(values=c("red","blue","deepskyblue")) +
  scale_x_continuous(breaks=seq(0.7,1,0.05),limits=c(0.85,1))+
  xlab("Coverage Probability") + ylab("Sample Size")+
  theme_classic() + theme(legend.position="bottom")
```


# Three-level data 

Suppose we have three-level data of students nested within classrooms, nested within schools. A hierarchical model for the three-level structure can be $X_{ijk} = U_i + V_{ij} + R_{ijk}$. The variances at the school, classroom and student level are respectively, $\sigma_u^2$, $\sigma_v^2$, and $\sigma_r^2$. There are two methods to define intraclass correlation.   

The first method (Davis & Scoot, 1995) defines the ICC at the classroom and school level as
$\rho_{class} = \frac{\sigma_v^2}{\sigma_u^2+\sigma_v^2+\sigma_r^2}$, $\rho_{school} = \frac{\sigma_u^2}{\sigma_u^2+\sigma_v^2+\sigma_r^2}$. This method identifies the proportion of variance at the class and school level. It can be used if we are interested in a decomposition of the variance. 

The second method (Siddiqui, Hedeker, Flay & Hu, 1996) the ICC at the classroom and school level as $\rho_{class} = \frac{\sigma_u^2 + \sigma_v^2}{\sigma_u^2+\sigma_v^2+\sigma_r^2}$, $\rho_{school} = \frac{\sigma_u^2}{\sigma_u^2+\sigma_v^2+\sigma_r^2}$. This method evaluates the correlation between two randomly chosen students in the same classroom or school.  

These two methods are equivalent for two-level data. 


## Intraclass correlation

For three-level nested data, there are level-1 units (the innermost), level-2 units, and level-3 units. Let $i$ denote the index of a level-3 unit, $j$ denote the index of a level-2 unit, $k$ denote the index of a level-1 unit. 

Suppose $X$ is the variable of interest, let $X_{ijk}$ denote an observation of the $k$th level-1 unit in the $j$th level-2 unit and the $i$th level-3 unit. Then we have, 
$$X_{ijk} = U_i + V_{ij} + R_{ijk}$$
where $U_i$ is the mean for the $i$th level-3 unit, $V_{ij}$ is the deviation from $U_i$ of the $j$th level-2 unit with $E[V_{ij}]=0$, $R_{ijk}$ is the deviation from $U_i+V_{ij}$ of the $k$th level-1 unit with $E[R_{ijk}]=0$, $U_i \perp V_{ij} \perp R_{ij}$. Let $\sigma^2_u$, $\sigma^2_v$, $\sigma^2_r$ denote the variances of $U_i$, $V_{ij}$, $R_{ijk}$ respectively. We have two types of intraclass correlation. 

- Correlation between a random level-1 pair from the same level-2 unit and the same level-3 
unit.

$$\rho_I(\text{same level-3 and level-2}) = corr(X_{ijk},X_{ijk'}) = \frac{\sigma^2_u+\sigma^2_v}{\sigma^2_u+\sigma^2_v + \sigma^2_r}$$

It is equal to the correlation when we treat the clustered data as two-level; the inner level is the level-1 unit, the outer level is the level-2 unit.  


- Correlation between a random level-1 pair from the same level-3 unit.

$$\rho_I(\text{same level-3}) = corr(X_{ijk},X_{ij'l}) = \frac{\sigma^2_u}{\sigma^2_u+\sigma^2_v + \sigma^2_r} \text{, where }  j \text{   can be equal to    } j' \text{, } k \neq l \text{ when } j=j'$$

This is for infinite samples. 


- Correlation between a random level-1 pair from the same level-3 unit but different level-2 units

$$\rho_I(\text{same level-3 and different level-2}) = corr(X_{ijk},X_{ij'l})=\frac{\sigma^2_u}{\sigma^2_u+\sigma^2_v + \sigma^2_r} \text{, where } j \neq j'$$ 


## Population parameters of Rank-based ICC 

- The correlation between a random pair from the same level-2 unit and level-3 unit. 
$$\gamma_1 = \gamma_I(\text{level-3, level-2}) = corr[F(X_{ijk}), F(X_{ijk'})] \text{, where } k \neq k'$$

- The correlation between a random pair from different level-2 units but the same level 3 unit. 
$$\gamma_2 = \gamma_I(\text{same level-3 and different level-2}) = corr[F(X_{ijk}), F(X_{ij'l})] \text{, where }  j \neq j'$$
- The correlation between a random pair from the same level 3 unit. 
$$\gamma_3 = \gamma_I(\text{same level-3}) = corr[F(X_{ijk}), F(X_{ij'l})] \text{, where }  j \text{   can be equal to    } j' \text{ and } k \neq l \text{ when } j=j'$$
$\gamma_3$ might be expressed in terms of $\gamma_1$ and $2$,

$$\begin{align} \gamma_3 & = corr[F(X_{ijk}), F(X_{ij'l})] \\
& = cov(F(X_{ijk}), F(X_{ij'l}))/var(F) \\
& = cov(F(X_{ijk}), F(X_{ij'l}) | j \neq j')P(j \neq j')/var(F) + cov(F(X_{ijk}), F(X_{ij'l}) | j = j')P(j = j')/var(F)\\
& = \gamma_2P(j \neq j') + \gamma_1P(j = j')
\end{align}$$

Suppose we have balanced data for a level 3 unit, which has $k$ level 2 units and $n$ observations in each level 2 units. The probability that randomly choosing two observations and they are from the same level 2 unit is $P(j = j') = (C^1_kC_n^2)/(C_{nk}^2) = (n-1)/(nk-1)$. 
 
## Estimation 

Suppose we have three-level nested data $\{x_{ijk}; i=1,...,N,\;j=1,...,n_i,\;k=1,...,m_{ij}\}$, the total number of observations is $\sum_{i=1}^n\sum_{j=1}^{m_i} m_{ij}$, where $N$ is the number of distinct level-3 units, $n_i$ is the number of distinct level-2 units in the $i$th level-3 unit, $m_{ij}$ is the number of level-1 units in the $i$th level-2 unit and $j$th level-3 unit.  


### $\gamma_1$ Correlation between a random pair from the same level-2 unit and level-3 unit. 

We can use the estimation method for two-level data, treating level-1 units as individuals and level-2 units as clusters.  


### $\gamma_2$ Correlation between a random pair from the same level-2 unit and level-3 unit. 

For the three-level nested data, we denote $p_{i..}$ as the probability of the $i$th level-3 unit, $p_{ij.}$ as the probability of the $j$th level-2 unit in the $i$th level-3 unit, $p_{ijk}=p_{ij.}/m_{ij}$ as the probability of the $k$th level-1 unit in the $j$th level-2 unit and the $i$th level-3 unit. $\sum_{j=1}^{n_i} p_{ij.}=p_{i..}$ and $\sum_{i=1}^N p_{i..}=1$. 

The nonparametric estimator for the cumulative probability function is $\hat F(x) = \sum_{i=1}^N \sum_{j=1}^{n_i} \sum_{k=1}^{m_{ij}} p_{ijk}I(x_{ijk} \leq x)$. Similarly,$\hat F(x^-) = \sum_{i=1}^N \sum_{j=1}^{n_i} \sum_{k=1}^{m_{ij}} p_{ijk}I(x_{ijk} < x)$. To simplify the denotation, we denote $\{\hat F(x) + \hat F(x-)\}/2$ as $\hat F^*(x)$. 

Similar to the estimation for two levels, we pool the data to estimate the mean and variance. The total variance is estimated by $\sum_{i=1}^N \sum_{j=1}^{n_i} \sum_{k=1}^{m_{ij}} p_{ijk} [\hat F^*(x_{ijk}) - \bar F^*]^2$, where $\bar F^* = \sum_{i=1}^N \sum_{j=1}^{n_i} \sum_{k=1}^{m_{ij}} p_{ijk} \hat F^* (x_{ijk})$. There are $w_{i}=\{(\sum_{j=1}^{n_i} m_{ij})^2-(\sum_{j=1}^{n_i}  m_{ij}^2)\}/2$ combinations of unordered pairs in a level-3 unit. Then, the covariance is estimated by $\sum_{i=1}^N \frac{2p_{i..}}{w_i}  \sum_{j=1}^{n_i-1}\sum_{j'=j+1}^{n_i} \sum_{k=1}^{m_{ij}} \sum_{l=1}^{m_{ij'}}[\hat F^*(x_{ijk}) - \bar F^*][\hat F^*(x_{ij'l}) - \bar F^*]$.

The general form of the estimator is
$$\hat \gamma_2 = \frac{\sum_{i=1}^N \frac{p_{i..}}{w_i}  \sum_{j=1}^{n_i-1}\sum_{j'=j+1}^{n_i} \sum_{k=1}^{m_{ij}} \sum_{l=1}^{m_{ij'}}[\hat F^*(x_{ijk}) - \bar F^*][\hat F^*(x_{ij'l}) - \bar F^*]}{\sum_{i=1}^N \sum_{j=1}^{n_i} \sum_{k=1}^{m_{ij}} p_{ijk} [\hat F^*(x_{ijk}) - \bar F^*]^2}$$
If $m_{ij}=1$, this estimator is equal to the estimator for two-level data. 


Sides: the estimation above assigns equal weights to random pairs in a level-3 unit. Or we can think about adjusting the weights by level-3 and level-2 sizes (although it may not make good sense), i.e. the covariance can be estimated by $\sum_{i=1}^N \frac{2p_{i..}}{n_i(n_i-1)}  \sum_{j<j'} \frac{1}{m_{ij}m_{ij'}}\sum_{k=1}^{m_{ij}} \sum_{l=1}^{m_{ij'}}[\hat F^*(x_{ijk}) - \bar F^*][\hat F^*(x_{ij'l}) - \bar F^*]$. When level-2 sizes (the number of level-1 units in a level-2 unit, $m_{ij}=m_{ij'}$) are equal in a level-3 unit, the two weighting methods are equivalent. 


### Optimization for $p_{ijk}$

We optimize the probabilities of level-3 units using effective sample size. For a level-3 unit, the variance of the sample mean is proportional to the population variance. The proportion is $n_{effi}$ for the $i$th level-3 unit, $n_{effi} = N_i^2/\{N_i(1-\gamma_1+\gamma_2N_i)+(\gamma_1-\gamma_2)\sum_{j=1}^{n_i}m_{ij}^2\}$, where $N_i$ is the number of level-1 units in the $i$th level-3 unit, $\rho_1$ is the correlation between level-1 units in the same level-2 unit, $\rho_2$ is the correlation between level-1 units in different level-2 units. Then we have the probability for a level-3 unit $p_{i..} = n_{effi}/\{\sum_{i=1}^Nn_{effi}\}$

To obtain the probabilities for level-2 units, we again use effective sample size in a level-2 unit, which is similar to the one in the two-level estimation. For a level-2 unit, the effective sample size is $n_{effij} = m_{ij}/\{1+(m_{ij}-1)\gamma_1\}$. Thus, the probability for a level-2 unit is $p_{ij.} = p_{i..}n_{effij}/\{\sum_{j=1}^{n_i}n_{effij}\}$, the probability for a level-1 unit is $p_{ijk}=p_{ij.}/m_{ij}$. When $\gamma_1=1$,level-2 units in the same level-3 unit have the same probability. When $\gamma_1=0$, level-2 units in the same level-3 unit have probabilities proportional to their sizes. When $\gamma_1=1$ and $\gamma_2=1$, level-3 units have the same probability. When $\gamma_1=0$ and $\gamma_2=0$, the probabilities of level-2 and level-3 units depends on their numbers of level-1 units. That is, all level-1 units have the same probability in this scenario. 

To implement the optimization, we first obtain $\hat \gamma_1$ through the two-level estimation, then start with an initial value of $\gamma_2$ together with $\hat \gamma_1$ to get probabilities for the three levels and obtain the first estimate of $\gamma_2$, continue the previous step until the estimate converges (i.e., the absolute difference between the previous and the present one is smaller than the pre-set tolerance). 


### $\gamma_3$ Correlation between a random pair from the same level 3 unit. 

Again use the estimation method for two-level data, treating level-1 units as individuals and the level-3 units as clusters.  


```{r, eval=F}
generate.data.multi <- function(seed=1234, n1=c(10,10), n2=c(10,10), n3=30, mu=1, v1=1, v2=1, v3=1){
  set.seed(seed)
  #cluster size
  if(n2[1] == n2[2]){
        size <- rep(n2[1], n3)
        }else size <- replicate(n3, sample(n2[1]:n2[2], 1))
  u <- rnorm(n3, mean = mu, sd = sqrt(v3))
  dat <- NULL
  for(i in 1:n3){
    dsub <- generate.data(seed, n=size[i], cluster.limit=n1, mu=u[i], vu=v2, vr=v1, hlf=F)
    colnames(dsub)[2] <- "level2"
    dsub$level3 <- i
    dat <- rbind(dat, dsub)
  }
  dat$level3 <- as.factor(dat$level3)
  return(dat)
}

aggrMean <- function(mat,cluster){
    cluster <- as.factor(as.character(cluster))
    ucl <- unique(cluster)
    nid <- ncol(mat)
    nucl <- length(ucl)
    out <- matrix(NA, nucl, nid)
    for (i in 1:nucl){
      nl = sum(cluster == ucl[i])
      out[i,] <- colMeans(matrix(mat[cluster == ucl[i],], nrow = nl)) 
    }
    out
}
aggrCDF <- function(m, type){
  mat <- outer(m,m, "*")
  s <- sum(mat) - sum(diag(mat))
  if(type=="EC") r <- s / (nrow(mat) * (nrow(mat)-1))
  if(type=="EI") r <- s / (nrow(mat)-1)
  return(r)
}

pair.diff.cdf <- function(level2, x, pi){
   level2 <- as.factor(as.character(level2))
   mat <- outer(x,x, "*")
   s <- 0
   mi <- length(level2)
   for(i in seq_along(level2)){
     cl <- level2[i]
     s <- s + sum(mat[level2 != cl, i])     
   }
   kij <- table(level2)
   w <- sum((mi - kij) * kij)
   s <- s * pi / w
   return(s)
}

CDF.mean <- function(x, pij){
  mat <- outer(x, x, "<=")
  ef <- t(mat) %*% pij
  mat <- outer(x, x, "<")
  ef <- (ef + t(mat) %*% pij)/2
  ef
}

est.cdf.multi <- function(x, level2, level3, r1=0, r2=0){
  dat <- data.frame("x"=x, "level2"=level2, "level3"=level3)
  dat <- dat %>% group_by(level3) %>% 
                 mutate(ki=n()) %>% 
                 group_by(level3, level2) %>% 
                 mutate(kij=n()) %>%
                 distinct(level3, level2, .keep_all=T) %>% 
                 group_by(level3) %>%
                 mutate(sumkij2=sum(kij^2)) %>%
                 select(level3, level2, sumkij2, ki, kij) %>% 
                 right_join(dat, by=c("level3","level2")) %>% 
                 group_by(level3) %>% 
                 mutate(wi=(ki^2)/(ki+(r1-r2)*sumkij2+r2*ki^2-r1*ki),
                        wij=kij/(1+(kij-1)*r1))
  sumwi <- sum(dat %>% distinct(level3, .keep_all=T) %>% pull(wi))
  dat <- dat %>% distinct(level3, level2, .keep_all=T) %>% 
    group_by(level3) %>%
    mutate(sumwij=sum(wij)) %>%   
    select(level3, level2, sumwij) %>% 
    right_join(dat, by=c("level3","level2")) %>% 
    mutate(pi=wi/sumwi, pij=pi*wij/sumwij, pijk=pij/kij)
  dat$ef <- CDF.mean(dat$x, dat$pijk)
  avg <- sum(dat$ef * dat$pijk)
  tv <- sum((dat$ef - avg)^2 * dat$pijk)
  cv <- sapply(unique(dat$level3), function(i){
    cls <- dat[dat$level3==i,]$level2
    x <- as.vector(dat[dat$level3==i,]$ef - avg)
    pi <- unique(dat[dat$level3==i,]$pi)
    pair.diff.cdf(cls, x, pi)
    })
  ri <- sum(cv)/tv
  return(ri)
}

est.iter.multi <- function(x, l2, l3, r1=0, r2=0, tol=1e-5, maxIter=100){
  i <- 0; d <- 10
  while(i < maxIter & d > tol){
    rnew <- est.cdf.multi(x, l2, l3, r1, r2)
    d <- abs(rnew - r2)
    r2 <- rnew
    i <- i + 1
  }
  c(r2, i)
}
```


## Simulations

 
- $N$ is the number of level 3 units (e.g. schools), $n_i$ is the number of level 2 units (e.g. classrooms) in the $i$th level 3 unit, $m_{ij}$ is the number of level 1 units (e.g. students) in the $j$ 
- $X_{ij} = U_i + V_{ij} + R_{ijk}$, where $i=1,2,...,N$, $j=1,2,...,n_i$, $k=1,..,m_{ij}$.
- $U_i \stackrel{i.i.d}{\sim} N(1,\sigma^2_u)$, for $i=1,2,...,N$
- $V_{ij} \stackrel{i.i.d}{\sim} N(0,\sigma^2_v)$, for $i=1,2,...,N$ and $j=1,2,...,n_i$.
- $R_{ijk} \stackrel{i.i.d}{\sim} N(0,\sigma^2_r)$, for $i=1,2,...,N$, $j=1,2,...,n_i$, $k=1,..,m_{ij}$.
- $\rho_1 = \frac{\sigma^2_u+\sigma^2_v}{\sigma^2_u+\sigma^2_v+\sigma^2_r}$, $\rho_2=\rho_3 = \frac{\sigma^2_u}{\sigma^2_u+\sigma^2_v+\sigma^2_r}$
- $(\rho_1,\rho_2) \in \{(0,0), (0.25,0.2), (0.55, 0.2), (0.85, 0.2), (0.55, 0.5), (0.85, 0.5), (0.85, 0.8), (1,1)\}$
- 1000 simulations

### ($N=100, n_i=15, m_{ij}=2$)


$\gamma_3 = \gamma_2P(j \neq j') + \gamma_1P(j = j') =  \gamma_2\times\frac{28}{29}+ \gamma_1\times \frac{1}{29}$


```{r}
load("data/RankICC/output3combo.RData")
v3s <- c(0, 4, 4, 4, 10, 10, 16, 2)
v2s <- c(0, 1, 7, 13, 1, 7, 1, 0)
v1s <- c(1, 15, 9, 3, 9, 3, 3, 0)
r2 <- v3s / (v3s + v2s + v1s)
r1 <- (v3s + v2s) / (v3s + v2s + v1s)
r2 <- 6 * asin(r2/2)/pi 
r1 <- 6 * asin(r1/2)/pi 
r3 <- r2 * 28 / 29 + r1 / 29
mest <- std <- mse <- pb <- matrix(NA, ncol = 3, nrow = length(r2))
pb3 <- rep(NA, length(r2))
for(i in seq_along(r2)){
  ans <- output[[i]]
  r <- c(r1[i], r2[i], r3[i])
  mest[i,] <- est <- colMeans(ans)
  pb[i, ] <- (est - r)/r * 100
  pb3[i] <- (est[3] - r2[i])/r2[i] * 100
  mse[i,] <- sapply(1:3, function(x) mean((ans[,x] - r[x])^2))
  std[i,] <- sapply(1:3, function(x) sd(ans[,x]))
}
output <- matrix(NA, ncol = 3, nrow = length(r2))
for(i in 1:3){
  m <- round(mest[,i], 3)
  p <- paste(round(pb[,i],2),"%",sep="")
  s <- round(std[,i], 3)
  ms <- round(mse[,i], 3)
  output[,i] <- paste(m, " (", p,", ", ms,", ",s,")",sep="")
}
output <- cbind(round(r1,3),round(r2,3), round(r3,3),output,paste(round(pb3,2),"%",sep=""))
colnames(output) <- c("Gamma 1", "Gamma 2", "Gamma 3 (Calculated from Gamma 1 & 2)", "EST Gamma 1", "EST Gamma 2", "EST Gamma 3", "% Bias of EST Gamma 3 (True is Gamma 2)")
t1 <- cbind(r1,mest[,1], pb[,1],  std[,1], mse[,1],r2,
            mest[,2], pb[,2], std[,2], mse[,2])
output %>% kbl(align = "c", full.width = F) %>% 
  kable_styling(full_width = F) %>%
  add_header_above(c(" "= 3,"Averaged EST (% Bias, MSE, SE)"=3, " "=1)) 
```


```{r}
# Given $\gamma_3 = \gamma_2P(j \neq j') + \gamma_1P(j = j') =  \gamma_2\times\frac{28}{29}+ \gamma_1\times \frac{1}{29}$, we can obtain $\hat \gamma_3$ from $\hat \gamma_1$ and $\hat \gamma_2$.
# load("data/RankICC/output3combo.RData")
# simest <- list()
# for(i in seq_along(r2)){
#   ans <- output[[i]]
#   simest[[i]] <- cbind(ans[,1]/29 + ans[,2]*28/29, ans[,3])
# }
# simest <- as.data.frame(do.call(rbind, simest))
# colnames(simest) <- c("EST Gamma 3 from EST Gamma 1 and 2", "EST Gamma 3")
# r3 <- paste("(",round(r1,3),",", round(r2, 3), ")",sep="")
# simest$Type <- rep(r3, each = 1000)
# ggplot(simest, aes(`EST Gamma 3 from EST Gamma 1 and 2`, `EST Gamma 3`, color = Type)) +
#   geom_point() +
#   scale_color_manual(values=alpha(brewer.pal(12,"Paired")[1:8], 0.8))+
#   facet_wrap( ~ Type, ncol=4)+
#   geom_abline(intercept = 0, slope = 1, lty="dashed")+
#   theme_classic()+
#   theme(legend.position="none")
```


### ($N=100, n_i=2, m_{ij}=15$)

$\gamma_3 = \gamma_2P(j \neq j') + \gamma_1P(j = j') =  \gamma_2\times\frac{15}{29}+ \gamma_1\times \frac{14}{29}$

Note: EST Gamma 3 was obtained by the two-level estimation ignoring the level 2. The second EST Gamma 3 was the weighted sum of EST Gamma 1 and 2. 

```{r}
load("data/RankICC/output3combo15-2.RData")
v3s <- c(0, 4, 4, 4, 10, 10, 16, 2)
v2s <- c(0, 1, 7, 13, 1, 7, 1, 0)
v1s <- c(1, 15, 9, 3, 9, 3, 3, 0)
r2 <- v3s / (v3s + v2s + v1s)
r1 <- (v3s + v2s) / (v3s + v2s + v1s)
r2 <- 6 * asin(r2/2)/pi 
r1 <- 6 * asin(r1/2)/pi 
r3 <- r2 * 15 / 29 + r1 * 14 / 29
mest <- std <- mse <- pb <- matrix(NA, ncol = 4, nrow = length(r2))
pb3 <- rep(NA, length(r2))
for(i in seq_along(r2)){
  ans <- output[[i]]
  ans <- cbind(ans, ans[,1] * 14 / 29 + ans[,2] * 15 / 29)
  r <- c(r1[i], r2[i], r3[i], r3[i])
  mest[i,] <- est <- colMeans(ans)
  pb[i, ] <- (est - r)/r * 100
  pb3[i] <- (est[3] - r2[i])/r2[i] * 100
  mse[i,] <- sapply(1:4, function(x) mean((ans[,x] - r[x])^2))
  std[i,] <- sapply(1:4, function(x) sd(ans[,x]))
}
output <- matrix(NA, ncol = 4, nrow = length(r2))
for(i in 1:4){
  m <- round(mest[,i], 3)
  p <- paste(round(pb[,i],2),"%",sep="")
  s <- round(std[,i], 3)
  ms <- round(mse[,i], 3)
  output[,i] <- paste(m, " (", p,", ", ms,", ",s,")",sep="")
}
output <- cbind(round(r1,3),round(r2,3), round(r3,3),output,paste(round(pb3,2),"%",sep=""))
colnames(output) <- c("Gamma 1", "Gamma 2", "Gamma 3 (Calculated from Gamma 1 & 2)", "EST Gamma 1", "EST Gamma 2", "EST Gamma 3", "EST Gamma 3 calculated from EST Gamma 1 & 2", "% Bias of EST Gamma 3 (True is Gamma 2)")
t2 <- cbind(r1,mest[,1], pb[,1],  std[,1], mse[,1],r2,
            mest[,2], pb[,2], std[,2], mse[,2])
output %>% kbl(align = "c", full.width = F) %>% 
  kable_styling(full_width = F) %>%
  add_header_above(c(" "= 3,"Averaged EST (% Bias, MSE, SE)"=4, " "=1)) 
```



### ($N=100, n_i=4, m_{ij}=2$)


$\gamma_3 = \gamma_2P(j \neq j') + \gamma_1P(j = j') =  \gamma_2\times\frac{6}{7}+ \gamma_1\times \frac{1}{7}$

```{r}
load("data/RankICC/output3combo2-4.RData")
v3s <- c(0, 4, 4, 4, 10, 10, 16, 2)
v2s <- c(0, 1, 7, 13, 1, 7, 1, 0)
v1s <- c(1, 15, 9, 3, 9, 3, 3, 0)
r2 <- v3s / (v3s + v2s + v1s)
r1 <- (v3s + v2s) / (v3s + v2s + v1s)
r2 <- 6 * asin(r2/2)/pi 
r1 <- 6 * asin(r1/2)/pi 
r3 <- r2 * 6 / 7 + r1 * 1 / 7
mest <- std <- mse <- pb <- matrix(NA, ncol = 4, nrow = length(r2))
pb3 <- rep(NA, length(r2))
for(i in seq_along(r2)){
  ans <- output[[i]]
  ans <- cbind(ans, ans[,1] * 1 / 7 + ans[,2] * 6 / 7)
  r <- c(r1[i], r2[i], r3[i], r3[i])
  mest[i,] <- est <- colMeans(ans)
  pb[i, ] <- (est - r)/r * 100
  pb3[i] <- (est[3] - r2[i])/r2[i] * 100
  mse[i,] <- sapply(1:4, function(x) mean((ans[,x] - r[x])^2))
  std[i,] <- sapply(1:4, function(x) sd(ans[,x]))
}
output <- matrix(NA, ncol = 4, nrow = length(r2))
for(i in 1:4){
  m <- round(mest[,i], 3)
  p <- paste(round(pb[,i],2),"%",sep="")
  s <- round(std[,i], 3)
  ms <- round(mse[,i], 3)
  output[,i] <- paste(m, " (", p,", ", ms,", ",s,")",sep="")
}
output <- cbind(round(r1,3),round(r2,3), round(r3,3),output,paste(round(pb3,2),"%",sep=""))
colnames(output) <- c("Gamma 1", "Gamma 2", "Gamma 3 (Calculated from Gamma 1 & 2)", "EST Gamma 1", "EST Gamma 2", "EST Gamma 3", "EST Gamma 3 calculated from EST Gamma 1 & 2", "% Bias of EST Gamma 3 (True is Gamma 2)")

t3 <- cbind(r1,mest[,1], pb[,1],  std[,1], mse[,1],r2,
            mest[,2], pb[,2], std[,2], mse[,2])

output %>% kbl(align = "c", full.width = F) %>% 
  kable_styling(full_width = F) %>%
  add_header_above(c(" "= 3,"Averaged EST (% Bias, MSE, SE)"=4, " "=1)) 
```


```{r}
# t <- rbind(t1,t2,t3)
# dg <- rep(c(rep(3,4),4),2)
# t <- sapply(1:ncol(t), function(x) round(t[,x],dg[x]))
# t <- cbind(rep(1:3, each = 8), t)
# colnames(t) <- c("(ni,mij)",rep(c("truth","est","bias","emp.SE","MSE"),2))
# knitr::kable(t) %>%  collapse_rows(columns = 1, valign = "top") %>% 
#   add_header_above(c(" "=1, "g2" = 5, "g3" = 5)) 
```




## Inference

- Use bootstrap SE or percentiles to construct confidence intervals with bootstrap. We consider two ways of bootstrapping; randomly sample with replacement only at level 3 (cluster bootstrap), randomly sample with replacement at all the levels (three-stage bootstrap). 
- First randomly choose a level 1 unit for each level 2 unit and transform the three-level data into two-level data. Then calculate the asymptotic SE of the two-level data and construct confidence intervals.

### Simulations

- $X_{ij} = U_i + V_{ij} + R_{ijk}$, where $i=1,2,...,100$, $j=1,2,...,15$, $k=1,2$. 
- $U_i \stackrel{i.i.d}{\sim} N(1,\sigma^2_u)$, for $i=1,2,...,100$
- $V_{ij} \stackrel{i.i.d}{\sim} N(0,\sigma^2_v)$, for $i=1,2,...,100$ and $j=1,2,...,15$.
- $\rho_1=2/3$, $\rho_2=0.5$
- 200 replicates for each bootstrap  
- 1000 simulations


```{r}
load("data/RankICC/outputSE3levels.RData")
load("data/RankICC/outputBoot3levels200.RData")
fisherCIdelta <- function(x, s){
  tr <- log((1+x)/(1-x))/2 
  ts <- s/((1+x)*(1-x))
  l <- tr - 1.96 * ts
  u <- tr + 1.96 * ts
  l <- (exp(2*l)-1)/(exp(2*l)+1) #tanh()
  u <- (exp(2*u)-1)/(exp(2*u)+1)
  cbind(l,u)
}
n <- c(25, 50, 100, 200, 500, 1000)
r <- 6 * asin(0.5/2)/pi 
pA <- matrix(0, ncol = 2, nrow = length(n))
pB <- matrix(0, ncol = 4, nrow = length(n))
simest <- matrix(0, ncol = 5, nrow = length(n))
for(i in 1:length(n)){
  t <- output[[i]]
  #one replication 
  l <- t[,1] - 1.96 * t[,2]
  u <- t[,1] + 1.96 * t[,2]
  fci <- fisherCIdelta(t[,1], t[,2])
  pA[i,] <- c(mean((l<=r)&(r<=u)),
             mean((fci[,1]<=r)&(r<=fci[,2])))
  if(n[i] <= 1000){
    tB <- lapply(outputBoot[[i]], function(x){
      c(sd(x[,1]), sd(x[,2]), 
        quantile(x[,1], c(0.025, 0.975)),
        quantile(x[,2], c(0.025, 0.975)))
    })
    tB <- do.call(rbind, tB)
    l1 <- t[1:(186*5),1] - 1.96 * tB[,1]; u1 <- t[1:(186*5),1] + 1.96 * tB[,1]
    l2 <- t[1:(186*5),1] - 1.96 * tB[,2]; u2 <- t[1:(186*5),1] + 1.96 * tB[,2]   
    pB[i,] <- c(mean((l1<=r)&(r<=u1)), 
                mean((l2<=r)&(r<=u2)), 
                mean((tB[,3]<=r)&(r<=tB[,4])),
                mean((tB[,5]<=r)&(r<=tB[,6])))
    simest[i, ] <- c((mean(t[,1])-r)/r*100,sd(t[,1]), 
                   mean(t[,2]), mean(tB[,1]), mean(tB[,2]))
  }
  else{
    pB[i,] <- NA
    simest[i, ] <- c((mean(t[,1])-r)/r*100,sd(t[,1]), 
                   mean(t[,2]), NA, NA)
  }
}
df <- data.frame(size=rep(n, ncol(pA)+ncol(pB)),
                 pr=c(pA, pB),
                 Methods=c(rep(c("Asymptotic SE",
                                "Fisher transformation (Delta method)",
                                "Bootstrap SE",
                                "Bootstrap SE (Three-stage)",
                                "Bootstrap percentile",
                                "Bootstrap percentile (Three-stage)"),each=length(n)))
                 )
df$Methods <- factor(df$Methods, levels = c("Asymptotic SE",
                                "Fisher transformation (Delta method)",
                                "Bootstrap SE",
                                "Bootstrap SE (Three-stage)",
                                "Bootstrap percentile",
                                "Bootstrap percentile (Three-stage)"))
ggplot(df, aes(pr, factor(size), color=Methods)) +
  geom_point() + 
  geom_vline(xintercept = 0.95,linetype="dashed") +
  scale_color_manual(values=c("red","blue","deepskyblue","darkorange3","orange","green","darkgreen")) +
  scale_x_continuous(breaks=seq(0.7,1,0.05),limits=c(0.85,1))+
  xlab("Coverage Probability") + ylab("Sample Size")+
  theme_classic() 
```
```{r}
df %>% spread(Methods,pr) %>%
  kbl(digits = 3, align = "c", full.width = F, caption = "Coverage probability") %>%
  kable_styling(full_width = F)
```                                                                                                        

```{r}
# df %>% spread(Methods,pr) %>%
#   kbl(digits = 3, align = "c",format="latex")
```

```{r}
simest <- cbind(n,simest)
simest %>%
  kbl(digits = 3, align = "c", full.width = F, col.names = c("Size","Percent Bias (%)","Empirical SE","Averaged Asymptotic SE","Averaged Bootstrap SE", "Averaged Bootstrap SE (Three-stage) ")) %>% 
  kable_styling(full_width = F)
```



```{r, fig.height=8}
n <- c(25, 50, 100, 200, 500)
sim_num <- 186*5
bootest <- matrix(NA, ncol=3, nrow = sim_num)
par(mfrow=c(3,2))
for(j in seq_along(n)){
  m2 <- m1 <- rep(NA, sim_num)
  for(i in 1:sim_num){
    m1[i] <- median(outputBoot[[j]][[i]][,1])
    m2[i] <- median(outputBoot[[j]][[i]][,2])
  }
  hist(m1, breaks=30, xlab="Bootstrap Median", main = paste("n=",n[j],", Cluster bootstrap", sep=""), xlim=c(0.2,0.7))
  abline(v=r,col="red")
  abline(v=median(m1), col="green")
  
  hist(m2, breaks=30, xlab="Bootstrap Median", main = paste("n=",n[j],", Three-stage bootstrap", sep=""), xlim=c(0.2,0.7))
  abline(v=r,col="red")
  abline(v=median(m2), col="green")
  
}
```

Comparison of different asymptotic-SE-based methods 

**$\gamma_{I3} = 0.48$**

```{r}
load("data/RankICC/outputSE3levels.RData")
n <- c(25, 50, 100, 200, 500, 1000)
r <- 6 * asin(0.5/2)/pi 
pA <- matrix(0, ncol = 4, nrow = length(n))
simest <- matrix(0, ncol = 6, nrow = length(n))
for(i in 1:length(n)){
  t <- output[[i]]
  #one replication
  l1 <- t[,1] - 1.96 * t[,2]
  u1 <- t[,1] + 1.96 * t[,2]
  #sqrt of average over 5 replications
  l2 <- t[,1] - 1.96 * sqrt(rowMeans(t[,2:6]^2))
  u2 <- t[,1] + 1.96 * sqrt(rowMeans(t[,2:6]^2))
  #average of SD over 5 replications
  l3 <- t[,1] - 1.96 * rowMeans(t[,2:6])
  u3 <- t[,1] + 1.96 * rowMeans(t[,2:6])
  #sqrt of average Var + var(5 EST)
  l4 <- t[,1] - 1.96 * sqrt(rowMeans(t[,2:6]^2) + apply(t[,7:11], 1, function(x) var(x)))
  u4 <- t[,1] + 1.96 * sqrt(rowMeans(t[,2:6]^2) + apply(t[,7:11], 1, function(x) var(x)))
  pA[i,] <- c(mean((l1<=r)&(r<=u1)),
             mean((l2<=r)&(r<=u2)),
             mean((l3<=r)&(r<=u3)),
             mean((l4<=r)&(r<=u4)))
  simest[i, ] <- c((mean(t[,1])-r)/r*100,sd(t[,1]), 
                   mean(t[,2]), mean(sqrt(rowMeans(t[,2:6]^2))),
                   mean(rowMeans(t[,2:6])),
                   mean(sqrt(rowMeans(t[,2:6]^2) + apply(t[,7:11], 1, function(x) var(x)))))

}
df <- data.frame(size=rep(n, ncol(pA)),
                 pr=c(pA),
                 Methods=c(rep(c("One replication",
                                "AVE of VAR",
                                "AVE of SE",
                                "AVE of VAR + VAR of EST"),each=length(n)))
                 )
df$Methods <- factor(df$Methods, levels = c("One replication", "AVE of VAR", "AVE of SE", "AVE of VAR + VAR of EST"))
ggplot(df, aes(pr, factor(size), color=Methods)) +
  geom_point() + 
  geom_vline(xintercept = 0.95,linetype="dashed") +
  scale_color_manual(values=c("red","blue","deepskyblue","darkorange3","orange","green","darkgreen")) +
  scale_x_continuous(breaks=seq(0.7,1,0.05),limits=c(0.85,1))+
  xlab("Coverage Probability") + ylab("Sample Size")+
  theme_classic() 
```


```{r}
df %>% spread(Methods,pr) %>%
  kbl(digits = 3, align = "c", full.width = F, caption = "Coverage probability") %>% 
  kable_styling(full_width = F)
```                                                                                                        


```{r}
simest <- cbind(n,simest)
simest %>%
  kbl(digits = 3, align = "c", full.width = F, col.names = c("Size","Percent Bias (%)","Empirical SE","One replication", "Squared AVE of VAR", "AVE of SE",
"AVE of VAR + VAR of EST")) %>% 
  kable_styling(full_width = F)
```


**$\gamma_{I3} = 0.096$**

```{r}
load("data/RankICC/outputSE3levelsPoint1.RData")
n <- c(25, 50, 100, 200, 500, 1000)
r <- 6 * asin(0.1/2)/pi 
pR <- pL <- pA <- matrix(0, ncol = 4, nrow = length(n))
simest <- matrix(0, ncol = 6, nrow = length(n))

for(i in 1:length(n)){
  t <- output[[i]]
  #one replication
  l1 <- t[,1] - 1.96 * t[,2]
  u1 <- t[,1] + 1.96 * t[,2]
  #sqrt of average over 5 replications
  l2 <- t[,1] - 1.96 * sqrt(rowMeans(t[,2:6]^2))
  u2 <- t[,1] + 1.96 * sqrt(rowMeans(t[,2:6]^2))
  #average of SD over 5 replications
  l3 <- t[,1] - 1.96 * rowMeans(t[,2:6])
  u3 <- t[,1] + 1.96 * rowMeans(t[,2:6])
  #sqrt of average Var + var(5 EST)
  l4 <- t[,1] - 1.96 * sqrt(rowMeans(t[,2:6]^2) + apply(t[,7:11], 1, function(x) var(x)))
  u4 <- t[,1] + 1.96 * sqrt(rowMeans(t[,2:6]^2) + apply(t[,7:11], 1, function(x) var(x)))
  pA[i,] <- c(mean((l1<=r)&(r<=u1)),
             mean((l2<=r)&(r<=u2)),
             mean((l3<=r)&(r<=u3)),
             mean((l4<=r)&(r<=u4)))
  
  pR[i, ] <- c(mean(r<=u1), mean(r<=u2), mean(r<=u3), mean(r<=u4))
  pL[i, ] <- c(mean(l1<=r), mean(l2<=r), mean(l3<=r), mean(l4<=r))
  
  simest[i, ] <- c((mean(t[,1])-r)/r*100,sd(t[,1]), 
                   mean(t[,2]), mean(sqrt(rowMeans(t[,2:6]^2))),
                   mean(rowMeans(t[,2:6])),
                   mean(sqrt(rowMeans(t[,2:6]^2) + apply(t[,7:11], 1, function(x) var(x)))))

}
df <- data.frame(size=rep(n, ncol(pA)),
                 pr=c(pA),
                 Methods=c(rep(c("One replication",
                                "AVE of VAR",
                                "AVE of SE",
                                "AVE of VAR + VAR of EST"),each=length(n)))
                 )
df$Methods <- factor(df$Methods, levels = c("One replication", "AVE of VAR", "AVE of SE", "AVE of VAR + VAR of EST"))
ggplot(df, aes(pr, factor(size), color=Methods)) +
  geom_point() + 
  geom_vline(xintercept = 0.95,linetype="dashed") +
  scale_color_manual(values=c("red","blue","deepskyblue","darkorange3","orange","green","darkgreen")) +
  scale_x_continuous(breaks=seq(0.7,1,0.05),limits=c(0.85,1))+
  xlab("Coverage Probability") + ylab("Sample Size")+
  theme_classic() 
```



```{r}
# df %>% spread(Methods,pr) %>%
#   kbl(digits = 3, align = "c", full.width = F, caption = "Coverage probability") %>% 
#   kable_styling(full_width = F)
df$prLR <- paste(df$pr,' (L:',c(pL),", R:",c(pR),')', sep="")

df %>% select(size, Methods, prLR) %>% spread(Methods, prLR) %>%
  kbl(digits = 3, align = "c", full.width = F, caption = "Coverage probability") %>% 
  kable_styling(full_width = F)
```                                                                               



```{r}
simest <- cbind(n,simest)
simest %>%
  kbl(digits = 3, align = "c", full.width = F, col.names = c("Size","Percent Bias (%)","Empirical SE","One replication", "Squared AVE of VAR", "AVE of SE",
"AVE of VAR + VAR of EST")) %>% 
  kable_styling(full_width = F)
```

**$\gamma_{I3} = 0.89$**

```{r}
load("data/RankICC/outputSE3levelsPoint9.RData")
n <- c(25, 50, 100, 200, 500, 1000)
r <- 6 * asin(0.9/2)/pi 
pR <- pL <- pA <- matrix(0, ncol = 4, nrow = length(n))
simest <- matrix(0, ncol = 6, nrow = length(n))
for(i in 1:length(n)){
  t <- output[[i]]
  #one replication
  l1 <- t[,1] - 1.96 * t[,2]
  u1 <- t[,1] + 1.96 * t[,2]
  #sqrt of average over 5 replications
  l2 <- t[,1] - 1.96 * sqrt(rowMeans(t[,2:6]^2))
  u2 <- t[,1] + 1.96 * sqrt(rowMeans(t[,2:6]^2))
  #average of SD over 5 replications
  l3 <- t[,1] - 1.96 * rowMeans(t[,2:6])
  u3 <- t[,1] + 1.96 * rowMeans(t[,2:6])
  #sqrt of average Var + var(5 EST)
  l4 <- t[,1] - 1.96 * sqrt(rowMeans(t[,2:6]^2) + apply(t[,7:11], 1, function(x) var(x)))
  u4 <- t[,1] + 1.96 * sqrt(rowMeans(t[,2:6]^2) + apply(t[,7:11], 1, function(x) var(x)))
  pA[i,] <- c(mean((l1<=r)&(r<=u1)),
             mean((l2<=r)&(r<=u2)),
             mean((l3<=r)&(r<=u3)),
             mean((l4<=r)&(r<=u4)))
  pR[i, ] <- c(mean(r<=u1), mean(r<=u2), mean(r<=u3), mean(r<=u4))
  pL[i, ] <- c(mean(l1<=r), mean(l2<=r), mean(l3<=r), mean(l4<=r))
  
  simest[i, ] <- c((mean(t[,1])-r)/r*100,sd(t[,1]), 
                   mean(t[,2]), mean(sqrt(rowMeans(t[,2:6]^2))),
                   mean(rowMeans(t[,2:6])),
                   mean(sqrt(rowMeans(t[,2:6]^2) + apply(t[,7:11], 1, function(x) var(x)))))

}
df <- data.frame(size=rep(n, ncol(pA)),
                 pr=c(pA),
                 Methods=c(rep(c("One replication",
                                "AVE of VAR",
                                "AVE of SE",
                                "AVE of VAR + VAR of EST"),each=length(n)))
                 )
df$Methods <- factor(df$Methods, levels = c("One replication", "AVE of VAR", "AVE of SE", "AVE of VAR + VAR of EST"))
ggplot(df, aes(pr, factor(size), color=Methods)) +
  geom_point() + 
  geom_vline(xintercept = 0.95,linetype="dashed") +
  scale_color_manual(values=c("red","blue","deepskyblue","darkorange3","orange","green","darkgreen")) +
  scale_x_continuous(breaks=seq(0.7,1,0.05),limits=c(0.85,1))+
  xlab("Coverage Probability") + ylab("Sample Size")+
  theme_classic() 
```


```{r}
df$prLR <- paste(df$pr,' (L:',c(pL),", R:",c(pR),')', sep="")

df %>% select(size, Methods, prLR) %>% spread(Methods, prLR) %>%
  kbl(digits = 3, align = "c", full.width = F, caption = "Coverage probability") %>% 
  kable_styling(full_width = F)
```                                                                                   

```{r}
simest <- cbind(n,simest)
simest %>%
  kbl(digits = 3, align = "c", full.width = F, col.names = c("Size","Percent Bias (%)","Empirical SE","One replication", "Squared AVE of VAR", "AVE of SE",
"AVE of VAR + VAR of EST")) %>% 
  kable_styling(full_width = F)
```

# Intra- and Inter-observer Disagreement 


- The inter-observer disagreement (or called variability) quantifies the extent to which two determinations of the measurement, made by two different observers or measurement devices, disagree. It is defined as the average absolute difference between any two measurements from different observers.

- The intra-observer disagreement (or called variability) evaluates the repeatability of one observer in making the measurement at different times. It is defined as the average absolute difference between any two measurements from the same observer. 

- Disagreement measures are computed separately for each unit and combined over units (by taking the mean or median for example) to get an overall summary measure.


# Application Examples

```{r}
est.icc <- function(x, cluster){
  dat <- data.frame("x"=x, "cluster"=cluster)
  #within var
  m <- nrow(dat)
  n.cls  <- length(unique(dat$cluster))
  tb <- dat %>% group_by(cluster) %>%
    mutate(xd = x - mean(x), xb = mean(x))
  swx <- var(tb$xd) * (m-1)/(m-n.cls)
  #between var
  nj <- dat %>% group_by(cluster) %>% summarise(nj = length(x)) %>% pull(nj)
  nt <- 1/(n.cls - 1) * (m - sum(nj^2) / m)
  sbx <- var(tb$xb) * (m-1)/(n.cls-1)/nt
  stx <- sbx - swx/nt +swx
  #ICC
  irx <- (sbx - swx/nt)/stx
  return(list("bVar"=sbx - swx/nt, 
              "wVar"=swx,
              "icc"=irx))
}
est.lmer <- function(x, cluster){
  dat <- data.frame("x"=x, "cluster"=cluster)
  m <- lmer(x ~ (1|cluster), data = dat, REML = T)
  sx <- as.data.frame(VarCorr(m))[,"vcov"]
  return(list("bVar"=sx[1], 
              "wVar"=sx[2],
              "icc"=sx[1]/sum(sx)))
}

CDF.mean <- function(x, pij, tol = 1e-7) {
  vapply(x, function(i) {
    c1 <- x - i
    isEq <- abs(c1) < tol
    isLT <- (!isEq & c1 < 0)
    sum(isLT * pij + (isEq * pij) / 2)
  }, numeric(1))
}

CDF.cov <- function(ef, pci){
  mat <- outer(ef, ef, `*`)
  s <- sum(mat) - sum(diag(mat)) 
  r <- s / (nrow(mat) * (nrow(mat)-1)) * pci
  return(r)
}

outer_lte <- function(a, b, tol = 1e-7) {
  m1 <- outer(a, b, `-`)
  isEq <- abs(m1) < tol
  isLT <- (!isEq & m1 < 0)
  list(isEq, isLT)
}

neffi3 <- function(kij, r2, r3){
  ki <- sum(kij)
  ki^2/(ki * (1 - r2 + r3 * ki) + (r2 - r3) * sum(kij^2))
}

neffi2 <- function(kij, r2){
  nij <- kij/(1 + r2 * (kij - 1))
  nij / sum(nij)
}

CDF.cov.multi <- function(ef, pci, idx){
  s <- 0
  for(i in seq_along(idx)){
    s <- s + sum(ef[i] * ef[idx != idx[i]])
  }
  kij <- table(idx)
  wi <- (sum(kij))^2 - sum(kij^2)
  s <- s * pci / wi
  return(s)
}

d3f <- function(ip, dat, cl, avg, n, an, bn) {
  l_rowix <- tapply(seq(nrow(dat)), dat[,'cluster'], I)
  allL1 <- dat[,'ef'] - avg
  allNI <- lengths(l_rowix)
  allPI <- tapply(dat[,'pci'], dat[,'cluster'], unique)
  xi <- dat[l_rowix[[ip]],'x']
  pij <- dat[l_rowix[[ip]],'pij']
  allLTE <- outer_lte(xi, dat[,'x'])
  allCMP <- colSums(((allLTE[[1]] | allLTE[[2]]) + allLTE[[2]]) / 2 * pij)#F(xi'j|xij'')
  t1 <- numeric(length(cl))
  d34 <- 0
  for(i in seq_along(t1)) {
    ix <- l_rowix[[i]]
    l1 <- allL1[ix]
    l2 <- allCMP[ix]
    ni <- unname(allNI[i])
    Pi <- allPI[[i]]
    s1 <- sum(unlist(lapply(l1, `+`, l1)))
    s2 <- sum(l1 * 2)
    t1[i] <- (s1 - s2) / (ni * (ni - 1)) * Pi
    
    s1 <- sum(unlist(lapply(l1, `*`, l2)))
    s2 <- sum(l1 * l2)
    d34 <- d34 + (s1 - s2) * 2 * Pi / (ni * (ni - 1))
  }
  
  fi <- dat[l_rowix[[ip]],'ef']
  t2 <- allLTE[[1]] / 2 + allLTE[[2]]
  calc1 <- colSums(t2 * pij) * dat[,'pij']
  cni <- sum(pij * fi) + sum(calc1) / n
  t3 <- sum(calc1 * allL1) * 2 
  t4 <- cni * sum(dat[,'pij'] * allL1) * 2 
  d34 / bn - sum(t1) * cni / bn - an / (bn^2) * (t3 - t4)
}

#########Calculate components for standard error 
d3f.gamma2 <- function(ip, dat, avg, n, an, bn) {
  l_rowix <- tapply(seq(nrow(dat)), dat[,'level3'], I)
  l_rowijx <- tapply(seq(nrow(dat)), dat[,'level32'], I)
  allL1 <- dat[,'ef'] - avg
  allNIJ <- lengths(l_rowijx)
  allPIJ <- tapply(dat[,'pij'], dat[,'level32'], unique)
  xi <- dat[l_rowix[[ip]],'x']
  pijk <- dat[l_rowix[[ip]],'pijk']
  allLTE <- outer_lte(xi, dat[,'x'])
  allCMP <- colSums(((allLTE[[1]] | allLTE[[2]]) + allLTE[[2]]) / 2 * pijk)
  t1 <- numeric(length(unique(dat[,'level32'])))
  dd1 <- 0
  for(ij in seq_along(t1)) {
    ijx <- l_rowijx[[ij]]
    l1 <- allL1[ijx]
    l2 <- allCMP[ijx]
    nij <- unname(allNIJ[ij])
    Pij <- allPIJ[[ij]]
    
    s1 <- sum(unlist(lapply(l1, `+`, l1)))
    s2 <- sum(l1 * 2)
    t1[ij] <- (s1 - s2) / (nij * (nij - 1)) * Pij
    
    s1 <- sum(unlist(lapply(l1, `*`, l2)))
    s2 <- sum(l1 * l2)
    dd1 <- dd1 + (s1 - s2) * 2 * Pij / (nij * (nij - 1))
  }
  
  fi <- dat[l_rowix[[ip]],'ef']
  t2 <- allLTE[[1]] / 2 + allLTE[[2]]
  calc1 <- colSums(t2 * pijk) * dat[,'pijk']
  cni <- sum(pijk * fi) + sum(calc1) / n
  t3 <- sum(calc1 * allL1) * 2 
  t4 <- cni * sum(dat[,'pijk'] * allL1) * 2 
  dd1 / bn - sum(t1) * cni / bn - an / (bn^2) * (t3 - t4)
}

#################SE part for gamma 3
d3f.gamma3 <- function(ip, dat, cl, avg, n, an, bn) {
  l_rowix <- tapply(seq(nrow(dat)), dat[,'level3'], I)
  allL1 <- dat[,'ef'] - avg
  allNI <- lengths(l_rowix)
  allPI <- tapply(dat[,'pi'], dat[,'level3'], unique)
  xi <- dat[l_rowix[[ip]],'x']
  pijk <- dat[l_rowix[[ip]],'pijk']
  allLTE <- outer_lte(xi, dat[,'x'])
  allCMP <- colSums(((allLTE[[1]] | allLTE[[2]]) + allLTE[[2]]) / 2 * pijk)
  dd1 <- t1 <- 0
  for(i in seq_along(cl)){
    ix <- l_rowix[[i]]
    l1 <- allL1[ix]
    l2 <- allCMP[ix]
    Pi <- allPI[[i]]
    cll2 <- dat[ix, 'level2']
    mij <- table(cll2)
    wi <- (sum(mij))^2 - sum(mij^2)
    s1 <- s2 <- 0
    for(j in unique(cll2)){
      l1j <- l1[cll2 == j]
      l2j <- l2[cll2 != j]
      s1 <- s1 + sum(unlist(lapply(l1j, `*`, l2j)))
      
      l1j <- l1[cll2 != j]
      l2j <- l2[cll2 == j]
      s1 <- s1 + sum(unlist(lapply(l1j, `*`, l2j)))
      
      s2 <- s2 + sum(unlist(lapply(l1[cll2 == j], `+`, l1[cll2 != j])))    
    }
    dd1 <- dd1 + s1 * Pi / wi
    t1 <- t1 + s2 * Pi / wi 
  }
  fi <- dat[l_rowix[[ip]],'ef']
  t2 <- allLTE[[1]] / 2 + allLTE[[2]]
  calc1 <- colSums(t2 * pijk) * dat[,'pijk']
  cni <- sum(pijk * fi) + sum(calc1) / n
  t3 <- sum(calc1 * allL1) * 2 
  t4 <- cni * sum(dat[,'pijk'] * allL1) * 2 
  dd1 / bn - t1 * cni / bn - an / (bn^2) * (t3 - t4)
}

est.Wcdf <- function(x, cluster, ri, std=T, opt_method='eff') {
  cluster <- factor(cluster, levels=unique(cluster))
  x <- x[order(cluster)]
  cluster <- sort(cluster)
  ####obtain estimates
  #cluster size
  ki <- tabulate(cluster) 
  if(opt_method == "eff"){
    #effective sample size
    neffi <- ki / (1 + (ki - 1) * ri) 
    #cluster weights
    Pi <- neffi / sum(neffi)
    #individual weights
    pij <- rep(Pi / ki, ki)  
    pci <- rep(Pi, ki)
  }
  if(opt_method=="combo"){
    N <- length(x)
    n <- length(ki)
    size <- rep(ki, ki)
    pij <- (1-ri)/N + ri/size/n
    Pi <- (1-ri)/N * ki + ri/n
    pci <- pij * size
  }
  #CDFs of observations
  ef <- CDF.mean(x, pij) 
  dat <- data.frame(x = x, cluster = cluster, pci = pci, pij = pij, ef = ef)
  #averaged CDF
  avg <- sum(ef * pij) 
  #total variance
  tv <- sum((ef - avg)^2 * pij)  
  cl <- unique(cluster)
  #covariance
  l_l <- tapply(ef - avg, cluster, I) 
  l_p <- as.list(Pi)
  cv <- mapply(CDF.cov, l_l, l_p, USE.NAMES = FALSE) 
  #estimate
  est <- sum(cv) / tv 
  ####calculate standard error 
  if(std){
    n <- length(cl)
    an <- sum(cv) / n
    bn <- tv / n
    d1 <- cv / bn
    d2 <- c(unname(tapply((ef - avg) ^ 2 * pij, cluster, sum)) * -an / bn ^ 2)
    d3 <- vapply(cl, d3f, numeric(1), dat, cl, avg, n, an, bn)
    se <- sd((d1 + d2 + d3) / sqrt(n))
    output <- list(est = est, se = se)
  }
  else output <- est
  
  return(output)
}


est.cdf.multi <- function(x, level2, level3, weights="equal1", SE=TRUE){
  level3 <- factor(level3, levels = unique(level3))
  level2 <- as.character(level2)
  idx <- order(level3, level2)
  x <- x[idx]
  level3 <- level3[idx]
  level2 <- level2[idx]
  level32 <- paste(level3, level2, sep="-")
  level32 <- factor(level32, levels = unique(level32))
  #number of obs in each level3
  ki <- tabulate(level3)
  #number of obs in each level2
  kij <- unlist(tapply(level2, level3, table))
  #number of level2 in each level3
  mi <- unlist(lapply(tapply(level2, level3, unique), length))
  #number of obs
  N <- length(level3)
  if(weights=="equal3"){
    n3 <- length(unique(level3))
    pi <- rep(1 / n3, N)
    pij <- rep(rep(1 / mi, mi), kij) * pi
    pijk <-  pij / (unname(rep(kij, kij)))
  }
  if(weights=="equal2"){
    pi <- rep(mi / sum(mi), ki)
    pij <- rep(1 / sum(mi), N)
    pijk <-  pij / (unname(rep(kij, kij)))
  }
  if(weights=="equal1"){
    pi <- rep(ki / N, ki)
    pijk <-  rep(1 / N, N)
    pij <- rep(as.vector(by(pijk, level32, sum)), kij)
  }
  
  #CDFs of observations
  ef <- CDF.mean(x, pijk) 
  #averaged CDF
  avg <- sum(ef * pijk) 
  #total variance
  tv <- sum((ef - avg)^2 * pijk)  
  cl <- unique(level3)
  n <- length(cl)
  #################gamma2 
  #covariance
  l_l <- tapply(ef - avg, level32, I)
  l_pij <- as.list(tapply(pij, level32, unique))
  cv <- mapply(CDF.cov, l_l, l_pij, USE.NAMES = FALSE)
  l_idx <- unlist(lapply(tapply(level3, level32, I), unique))
  cv <- as.vector(by(cv, l_idx, sum))
  #estimate
  est2 <- sum(cv) / tv
  #SE
  if(SE){
    an <- sum(cv) / n
    bn <- tv / n
    d1 <- cv / bn
    d2 <- c(unname(tapply((ef - avg) ^ 2 * pijk, level3, sum)) * -an / bn ^ 2)
    dat <- data.frame(x = x, level3 = level3, level2 = level2, level32 = level32, pij = pij, pijk = pijk, ef = ef)
    d3 <- vapply(cl, d3f.gamma2, numeric(1), dat, avg, n, an, bn)
    se2 <- sd((d1 + d2 + d3) / sqrt(n))
  }
  
  ##################gamma3
  #covariance
  l_l <- tapply(ef - avg, level3, I)
  l_pi <- as.list(tapply(pi, level3, unique))
  l_ij <- tapply(level2, level3, I)
  cv <- mapply(CDF.cov.multi, l_l, l_pi, l_ij, USE.NAMES = FALSE)
  #estimate
  est3 <- sum(cv) / tv
  #SE
  if(SE){
    an <- sum(cv) / n
    bn <- tv / n
    d1 <- cv / bn
    d2 <- c(unname(tapply((ef - avg) ^ 2 * pijk, level3, sum)) * -an / bn ^ 2)
    dat <- data.frame(x = x, level3 = level3, level2 = level2, pi = pi, pijk = pijk, ef = ef)
    d3 <- vapply(cl, d3f.gamma3, numeric(1), dat, cl, avg, n, an, bn)
    se3 <- sd((d1 + d2 + d3) / sqrt(n))
    output <- list("gamma2" = list(est = est2, se = se2),
                   "gamma3" = list(est = est3, se = se3))
  }
  else{
    output <- list("gamma2" = list(est = est2),
                   "gamma3" = list(est = est3))
  }
  return(output)
  
}

est.iter <- function(x, cluster, ri=0, tol=1e-5, maxIter=100, std=T){
  i <- 0; d <- 10
  ri1 <- ri2 <- ri
  while(i < maxIter & d > tol){
    rnew <- est.Wcdf(x, cluster, ri1, opt_method = "eff", std=F)
    d <- abs(rnew - ri1)
    ri1 <- rnew
    i <- i + 1
  }
  n1 <- i
  i <- 0; d <- 10
  while(i < maxIter & d > tol){
    rnew <- est.Wcdf(x, cluster, ri2, opt_method = "combo", std=F)
    d <- abs(rnew - ri2)
    ri2 <- rnew
    i <- i + 1
  }
  n2 <- i  
  if(std){
    est1 <- est.Wcdf(x, cluster, ri1, opt_method = "eff")
    est2 <- est.Wcdf(x, cluster, ri2, opt_method = "combo")
    output <- list("est"=c(ri1, ri2),
                   "se"=c(est1$se, est2$se),
                   "Niter"=c(n1, n2))
  }
  else{output <- list("est"=c(ri1, ri2),
                      "Niter"=c(n1, n2))}
  return(output)
}

fisherCIdelta <- function(x, s){
  tr <- log((1+x)/(1-x))/2 
  ts <- s/((1+x)*(1-x))
  l <- tr - 1.96 * ts
  u <- tr + 1.96 * ts
  l <- (exp(2*l)-1)/(exp(2*l)+1) #tanh()
  u <- (exp(2*u)-1)/(exp(2*u)+1)
  cbind(l,u)
}

# #####Function to compute mean absolute discrepancies
# mad <- function(y, obs) {
#   nintra <- ninter <- sumintra <- suminter <- 0 
#   n <- length(y)
#   for(i in 1 : (n - 1)) {
#     for(j in (i + 1) : n) { 
#           dif <- abs(y[i] - y[j]) 
#           if(! is.na(dif)) {
#             if(obs[i] == obs[j]) { 
#               nintra <- nintra + 1 
#               sumintra <- sumintra + dif
#           }
#       else {
#         ninter <- ninter + 1 
#         suminter <- suminter + dif
#          }   
#       }
#     }
#   } 
#   c(nintra=nintra , intra=sumintra / nintra , ninter=ninter , inter=suminter / ninter)
# }
# 
# mad3 <- function(y, l2, l3) {
#   nintra <- ninter <- sumintra <- suminter <- 0 
#   n <- length(y)
#   for(i in 1 : (n - 1)) {
#     for(j in (i + 1) : n) { 
#       if(l3[i] == l3[j]) {
#           dif <- abs(y[i] - y[j]) 
#           if(l2[i] != l2[j]) { 
#               nintra <- nintra + 1 
#               sumintra <- sumintra + dif
#           }
#       }
#       else{
#         ninter <- ninter + 1 
#         suminter <- suminter + dif
#       }   
#     } 
#   }
#   c(nintra=nintra , intra=sumintra / nintra , ninter=ninter , inter=suminter / ninter)
# }
```





### HoPS baseline PHQ 9

The baseline patient health questionnaire-9 (PHQ-9) data from the HoPS+ trial. Each couple has a male PHQ-9 score and a female PHQ-9 score. There are 1079 couples, of whom 813 couples have complete data. PHQ-9 total score ranges from 0 to 27.

Variables of interest: 

- PHQ-9 (Median=2, [Q1,Q3]=[0,5], [Min,Max]=[0,27])
- Sex, 813 couples
- Cluster index. 24 clusters, cluster size (Median=68, [Q1, Q3]=[51.5, 91.5], [Min,Max]=[4,136])

```{r}
load("data/baseline_hops_dep_deid.rda")
df <- baseline_hops_dep_deid[complete.cases(baseline_hops_dep_deid),]
p <- summarise(group_by(df,Female,Male),length(Male))
colnames(p)[3] <- "Count"
ggplot(p,aes(Female,Male, color=Count, alpha = "191"))+ geom_point() + 
  scale_color_gradient2(high = 'grey20', mid = 'grey65', na.value = 'black', limits= c(1, 29),
    guide = guide_colorbar(title.position = 'left'), breaks= seq(0,30,5)) +
  scale_alpha_manual(values = 1, name = 'Count', guide = guide_legend(override.aes = list(color = 'black'), title.position = 'left', title.theme = element_text(color = 'white', angle = 0)))+theme_classic()+
  theme(legend.margin = margin(-5,10, -5, 10))+ theme(text = element_text(size=15))
```

```{r}
p <- df %>% gather(key="Sex", value="Score", Male:Female) %>% arrange(cluster,Sex) 
ggplot(p,aes(x=factor(cluster), y=Score, color=factor(cluster), shape=Sex))+ 
  geom_jitter() +theme_classic() +
  scale_shape_manual(values=c(18, 21))+xlab("Cluster Index")+ylab("PHQ-9 Score")
# p <- p %>% group_by(cluster) %>% summarise(size=n())
# summary(p$size)
```


```{r HistPHQ}
ggplot(p %>% spread(Sex,Score)) +
  geom_histogram(aes(x = Female, y = ..count..), color="black", fill="grey80") +
  geom_label( aes(x=10, y=150, label="Female")) +
  geom_histogram( aes(x = Male, y = -..count..), color="black", fill="grey80") +
  geom_label( aes(x=10, y=-150, label="Male")) + 
  theme_classic()+ ylab("Count")+ theme(text = element_text(size=15))
```

```{r}
p %>% group_by(cluster, Sex) %>% 
  summarise(ScoreM=median(as.numeric(Score))) %>% spread(Sex, ScoreM) %>%
  ggplot(aes(x=Female,y=Male)) + geom_point() + 
  geom_abline(intercept = 0, slope=1, linetype="dashed") +xlab("Median PHQ-Score of female in each clinical site")+ylab("Median PHQ-Score of male in each clinical site") +
  theme_bw()
```


```{r}
dt <- data.frame(x=c(df$Female,df$Male), level2=factor(rep(1:nrow(df), 2)), level3 = factor(rep(df$cluster, 2)), sex=rep(c("Female","Male"), each=nrow(df)))
dt <- dt %>% arrange(level3, level2)
x <- dt$x
level2 <- dt$level2
level3 <- dt$level3
r <- rep(0,4)
r[1] <- cor(df$Female, df$Male, method = "spearman")
r1 <- est.cdf.multi(x, level2, level3, weights = "equal2")
r[2] <- r1$gamma2$est
dt <-  dt %>% mutate(cluster = paste(level3, level2, sep="-")) %>% arrange(cluster)
x <- dt$x
cluster <- factor(dt$cluster)
r[3] <- est.icc(rank(x),cluster)$icc 
r[4] <-  est.icc(x,cluster)$icc 
output <- round(r,4)
output[2] <- paste(output[2], "(SE=",round(r1$gamma2$se,4),")",sep="")
kable(rbind(c("Spearman corr", "Rank-based ICC", "ICC using ranked data", "Pearson ICC"), output), align = "c", caption = "ICC at the couple level") %>% 
  kable_styling(full_width = F)
```


```{r, include=F}
# # st <- mad(x, cluster)
# # st 
# c("intra"=1.872079, "inter"=4.537615)
```



```{r}
lb <- round(r1$gamma2$est - 1.96 * r1$gamma2$se,4)
ub <- round(r1$gamma2$est + 1.96 * r1$gamma2$se,4)
flub <- round(fisherCIdelta(r1$gamma2$est, r1$gamma2$se),4)
cis <- c(paste("[",lb,", ",ub,"]",sep=""),
         paste("[",flub[1],",",flub[2],"]",sep=""))
kable(rbind(c("Asymptotic SE","Fisher's z transformation"), cis), align = "c", caption = "95% CI of the Rank-based ICC at the couple level", row.names = F) %>% 
  kable_styling(full_width = F)
```


```{r}
# #Explore why Spearman correlation is close to our estimate
# ri <- 0
# dat <- data.frame("x"=x, "cluster"=cluster)
# cpsum <- sum(dat %>% group_by(cluster) %>% summarise(size=n(), c=size/(1+(size-1)*ri)) %>% pull(c))
# dat <- dat %>% group_by(cluster) %>% mutate(size=n(), ci=size/(1+(size-1)*ri), pci=ci/cpsum, pij=ci/cpsum/size)
# dat$ef <- CDF.mean(dat$x, dat$pij)
# avg <- sum(dat$ef * dat$pij)
# tv <- sum((dat$ef - avg)^2 * dat$pij)
# cl <- unique(dat$cluster)
# cv <- sapply(cl, function(i){
#      l <- as.vector(dat[dat$cluster==i,"ef",drop=T]) - avg
#      p <-  unique(dat[dat$cluster==i,"pci",drop=T])
#      CDF.cov(l, p)
#   })
# c(sum(cv),tv)
# 
# n <- nrow(dat)
# ef1 <- c(dat[1:(n/2),]$ef - mean(dat[1:(n/2),]$ef))
# ef2 <- c(dat[(n/2+1):n,]$ef - mean(dat[(n/2+1):n,]$ef))
# c(mean(ef1*ef2), sd(ef1)*sd(ef2))
# c(sd(ef1),sd(ef2), mean(dat[1:(n/2),]$ef),mean(dat[(n/2+1):n,]$ef))
```


```{r}
dt <- dt %>% arrange(level3, level2)
x <- dt$x
level2 <- dt$level2
level3 <- dt$level3
r2 <- est.cdf.multi(x, level2, level3, weights = "equal3")

r <- matrix(NA, ncol = 2, nrow = 3)
r[1,1] <- r1$gamma3$est
r[1,2] <- r2$gamma3$est

r0f <- est.Wcdf(dt[dt$sex=="Female", ]$x, dt[dt$sex=="Female", ]$level3, 0)
r0m <- est.Wcdf(dt[dt$sex=="Male", ]$x, dt[dt$sex=="Male", ]$level3, 0)

r1f <- est.Wcdf(dt[dt$sex=="Female", ]$x, dt[dt$sex=="Female", ]$level3, 1)
r1m <- est.Wcdf(dt[dt$sex=="Male", ]$x, dt[dt$sex=="Male", ]$level3, 1)

r[2,] <- c(r0f$est, r1f$est)
r[3,] <- c(r0m$est, r1m$est)

std <- rbind(c(r1$gamma3$se, r2$gamma3$se), c(r0f$se, r1f$se), c(r0m$se, r1m$se))

output <- t(sapply(1:nrow(r), function(x) 
  paste(round(r[x,],4), " (SE=",round(std[x,],4), ")", sep="")))


output <- rbind(c("Equal obs (Equal couples)", "Equal clinics"), output)
rownames(output) <- c(" ","EST gamma 2", "Female", "Male")
kable(output, align = "c", caption = "ICC at the clinic level") %>% 
  kable_styling(full_width = F)
```


The ICC on the original scale is 

```{r}
est.icc(dt[dt$sex=="Female", ]$x, dt[dt$sex=="Female", ]$level3)$icc
est.icc(dt[dt$sex=="Male", ]$x, dt[dt$sex=="Female", ]$level3)$icc
```


```{r}
output <- matrix(NA, ncol = 2, nrow = 6)
k <- 1
for(i in 1:3){
  for(j in 1:2){
      lb <- round(r[i,j] - 1.96 * std[i, j],4)
      ub <- round(r[i,j] + 1.96 * std[i, j],4)
      flub <- round(fisherCIdelta(r[i,j], std[i, j]),4)
      output[k,] <- c(paste("[",lb,", ",ub,"]",sep=""),
                      paste("[",flub[1],",",flub[2],"]",sep=""))
      k <- k + 1
  }
}
rownames(output) <- rep(c("Equal obs", "Equal clinics"),3)
output <- rbind(c("Asymptotic SE","Fisher's z transformation"),output)
kable(output, align = "c", caption = "95% CI of the Rank-based ICC at the clinical level") %>% 
  kable_styling(full_width = F) %>% 
  pack_rows("EST gamma 2", 2, 3) %>% 
  pack_rows("Female", 4, 5) %>% 
  pack_rows("Male", 6, 7)

```


### Albumin:Creatinine Ratio 

2500 participants, each had two repeated measures of ACR. 

```{r}
Final_Nigeria_R3_Data <- readxl::read_excel("data/Final_Nigeria_R3_Data.xlsx")
ggplot(Final_Nigeria_R3_Data,
       aes(ACR_1, ACR_2))+ geom_point() + theme_classic()+ theme(text = element_text(size=15))+
  xlab("First uACR") + ylab("Second uACR")
```



```{r}
ggplot(Final_Nigeria_R3_Data, aes(log(ACR_1), log(ACR_2)))+ 
  xlab("log(First uACR)") + ylab("log(Second uACR)") +
  geom_point() + theme_classic()+ theme(text = element_text(size=15))
```

```{r HistLogACR}
ggplot(Final_Nigeria_R3_Data) + xlab("log(uACR)") + 
  geom_histogram(aes(x = log(ACR_1), y = ..count..),  color="black", fill="grey80") +
  geom_label( aes(x=8, y=150, label="First")) +
  geom_histogram( aes(x = log(ACR_2), y = -..count..),color="black", fill="grey80") +
  geom_label( aes(x=8, y=-150, label="Second")) + 
  theme_classic()+ ylab("Count")+ theme(text = element_text(size=15)) + xlim((c(-.9,10)))
```

```{r HistACR}
ggplot(Final_Nigeria_R3_Data) + xlab("uACR") +
  geom_histogram(aes(x = ACR_1, y = ..count..),  color="black", fill="grey80") +
  geom_label( aes(x=3000, y=1000, label="First")) +
  geom_histogram( aes(x = ACR_2, y = -..count..),color="black", fill="grey80") +
  geom_label( aes(x=3000, y=-1000, label="Second")) + 
  theme_classic() + ylab("Count")+ theme(text = element_text(size=15))
```


```{r}
dat <- data.frame(x = c(Final_Nigeria_R3_Data$ACR_1,Final_Nigeria_R3_Data$ACR_2),
                  cluster = factor(rep(1:nrow(Final_Nigeria_R3_Data), 2))) %>% 
  arrange(cluster)
x <- dat$x
cluster <- dat$cluster
r <- rep(0,4)
r[1] <- cor(Final_Nigeria_R3_Data$ACR_1, Final_Nigeria_R3_Data$ACR_2, method = "spearman")
#rr <- est.Wcdf(x, cluster, ri=0)
rr <- list("est"=0.2331347, "se"=0.01965055)
r[2] <- rr$est
r[3] <- est.icc(rank(x),cluster)$icc 
r[4] <- est.icc(x,cluster)$icc 
output <- round(r,4)
output[2] <- paste(output[2], "(SE=",round(rr$se,4),")",sep="")

r <- rep(0,4)
r[1] <- cor(log(Final_Nigeria_R3_Data$ACR_1), log(Final_Nigeria_R3_Data$ACR_2), method = "spearman")
#rr <- est.Wcdf(log(x), cluster, ri=0)
rr <- list("est"=0.2331347, "se"=0.01965055)
r[2] <- rr$est
r[3] <- est.icc(rank(log(x)),cluster)$icc 
r[4] <- est.icc(log(x),cluster)$icc 
output <- rbind(output, round(r,4))
output[2,2] <- paste(output[2,2], "(SE=",round(rr$se,4),")",sep="")
rownames(output) <- c("ACR", "log(ACR)")
kable(rbind(c("Spearman corr", "Rank-based ICC", "ICC using ranked data", "Pearson ICC"), output), align = "c") %>% 
  kable_styling(full_width = F)
```


```{r, include = F}
# # st <- mad(x, cluster)
# # st
# c("intra"=8.327351e+01, "inter"=1.054675e+02)
```


```{r}
lb <- round(rr$est - 1.96 * rr$se,4)
ub <- round(rr$est + 1.96 * rr$se,4)
flub <- round(fisherCIdelta(rr$est, rr$se),4)
cis <- c(paste("[",lb,", ",ub,"]",sep=""),
         paste("[",flub[1],",",flub[2],"]",sep=""))
kable(rbind(c("Asymptotic SE","Fisher's z transformation"), cis), align = "c", caption = "95% CI of the Rank-based ICC", row.names = F) %>% 
  kable_styling(full_width = F)
```

```{r}
# #Explore why Spearman correlation is close to our estimate
# ri <- 0
# dat <- data.frame("x"=x, "cluster"=cluster)
# cpsum <- sum(dat %>% group_by(cluster) %>% summarise(size=n(), c=size/(1+(size-1)*ri)) %>% pull(c))
# dat <- dat %>% group_by(cluster) %>% mutate(size=n(), ci=size/(1+(size-1)*ri), pci=ci/cpsum, pij=ci/cpsum/size)
# dat$ef <- CDF.mean(dat$x, dat$pij)
# avg <- sum(dat$ef * dat$pij)
# tv <- sum((dat$ef - avg)^2 * dat$pij)
# cl <- unique(dat$cluster)
# cv <- sapply(cl, function(i){
#      l <- as.vector(dat[dat$cluster==i,"ef",drop=T]) - avg
#      p <-  unique(dat[dat$cluster==i,"pci",drop=T])
#      CDF.cov(l, p)
#   })
# c(sum(cv),tv)
# 
# ef1 <- c(dat[1:2500,]$ef - mean(dat[1:2500,]$ef))
# ef2 <- c(dat[2501:5000,]$ef - mean(dat[2501:5000,]$ef))
# 
# c(mean(ef1*ef2), sd(ef1)*sd(ef2))
```


###	Status Epilepticus 

Variables of interest: 

- seize_prior_bm1 (Median=10, [Q1,Q3]=[3,40], [Min,Max]=[1,50])
- record_id, the numbers after PHC. 
- cluster size ranges from 19 to 31

60 clusters, 1507 observations. 

```{r}
SeizureTrack <- readxl::read_excel("data/SeizureTrack.xlsx",sheet = "Seiz prior Raw")
SeizureTrack <- SeizureTrack[!is.na(SeizureTrack$seize_prior_bm1),]
SeizureTrack$cluster <- stringr::str_extract(SeizureTrack$record_id,"[0-9]+")
p <- SeizureTrack %>% group_by(cluster) %>% summarise(size=n()) 
p %>% group_by(size) %>% summarise(counts=n()) %>% ggplot() + 
  geom_bar(aes(x=size, y=counts), stat="identity", fill="white",color="black") + 
  geom_text(aes(x=size, y=counts,label = counts), vjust = -0.2) +
  theme_classic() + xlab("Cluster Size") + ylab("Frequency")+ theme(text = element_text(size=15))
```


```{r}
hist(SeizureTrack$seize_prior_bm1, breaks = 50, xlab="Numbers of seizures", main="")+ theme(text = element_text(size=15))
```


```{r}
dat <- data.frame(x= SeizureTrack$seize_prior_bm1, cluster = factor(SeizureTrack$cluster)) %>% arrange(cluster)
x <- dat$x
cluster <- dat$cluster
r <- rep(0,6)
r0 <- est.Wcdf(x, cluster, r=0)
r1 <- est.Wcdf(x, cluster, r=1)
r[1:2] <- c(r0$est, r1$est)
r2 <- est.iter(x, cluster, ri = r0$est, std = T)
r[3:4] <- r2$est
r[5] <- est.icc(rank(x),cluster)$icc 
r[6] <- est.icc(x,cluster)$icc 
se <- c(r0$se, r1$se, r2$se, NA, NA)
output <- paste(round(r,4)," (SE=",round(se,4),")",sep="")
kable(rbind(c("Equal obs","Equal clusters","ESS","Combo", "ICC using ranked data","Pearson ICC"), output), align = "c", caption = "ICC estiamtes", row.names = F) %>% 
  kable_styling(full_width = F)
```



```{r, include=F}
# # st <- mad(x, cluster)
# # st
# c("intra"=1.973551e+01, "inter"=2.044995e+01)
```


```{r}
lb <- round(r0$est - 1.96 * r0$se,4)
ub <- round(r0$est + 1.96 * r0$se,4)
flub <- round(fisherCIdelta(r0$est, r0$se),4)
cis0 <- c(paste("[",lb,", ",ub,"]",sep=""),
         paste("[",flub[1],",",flub[2],"]",sep=""))

lb <- round(r1$est - 1.96 * r1$se,4)
ub <- round(r1$est + 1.96 * r1$se,4)
flub <- round(fisherCIdelta(r1$est, r1$se),4)
cis1 <- c(paste("[",lb,", ",ub,"]",sep=""),
         paste("[",flub[1],",",flub[2],"]",sep=""))

lb <- round(r2$est[1] - 1.96 * r2$se[1],4)
ub <- round(r2$est[1] + 1.96 * r2$se[1],4)
flub <- round(fisherCIdelta(r2$est[1], r2$se[1]),4)
cis2 <- c(paste("[",lb,", ",ub,"]",sep=""),
         paste("[",flub[1],",",flub[2],"]",sep=""))

lb <- round(r2$est[2] - 1.96 * r2$se[2],4)
ub <- round(r2$est[2] + 1.96 * r2$se[2],4)
flub <- round(fisherCIdelta(r2$est[2], r2$se[2]),4)
cis3 <- c(paste("[",lb,", ",ub,"]",sep=""),
         paste("[",flub[1],",",flub[2],"]",sep=""))

cis <- rbind(cis0, cis1, cis2, cis3)
rownames(cis) = c("Equal obs","Equal clusters","ESS","Combo")
kable(rbind(c("Asymptotic SE","Fisher's z transformation"), cis), align = "c", caption = "95% CI of the Rank-based ICC") %>% 
  kable_styling(full_width = F)

```

# Simulations of two hierarchies 

Let $X_{ij} = U_{i} + R_{ij}$ and $Y_{ij}$ be the observation of the $j$th individual in the $i$th cluster, where $U_i\stackrel{i.i.d}{\sim}N(1,1)$ and $R_{ij} \stackrel{i.i.d}{\sim} N(0, (1-\rho_I)/\rho_I)$ with $\rho_I$ varying over a fine grid over $[0,1]$.

## Scenario I $Y_{ij}=X_{ij}$ and Scenario II $Y_{ij}=exp(X_{ij})$

```{r}
fisherCIdelta <- function(x, s){
  tr <- log((1+x)/(1-x))/2 
  ts <- s/((1+x)*(1-x))
  l <- tr - 1.96 * ts
  u <- tr + 1.96 * ts
  l <- (exp(2*l)-1)/(exp(2*l)+1) #tanh()
  u <- (exp(2*u)-1)/(exp(2*u)+1)
  cbind(l,u)
}

CI_coverage <- function(r, x, s, fisher=T, tol = 1e-7){
  l <- x - 1.96 * s 
  u <- x + 1.96 * s
  p <- mean((l - tol  <= r) & (r <= u + tol))
  if(fisher){
    ci <- fisherCIdelta(x, s)
    p <- c(mean((l - tol  <= r) & (r <= u + tol)),
           mean((ci[,1] - tol <= r) & (r <= ci[,2] + tol)))
  }
  return(p)
}
```

When the cluster size is 30 and the number of clusters changes, 

```{r figure1.1S, fig.height=15, fig.width=4}
load("data/RankICC/output-ICC2-S1-kFix.RData")
n <- c(25, 50, 100, 200, 500, 1000)
r <- 6 * asin(seq(0, 1, 0.1)/2)/pi
l_bias <- l_coverage <- list()
for(j in seq_along(r)){
  estj <- unlist(lapply(output[[j]], function(x) mean(x[,1])))
  l_bias[[j]] <- estj - r[j]
  l_coverage[[j]] <- do.call(rbind, lapply(output[[j]], function(x) CI_coverage(r[j], x[,1], x[,2])))
}
l_coverage <- do.call(rbind, l_coverage) * 100
ans <- data.frame("value"=c(unlist(l_bias), l_coverage[,1]),
           "type"=rep(c("Bias", "Coverage (%)"), each=nrow(l_coverage)),
           "n"=rep(rep(n, length(r)), 2),
           "r"=round(rep(rep(r, each=length(n)), 2),2),
           "CI"="None")
ans <- rbind(ans,
             data.frame("value"=l_coverage[,2],
             "type"=rep("Coverage (%)", nrow(l_coverage)),
             "n"=rep(n, length(r)),
             "r"=round(rep(r, each=length(n)),2),
             "CI"="Fisher' z transformation")
             )
ans$n <- factor(ans$n, levels = as.character(rev(n)))
ans <- ans[ans$r != 1,]
p1 <- ggplot(ans[ans$type == "Bias",], aes(value, n)) + 
  geom_point() + 
  facet_grid(r~type) + xlab(" ") +
  ylab("Sample size") + 
  scale_x_continuous(limits = c(-0.05,0.05), breaks = c(-0.03,0,0.03),minor_breaks = c(-0.03,0,0.03)) + 
  theme_bw() + 
  theme(strip.text.y = element_blank()) 
p2 <- ggplot(ans[ans$type == "Coverage (%)",], aes(value, n, color=CI)) + 
  geom_point(aes(shape=CI)) + 
  facet_grid(r~type) + 
  xlab(" ") + ylab(" ") +
  scale_color_manual(values=c("purple", "black")) +
  scale_shape_manual(values=c(4, 16)) + 
  scale_x_continuous(limits = c(85,100), breaks = c(85, 90, 95, 100), minor_breaks = c(85, 90, 95, 100))+ 
  theme_bw() + theme(legend.title=element_blank(), legend.position = "none", axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y.right = element_text(angle = 0))
gridExtra::grid.arrange(p1, p2, ncol=2)
```

```{r figure1.1, fig.height=9, fig.width=4}
idx <- round(r[c(1,seq(2,11,2))], 2)
p1 <- ggplot(ans[(ans$type == "Bias") & (ans$r %in% idx),], aes(value, n)) + 
  geom_point() + 
  facet_grid(r~type) + xlab(" ") +
  ylab("Sample size") + 
  scale_x_continuous(limits = c(-0.05,0.05), breaks = c(-0.03,0,0.03),minor_breaks = c(-0.03,0,0.03)) + 
  theme_bw() + 
  theme(strip.text.y = element_blank()) 
p2 <- ggplot(ans[(ans$type == "Coverage (%)") & (ans$CI=="None") & (ans$r %in% idx),], aes(value, n)) + 
  geom_point() + 
  facet_grid(r~type) + 
  xlab(" ") + ylab(" ") +
  scale_x_continuous(limits = c(85,100), breaks = c(85, 90, 95, 100), minor_breaks = c(85, 90, 95, 100))+ 
  theme_bw() + theme(legend.title=element_blank(), legend.position = "none", axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y.right = element_text(angle = 0))
gridExtra::grid.arrange(p1, p2, ncol=2)
```


When the number of clusters is 200 and cluster sizes vary, 

```{r figure2.1S, fig.height=15, fig.width=4}
load("data/RankICC/output-ICC2-S1-n200Fix.RData")
n <- c("2","30", "2-50", "2/30")
r <- 6 * asin(seq(0, 1, 0.1)/2)/pi
l_bias <- l_coverage <- list()
t <- 2
#size 2, 30
for(j in 1:t){
  estj <- unlist(lapply(output[[j]], function(x) mean(x[,1])))
  l_bias[[j]] <- estj - r
  p <- matrix(NA, ncol=2, nrow=length(r))
  for(i in seq_along(r)){
    estj <- output[[j]][[i]]
    p[i, ] <- CI_coverage(r[i], estj[,1], estj[,2])
  }
  l_coverage[[j]] <- p * 100
}
l_mse_s1 <- list()
#size 2-50 and 2/30
for(j in (t+1):length(n)){
  estj <- unlist(lapply(output[[j]], function(x) colMeans(x[,1:4])))
  l_bias[[j]] <- estj - rep(r, each = 4)
  p <- list(); msej <- matrix(NA, ncol=4, nrow=length(r))
  for(i in seq_along(r)){
      estj <- output[[j]][[i]]
      p[[i]] <- t(sapply(1:4, function(m) CI_coverage(r[i], estj[,m], estj[,m+4])))
      msej[i,] <- apply(estj[,1:4], 2, function(x) mean((x-r[i])^2))
  }
  l_coverage[[j]] <- do.call(rbind, p) * 100
  l_mse_s1[[j-t]] <- msej
}

lbs <- c("Equal obs", "Equal clusters", "ESS", "Combo")
ans <- data.frame("value"=c(unlist(l_bias), unlist(lapply(l_coverage, function(x) x[,1]))),
           "type"=rep(c("Bias", "Coverage (%)"), each=length(unlist(l_bias))),
           "n"=c(rep(n[1:t], each=length(r)), rep(n[(t+1):length(n)], each=length(r)*4)),
           "r"=round(c(rep(r, t), rep(rep(r, each = 4),2)),2),
           "Weights"=c(rep("Any", length(r)*t), rep(rep(lbs, length(r)),2))
           )
ans$n <- factor(ans$n, levels = c("30","2-50","2/30","2"))
ans$Weights <- factor(ans$Weights, levels = c("Any", "Equal clusters", "Equal obs", "ESS", "Combo"))
ans <- ans[ans$r!=1,]
p1 <- ggplot(ans[ans$type == "Bias",], aes(value, n, color=Weights)) + 
  geom_point(aes(shape=Weights), size=2) + 
  facet_grid(r~type) + xlab(" ") + 
  scale_color_manual(values=c("black", "red", "darkorange", "green", "blue")) +
  scale_shape_manual(values=c(16, 17, 15, 3, 10)) +
  ylab("Cluster size") + 
  scale_x_continuous(limits = c(-0.02,0.02), breaks = c(-0.01,0,0.01),minor_breaks = c(-0.01,0,0.01)) + 
  theme_bw() + theme(strip.text.y = element_blank(),, legend.title = element_blank()) + guides(color=guide_legend(nrow=2,byrow=TRUE))
p2 <- ggplot(ans[ans$type == "Coverage (%)",], aes(value, n, color=Weights)) + 
  geom_point(aes(shape=Weights), size=2) + 
  facet_grid(r~type) + xlab(" ") + 
  scale_color_manual(values=c("black", "red", "darkorange", "green", "blue")) +
  scale_shape_manual(values=c(16, 17, 15, 3, 10)) +
  ylab(" ") + 
  scale_x_continuous(limits = c(90,100), breaks = c(92,95,98), minor_breaks = c(92,95,98))+
  theme_bw() + theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y.right = element_text(angle = 0), legend.title = element_blank()) + guides(color=guide_legend(nrow=2,byrow=TRUE))
ggpubr::ggarrange(p1, p2, ncol=2, common.legend = TRUE)
```


```{r figure2.1, fig.height=9, fig.width=4}
idx <- round(r[c(1,seq(2,11,2))], 2)
p1 <- ggplot(ans[(ans$type == "Bias") & (ans$Weights %in% c("Any","Equal clusters")) & (ans$r %in% idx),], aes(value, n)) + 
  geom_point(size=2) + 
  facet_grid(r~type) + xlab(" ") + 
  ylab("Cluster size") + 
  scale_x_continuous(limits = c(-0.02,0.02), breaks = c(-0.01,0,0.01),minor_breaks = c(-0.01,0,0.01)) + 
  theme_bw() + theme(strip.text.y = element_blank()) 
p2 <- ggplot(ans[(ans$type == "Coverage (%)") & (ans$Weights %in% c("Any","Equal clusters")) & (ans$r %in% idx),], aes(value, n)) + 
  geom_point(size=2) + 
  facet_grid(r~type) + xlab(" ")  +
  ylab(" ") + 
  scale_x_continuous(limits = c(90,100), breaks = c(92,95,98), minor_breaks = c(92,95,98))+
  theme_bw() + theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y.right = element_text(angle = 0))
ggpubr::ggarrange(p1, p2, ncol=2, common.legend = TRUE)
```

## Equal vs. Unequal within-cluster variance 

Let $X_{ij} = U_{i} + R_{ij}$, where $U_i\stackrel{i.i.d}{\sim}N(1,1)$. 

- Equal within-cluster VAR: the within-cluster variance is the same in all clusters of the population; $R_{ij} \stackrel{i.i.d}{\sim} N(0, \sigma^2_r)$, $\rho_I = \sigma^2_u/(\sigma^2_u+\sigma^2_r)$

- Unequal within-cluster VAR + equal cluster contribution: clusters have different within-cluster variance, here we suppose there are two distinct within-cluster variances and the cluster contributions are equal; $R_{ij} \stackrel{i.i.d}{\sim} N(0, 0.5\sigma^2_r)$ and $R_{i'j} \stackrel{i.i.d}{\sim} N(0, 1.5\sigma^2_r)$, $\rho_I = \sigma^2_u/(\sigma^2_u + 0.5\sigma^2_r/2 + 1.5\sigma^2_r/2)$. We sample 2 observations from clusters with within-variance of $0.5\sigma^2_r$ and sample 30 observations from clusters with within-variance of $1.5\sigma^2_r$. 
- Unequal within-cluster VAR + unequal cluster contribution: we still suppose there are two distinct within-cluster variances, the contribution of clusters with within-variance of $0.5\sigma^2_r$ is $2/32$ and the contribution of clusters with within-variance of $1.5\sigma^2_r$ is $30/32$; $R_{ij} \stackrel{i.i.d}{\sim} N(0, 0.5\sigma^2_r)$ and $R_{i'j} \stackrel{i.i.d}{\sim} N(0, 1.5\sigma^2_r)$, $\rho_I = \sigma^2_u/(\sigma^2_u + 0.5\sigma^2_r\times2/32 + 1.5\sigma^2_r\times30/32)$. We again sample 2 observations from clusters with within-variance of $0.5\sigma^2_r$ and sample 30 observations from clusters with within-variance of $1.5\sigma^2_r$.


```{r, fig.width=9, fig.height=4}
load("data/RankICC/output-ICC2-S4-n200.RData")
l_mse <- list()
r <- 6 * asin(seq(0, 1, 0.1)/2)/pi
for(j in 1:4){
  estj <- unlist(lapply(output[[j]], function(x) colMeans(x[,1:4])))
  msej <- matrix(NA, ncol=4, nrow=length(r))
  for(i in seq_along(r)){
      estj <- output[[j]][[i]]
      msej[i,] <- apply(estj[,1:4], 2, function(x) sqrt(mean((x-r[i])^2)))
  }
  l_mse[[j]] <- msej
}
l_mse <- data.frame(do.call(rbind, l_mse))
colnames(l_mse) <-  c("Equal obs", "Equal clusters", "ESS", "Combo")
l_mse$size <- c(rep(c("2-30","2/30"), each=length(r)), rep("2/30", length(r)*2))
l_mse$r <- rep(r, 4)
l_mse$var <- rep(c("Equal within-cluster variances", "Equal within-cluster variances",
                   "Unequal within-cluster variances \n Equal cluster contributions", "Unequal within-cluster variances \n Unequal cluster contributions"), each=length(r))
l_mse <- l_mse %>% gather(type, value, "Equal obs":"Combo")
l_mse$type <- factor(l_mse$type, levels=c("Equal clusters", "Equal obs", "ESS", "Combo"))
ggplot(l_mse, aes(x=r,y=value, color=type, shape=type, linetype=type)) + geom_line(size=0.4) + geom_point()+ facet_grid(~var  + size) +theme_bw() + theme(legend.position = "bottom") +  xlab(TeX("$\\gamma_I$")) + ylab("RMSE") + theme(legend.title = element_blank()) +   guides(color = guide_legend(keywidth = 3))
```


```{r figure4, fig.width=7, fig.height=4}
ggplot(l_mse %>% filter(size == "2/30"), aes(x=r,y=value, shape=type, linetype=type), color="black") + geom_line(size=0.4) + geom_point()+ facet_grid(~var) +theme_classic() + 
  theme(legend.position = "bottom") +  xlab(TeX("$\\gamma_I$")) + ylab("RMSE") + theme(legend.title = element_blank()) +   guides(color = guide_legend(keywidth = 3))
```

## Scenario III $Y_{ij} = exp(U_{i}) + R_{ij}$

In this scenario, let $U_i\stackrel{i.i.d}{\sim}N(1, log(1/2+\sqrt{exp(-2)+1/4}))$. 

```{r figure1.2S, fig.height=14, fig.width=4}
load("data/RankICC/gammaLogClmean.RData")
g <- do.call(rbind,g)
r <- g[,4]
r[1] <- 0; r[length(r)] <- 1

load("data/RankICC/output-ICC2-S3-kFix.RData")
n <- c(25, 50, 100, 200, 500, 1000)
l_bias <- l_coverage <- list()
for(j in seq_along(r)){
  estj <- unlist(lapply(output[[j]], function(x) mean(x[,1])))
  l_bias[[j]] <- estj - r[j]
  l_coverage[[j]] <- do.call(rbind, lapply(output[[j]], function(x) CI_coverage(r[j], x[,1], x[,2])))
}
l_coverage <- do.call(rbind, l_coverage) * 100
ans <- data.frame("value"=c(unlist(l_bias), l_coverage[,1]),
           "type"=rep(c("Bias", "Coverage (%)"), each=nrow(l_coverage)),
           "n"=rep(rep(n, length(r)), 2),
           "r"=round(rep(rep(r, each=length(n)), 2),2),
           "CI"="None")
ans <- rbind(ans,
             data.frame("value"=l_coverage[,2],
             "type"=rep("Coverage (%)", nrow(l_coverage)),
             "n"=rep(n, length(r)),
             "r"=round(rep(r, each=length(n)),2),
             "CI"="Fisher' z transformation")
             )
ans$n <- factor(ans$n, levels = as.character(rev(n)))
ans <- ans[ans$r != 1,]
p1 <- ggplot(ans[ans$type == "Bias",], aes(value, n)) + 
  geom_point() + 
  facet_grid(r~type) + xlab(" ") +
  ylab("Sample size") + 
  scale_x_continuous(limits = c(-0.05,0.05), breaks = c(-0.03,0,0.03),minor_breaks = c(-0.03,0,0.03)) + 
  theme_bw() + 
  theme(strip.text.y = element_blank()) 
p2 <- ggplot(ans[ans$type == "Coverage (%)",], aes(value, n, color=CI)) + 
  geom_point(aes(shape=CI)) + 
  facet_grid(r~type) + 
  xlab(" ") + ylab(" ") +
  scale_color_manual(values=c("purple", "black")) +
  scale_shape_manual(values=c(4, 16)) + 
  scale_x_continuous(limits = c(85,100), breaks = c(90, 92,95,98), minor_breaks = c(90,92,95,98))+ 
  theme_bw() + theme(legend.title=element_blank(), legend.position = "none", axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y.right = element_text(angle = 0))
gridExtra::grid.arrange(p1, p2, ncol=2)

```

```{r figure1.2, fig.height=9, fig.width=4}
idx <- round(r[c(1,seq(2,11,2))], 2)
p1 <- ggplot(ans[(ans$type == "Bias") & (ans$r %in% idx),], aes(value, n)) + 
  geom_point() + 
  facet_grid(r~type) + xlab(" ") +
  ylab("Sample size") + 
  scale_x_continuous(limits = c(-0.05,0.05), breaks = c(-0.03,0,0.03),minor_breaks = c(-0.03,0,0.03)) + 
  theme_bw() + 
  theme(strip.text.y = element_blank()) 
p2 <- ggplot(ans[(ans$type == "Coverage (%)") & (ans$CI=="None") & (ans$r %in% idx),], aes(value, n)) + 
  geom_point() + 
  facet_grid(r~type) + 
  xlab(" ") + ylab(" ") +
  scale_x_continuous(limits = c(85,100), breaks = c(90,92,95,98), minor_breaks = c(90,92,95,98))+ 
  theme_bw() + theme(legend.title=element_blank(), legend.position = "none", axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y.right = element_text(angle = 0))
gridExtra::grid.arrange(p1, p2, ncol=2)
```



```{r figure2.2S, fig.height=14, fig.width=4}
load("data/RankICC/gammaLogClmean.RData")
g <- do.call(rbind,g)
r <- g[,4]
r[1] <- 0; r[length(r)] <- 1

load("data/RankICC/output-ICC2-S3-n200Fix.RData")
n <- c("2","30", "2-50", "2/30")
l_bias <- l_coverage <- list()
t <- 2
#size 2, 30
for(j in 1:t){
  estj <- unlist(lapply(output[[j]], function(x) mean(x[,1])))
  l_bias[[j]] <- estj - r
  p <- matrix(NA, ncol=2, nrow=length(r))
  for(i in seq_along(r)){
    estj <- output[[j]][[i]]
    p[i, ] <- CI_coverage(r[i], estj[,1], estj[,2])
  }
  l_coverage[[j]] <- p * 100
}
l_mse_s1 <- list()
#size 2-50 and 2/30
for(j in (t+1):length(n)){
  estj <- unlist(lapply(output[[j]], function(x) colMeans(x[,1:4])))
  l_bias[[j]] <- estj - rep(r, each = 4)
  p <- list(); msej <- matrix(NA, ncol=4, nrow=length(r))
  for(i in seq_along(r)){
      estj <- output[[j]][[i]]
      p[[i]] <- t(sapply(1:4, function(m) CI_coverage(r[i], estj[,m], estj[,m+4])))
      msej[i,] <- apply(estj[,1:4], 2, function(x) mean((x-r[i])^2))
  }
  l_coverage[[j]] <- do.call(rbind, p) * 100
  l_mse_s1[[j-t]] <- msej
}

lbs <- c("Equal obs", "Equal clusters", "ESS", "Combo")
ans <- data.frame("value"=c(unlist(l_bias), unlist(lapply(l_coverage, function(x) x[,1]))),
           "type"=rep(c("Bias", "Coverage (%)"), each=length(unlist(l_bias))),
           "n"=c(rep(n[1:t], each=length(r)), rep(n[(t+1):length(n)], each=length(r)*4)),
           "r"=round(c(rep(r, t), rep(rep(r, each = 4),2)),2),
           "Weights"=c(rep("Any", length(r)*t), rep(rep(lbs, length(r)),2))
           )
ans$n <- factor(ans$n, levels = c("30","2-50","2/30","2"))
ans$Weights <- factor(ans$Weights, levels = c("Any", "Equal clusters", "Equal obs", "ESS", "Combo"))
ans <- ans[ans$r!=1,]
p1 <- ggplot(ans[ans$type == "Bias",], aes(value, n, color=Weights)) + 
  geom_point(aes(shape=Weights), size=2) + 
  facet_grid(r~type) + xlab(" ") + 
  scale_color_manual(values=c("black", "red", "darkorange", "green", "blue")) +
  scale_shape_manual(values=c(16, 17, 15, 3, 10)) +
  ylab("Cluster size") + 
  scale_x_continuous(limits = c(-0.02,0.02), breaks = c(-0.01,0,0.01),minor_breaks = c(-0.01,0,0.01)) + 
  theme_bw() + theme(strip.text.y = element_blank(),legend.title = element_blank()) + guides(color=guide_legend(nrow=2,byrow=TRUE))
p2 <- ggplot(ans[ans$type == "Coverage (%)",], aes(value, n, color=Weights)) + 
  geom_point(aes(shape=Weights), size=2) + 
  facet_grid(r~type) + xlab(" ") + 
  scale_color_manual(values=c("black", "red", "darkorange", "green", "blue")) +
  scale_shape_manual(values=c(16, 17, 15, 3, 10)) +
  ylab(" ") + 
  scale_x_continuous(limits = c(90,100), breaks = c(92,95,98), minor_breaks = c(92,95,98))+
  theme_bw() + theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y.right = element_text(angle = 0), legend.title = element_blank()) + guides(color=guide_legend(nrow=2,byrow=TRUE))
ggpubr::ggarrange(p1, p2, ncol=2, common.legend = TRUE)
```


```{r figure2.2, fig.height=9, fig.width=4}
idx <- round(r[c(1,seq(2,11,2))], 2)
p1 <- ggplot(ans[(ans$type == "Bias") & (ans$Weights %in% c("Any","Equal clusters")) & (ans$r %in% idx),], aes(value, n)) + 
  geom_point() + 
  facet_grid(r~type) + xlab(" ") + 
  ylab("Cluster size") + 
  scale_x_continuous(limits = c(-0.05,0.05), breaks = c(-0.03,0,0.03),minor_breaks = c(-0.03,0,0.03)) + 
  theme_bw() + theme(strip.text.y = element_blank()) 
p2 <- ggplot(ans[(ans$type == "Coverage (%)") & (ans$Weights %in% c("Any","Equal clusters")) & (ans$r %in% idx),], aes(value, n)) + 
  geom_point() +
  facet_grid(r~type) + xlab(" ")  +
  ylab(" ") + 
  scale_x_continuous(limits = c(90,100), breaks = c(92,95,98), minor_breaks = c(92,95,98))+
  theme_bw() + theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y.right = element_text(angle = 0))
ggpubr::ggarrange(p1, p2, ncol=2, common.legend = TRUE)
```

## Bootstrapping 


- $\gamma_I$= 0.48, equal cluster sizes ($k_{ij}$=30)

```{r}
load("data/RankICC/output-ICC2-kFix-val05.RData")
load("data/RankICC/output-ICC2-Boot200-kFix-val05.RData")

n <- c(25, 50, 100, 200, 500, 1000)
r <- 6 * asin(0.5/2)/pi 
pA <- matrix(NA, ncol=2, nrow = length(n))
pB <- matrix(NA, ncol=4, nrow = length(n))
simest <- matrix(NA, ncol=5, nrow = length(n))
for(i in 1:length(n)){
  t <- output[[i]]
  pA[i,] <- CI_coverage(r, t[,1], t[,2])
  tB <- lapply(outputBoot[[i]], function(x){
      c(sd(x[,1]), sd(x[,2]), 
        quantile(x[,1], c(0.025, 0.975)),
        quantile(x[,2], c(0.025, 0.975)))
    })
  tB <- do.call(rbind, tB)
  l1 <- t[,1] - 1.96 * tB[,1]; u1 <- t[,1] + 1.96 * tB[,1]
  l2 <- t[,1] - 1.96 * tB[,2]; u2 <- t[,1] + 1.96 * tB[,2]   
  pB[i,] <- c(mean((tB[,3]<=r)&(r<=tB[,4])),
                mean((tB[,5]<=r)&(r<=tB[,6])),
              mean((l1<=r)&(r<=u1)), 
                mean((l2<=r)&(r<=u2)))

  simest[i, ] <- c((mean(t[,1])-r)/r*100,sd(t[,1]), 
                   mean(t[,2]), mean(tB[,1]), mean(tB[,2]))
}

df <- cbind(n, pA, pB)
colnames(df) <- c("Size", "Asymptotic SE", "Fisher transformation", "Cluster Bootstrap Percentiles", "Two-stage Bootstrap Percentiles","Cluster Bootstrap SE", "Two-stage Bootstrap SE")
df %>% 
  kbl(digits = 3, align = "c", full.width = F, caption = "Coverage probability") %>% 
  kable_styling(full_width = F)
```


```{r}
simest <- cbind(n, simest)
colnames(simest) <-  c("Size","Percent Bias (%)","Emp.SE","AVG. Asymptotic SE","AVG. Cluster Bootstrap SE", "AVG. Two-stage Bootstrap SE")
simest %>% 
  kbl(digits = 3, align = "c", full.width = F) %>% 
  kable_styling(full_width = F)
```


- $\gamma_I$= 0.09, equal cluster sizes ($k_{ij}$=30)

```{r}
load("data/RankICC/output-ICC2-kFix-val01.RData")
load("data/RankICC/output-ICC2-Boot200-kFix-val01-09.RData")
n <- c(25, 50, 100, 200, 500, 1000)
r <- 6 * asin(0.1/2)/pi 
pA <- matrix(NA, ncol=2, nrow = length(n))
pB <- matrix(NA, ncol=4, nrow = length(n))
simest <- matrix(NA, ncol=5, nrow = length(n))
for(i in 1:length(n)){
  t <- output[[i]]
  pA[i,] <- CI_coverage(r, t[,1], t[,2])
  tB <- lapply(outputBoot[[1]][[i]], function(x){
      c(sd(x[,1]), sd(x[,2]), 
        quantile(x[,1], c(0.025, 0.975)),
        quantile(x[,2], c(0.025, 0.975)))
    })
  tB <- do.call(rbind, tB)
  l1 <- t[,1] - 1.96 * tB[,1]; u1 <- t[,1] + 1.96 * tB[,1]
  l2 <- t[,1] - 1.96 * tB[,2]; u2 <- t[,1] + 1.96 * tB[,2]   
  pB[i,] <- c(mean((tB[,3]<=r)&(r<=tB[,4])),
                mean((tB[,5]<=r)&(r<=tB[,6])),
              mean((l1<=r)&(r<=u1)), 
                mean((l2<=r)&(r<=u2)))

  simest[i, ] <- c((mean(t[,1])-r)/r*100,sd(t[,1]), 
                   mean(t[,2]), mean(tB[,1]), mean(tB[,2]))
}

df <- cbind(n, pA, pB)
colnames(df) <- c("Size", "Asymptotic SE", "Fisher transformation", "Cluster Bootstrap Percentiles", "Two-stage Bootstrap Percentiles", "Cluster Bootstrap SE", "Two-stage Bootstrap SE")
df %>% 
  kbl(digits = 3, align = "c", full.width = F, caption = "Coverage probability") %>% 
  kable_styling(full_width = F)
```


```{r}
simest <- cbind(n, simest)
colnames(simest) <-  c("Size","Percent Bias (%)","Emp.SE","AVG. Asymptotic SE","AVG. Cluster Bootstrap SE", "AVG. Two-stage Bootstrap SE")
simest %>% 
  kbl(digits = 3, align = "c", full.width = F) %>% 
  kable_styling(full_width = F)
```

- $\gamma_I$= 0.89, equal cluster sizes ($k_{ij}$=30)

```{r}
load("data/RankICC/output-ICC2-kFix-val09.RData")
n <- c(25, 50, 100, 200, 500, 1000)
r <- 6 * asin(0.9/2)/pi 
pA <- matrix(NA, ncol=2, nrow = length(n))
pB <- matrix(NA, ncol=4, nrow = length(n))
simest <- matrix(NA, ncol=5, nrow = length(n))
for(i in 1:length(n)){
  t <- output[[i]]
  pA[i,] <- CI_coverage(r, t[,1], t[,2])
  tB <- lapply(outputBoot[[2]][[i]], function(x){
      c(sd(x[,1]), sd(x[,2]), 
        quantile(x[,1], c(0.025, 0.975)),
        quantile(x[,2], c(0.025, 0.975)))
    })
  tB <- do.call(rbind, tB)
  l1 <- t[,1] - 1.96 * tB[,1]; u1 <- t[,1] + 1.96 * tB[,1]
  l2 <- t[,1] - 1.96 * tB[,2]; u2 <- t[,1] + 1.96 * tB[,2]   
  pB[i,] <- c(mean((tB[,3]<=r)&(r<=tB[,4])),
                mean((tB[,5]<=r)&(r<=tB[,6])),
              mean((l1<=r)&(r<=u1)), 
                mean((l2<=r)&(r<=u2)))

  simest[i, ] <- c((mean(t[,1])-r)/r*100,sd(t[,1]), 
                   mean(t[,2]), mean(tB[,1]), mean(tB[,2]))
}

df <- cbind(n, pA, pB)
colnames(df) <- c("Size", "Asymptotic SE", "Fisher transformation", "Cluster Bootstrap Percentiles", "Two-stage Bootstrap Percentiles", "Cluster Bootstrap SE", "Two-stage Bootstrap SE")
df %>% 
  kbl(digits = 3, align = "c", full.width = F, caption = "Coverage probability") %>% 
  kable_styling(full_width = F)
```


```{r}
simest <- cbind(n, simest)
colnames(simest) <-  c("Size","Percent Bias (%)","Emp.SE","AVG. Asymptotic SE","AVG. Cluster Bootstrap SE", "AVG. Two-stage Bootstrap SE")
simest %>% 
  kbl(digits = 3, align = "c", full.width = F) %>% 
  kable_styling(full_width = F)
```


- $\gamma_I$= 0.48, unequal cluster sizes uniformaly range from 2 to 50. 

```{r}
load("data/RankICC/output-ICC2-ncll-2-50-val05.RData")
load("data/RankICC/output-ICC2-Boot200-ncll-2-50-val05.RData")
n <- c(25, 50, 100, 200, 500, 1000)
r <- 6 * asin(0.5/2)/pi 
pA <- matrix(NA, ncol=2, nrow = length(n))
pB <- matrix(NA, ncol=8, nrow = length(n))
simest <- matrix(NA, ncol=10, nrow = length(n))
for(i in 1:length(n)){
  t <- output[[i]]
  pA[i,1] <- CI_coverage(r, t[,1], t[,2], fisher = F)
  pA[i,2] <- CI_coverage(r, t[,3], t[,4], fisher = F)
  tB <- lapply(outputBoot[[i]], function(x){
      c(sd(x[,1]), sd(x[,2]), sd(x[,3]), sd(x[,4]),
        quantile(x[,1], c(0.025, 0.975)),
        quantile(x[,2], c(0.025, 0.975)),
        quantile(x[,3], c(0.025, 0.975)),
        quantile(x[,4], c(0.025, 0.975)))
    })
  tB <- do.call(rbind, tB)
  l1 <- t[,1] - 1.96 * tB[,1]; u1 <- t[,1] + 1.96 * tB[,1]
  l2 <- t[,1] - 1.96 * tB[,2]; u2 <- t[,1] + 1.96 * tB[,2]   
  l3 <- t[,3] - 1.96 * tB[,3]; u3 <- t[,3] + 1.96 * tB[,3]  
  l4 <- t[,3] - 1.96 * tB[,4]; u4 <- t[,3] + 1.96 * tB[,4]  
  pB[i,] <- c(mean((tB[,5]<=r)&(r<=tB[,6])),
              mean((l1<=r)&(r<=u1)),
              mean((tB[,7]<=r)&(r<=tB[,8])),
              mean((l2<=r)&(r<=u2)),
              mean((tB[,9]<=r)&(r<=tB[,10])),
              mean((l3<=r)&(r<=u4)),               
              mean((tB[,11]<=r)&(r<=tB[,12])), 
              mean((l4<=r)&(r<=u4)))

  simest[i, ] <- c((mean(t[,1])-r)/r*100,sd(t[,1]), 
                   mean(t[,2]), mean(tB[,1]), mean(tB[,2]),
                   (mean(t[,3])-r)/r*100,sd(t[,3]),
                   mean(t[,4]), mean(tB[,3]), mean(tB[,4]))
}

df <- cbind(n, pA[,1], pB[,1:4], pA[,2], pB[,5:8])
colnames(df) <- c(" ", rep(c(" ","Percentiles", "SE","Percentiles","SE"), 2))
df %>% 
  kbl(digits = 3, align = "c", full.width = F, caption = "Coverage probability") %>% 
    add_header_above(c(" "=1, "Asym.SE"=1, "Cluster bootstrap"=2,"Two-stage bootstrap"=2, "Asym.SE"=1, "Cluster bootstrap"=2,"Two-stage bootstrap"=2)) %>% 
  add_header_above(c("Size"=1, "Equal clusters"=5,"Equal obs"=5)) %>% 
  kable_styling(full_width = F)
```


```{r}
simest <- cbind(n, simest)
colnames(simest) <-  c(" ","Bias (%)","Emp.SE","Avg.Asym.SE","Avg. cluster bootstrap SE", "Avg. two-stage bootstrap SE","Bias (%)","Emp.SE","Avg.Asym.SE","Avg. cluster bootstrap SE", "Avg. two-stage bootstrap SE")
simest %>% 
  kbl(digits = 3, align = "c", full.width = F) %>% 
  add_header_above(c("Size"=1, "Equal clusters"=5,"Equal obs"=5)) %>% 
  kable_styling(full_width = F)
```


# Simulations of three hierarchies 

Let $X_{ijk}$ be the observation of the $k$th level-1 unit in the $j$th level-2 unit and the $i$th level-3 unit. We used another additive model to generate three-level data; $X_{ijk} = U_i + V_{ij} + R_{ijk}$, where $U_i \stackrel{i.i.d}{\sim} N(1, 20\rho_{I3})$, $V_{ij} \stackrel{i.i.d}{\sim} N(0, 20(\rho_{I2}-\rho_{I3}))$, $R_{ijk} \stackrel{i.i.d}{\sim} N(0,20(1-\rho_{I2}))$, and $(\rho_{2I}, \rho_{3I}) \in \{(0,0),(0.25,0.20),(0.55,0.20),(0.85,0.20),(0.55,0.5), (0.85,0.5),(0.85,0.8)\}$.  


```{r, include=FALSE}
fisherCIdelta <- function(x, s){
  tr <- log((1+x)/(1-x))/2 
  ts <- s/((1+x)*(1-x))
  l <- tr - qnorm(0.975) * ts
  u <- tr + qnorm(0.975) * ts
  l <- (exp(2*l)-1)/(exp(2*l)+1) #tanh()
  u <- (exp(2*u)-1)/(exp(2*u)+1)
  cbind(l,u)
}

CI_coverage <- function(r, x, s, fisher=T, tol=1e-7){
  l <- x - qnorm(0.975) * s 
  u <- x + qnorm(0.975) * s
  p <- mean((l - tol  <= r) & (r <= u + tol))
  if(fisher){
    ci <- fisherCIdelta(x, s)
    p <- c(mean((l - tol  <= r) & (r <= u + tol)),
           mean((ci[,1] - tol <= r) & (r <= ci[,2] + tol)))
  }
  return(p)
}
```


### Fixed cluster sizes: 15 level-2 units per level-3 unit, 2 observations per level-2 unit

```{r figure3.1S, fig.height=10, fig.width=7}
load("data/RankICC/output-ICC3-kFix-15-2.RData")
n <- c(25, 50, 100, 200, 500, 1000)
# r2 <- c(0, 0.25, 0.55, 0.85, 0.55, 0.85, 0.85, 1)
# r3 <- c(0, 0.20, 0.20, 0.20, 0.50, 0.50, 0.80, 1)
v3s <- c(0, 4, 4, 4, 10, 10, 16, 2)
v2s <- c(0, 1, 7, 13, 1, 7, 1, 0)
v1s <- c(1, 15, 9, 3, 9, 3, 3, 0)
r3 <- v3s / (v3s + v2s + v1s)
r2 <- (v3s + v2s) / (v3s + v2s + v1s)
r3 <- 6 * asin(r3/2)/pi 
r2 <- 6 * asin(r2/2)/pi 
l_coverage <- l_bias <- l_empSE <- l_avgSE <- l_est <- list()
for(i in seq_along(r2)){
  est <- do.call(rbind, lapply(output[[i]], function(x) colMeans(x[,c(1,3)])))
  l_bias[[i]] <- cbind(est[,1] - r2[i], est[,2] - r3[i])

  l_coverage[[i]] <- cbind(do.call(rbind, lapply(output[[i]], function(x) CI_coverage(r2[i],x[,1],x[,2]))),
                           do.call(rbind, lapply(output[[i]], function(x) CI_coverage(r3[i],x[,3],x[,4]))))
  # 
  # l_avgSE[[i]] <- do.call(rbind, lapply(output[[i]], function(x) colMeans(x[, c(2,4)])))
  # l_est[[i]] <- do.call(rbind, lapply(output[[i]], function(x) colMeans(x[, c(1,3)])))  
  # l_empSE[[i]] <- do.call(rbind, lapply(output[[i]], function(x) apply(x[,c(1,3)], 2, sd)))
  
}
r <- paste("(",round(r2,2),",",round(r3,2),")",sep="")
ans <- data.frame(rep(n, length(r2)),
                  rep(r, each=length(n)),
                  do.call(rbind, l_bias),
                  do.call(rbind, l_coverage) * 100)
colnames(ans) <- c("n","r",rep("Bias",2), rep("Coverage (%)", 4))
ans <- rbind(ans[,c(1:2,3,5)] %>% mutate(CI="None"), 
             ans[,c(1:2,3,6)] %>% mutate(CI="Fisher"),
             ans[,c(1:2,4,7)] %>% mutate(CI="None"),
             ans[,c(1:2,4,8)]%>% mutate(CI="Fisher")
             )
ans$n <- factor(ans$n, levels=sort(n,decreasing = T))
ans$r <- factor(ans$r, levels = c("(0,0)","(0.24,0.19)","(0.53,0.19)","(0.84,0.19)","(0.53,0.48)","(0.84,0.48)","(0.84,0.79)", "(1,1)"))
ans$param_r <- rep(c("r2","r3"), each=nrow(ans)/2)
ans <- ans %>% gather(key, value, c("Bias", "Coverage (%)"))
ans <- ans %>% filter(r != "(1,1)")
levels(ans$r) <- c("(0,0)" = TeX("$(0,0)$"),"(0.24,0.19)" = TeX("$(0.24,0.19)$"), "(0.53,0.19" = TeX("$(0.53,0.19)$"),"(0.84,0.19)" = TeX("$(0.84,0.19)$"), "(0.53,0.48)" = TeX("$(0.53,0.48)$"), "(0.84,0.48)" = TeX("$(0.84,0.48)$"), "(0.84,0.79)" = TeX("$(0.84,0.79)$"), "(1,1)" = TeX("$(1,1)$"))

p <- ans[(ans$key == "Bias")&(ans$param_r=="r2"),] %>% mutate(key="r2 Bias", key=factor(key))
levels(p$key) <- c("r2 Bias" = TeX("$\\gamma_2\\;Bias$"))
p1 <- ggplot(p, aes(value, n)) + 
  geom_point() + 
  facet_grid(r~ key,labeller = label_parsed) + xlab(" ") +
  ylab("Sample size") + 
  scale_x_continuous(limits = c(-0.05,0.05), breaks = c(-0.03,0,0.03),minor_breaks = c(-0.03,0,0.03))  + 
  theme_bw() + theme(strip.text.y = element_blank())

p <- ans[(ans$key == "Coverage (%)")&(ans$param_r=="r2"),] %>% mutate(key="r2 Coverage (%)", key=factor(key))
levels(p$key) <- c("r2 Coverage (%)" = TeX("$\\gamma_2\\;Coverage (\\%)$"))
p2 <- ggplot(p, aes(value, n)) + 
  geom_point(aes(color=CI, shape=CI)) + 
  facet_grid(r~ key,labeller = label_parsed) + xlab(" ") + 
  scale_color_manual(values=c("purple","black")) +
  scale_shape_manual(values=c(4, 16)) + 
  ylab(" ") + 
  scale_x_continuous(limits = c(90,100), breaks = c(92,95,98),minor_breaks = c(92,95,98)) +
  theme_bw() + 
  theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(), strip.text.y = element_blank(), legend.position = "none") 

p <- ans[(ans$key == "Bias")&(ans$param_r=="r3"),] %>% mutate(key="r3 Bias", key=factor(key))
levels(p$key) <- c("r3 Bias" = TeX("$\\gamma_3\\;Bias$"))
p3 <- ggplot(p, aes(value, n)) + 
  geom_point() + 
  facet_grid(r~ key,labeller = label_parsed) + xlab(" ") +
  ylab(" ") + 
  scale_x_continuous(limits = c(-0.05,0.05), breaks = c(-0.03,0,0.03),minor_breaks = c(-0.03,0,0.03))  + 
  theme_bw() +  theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(), strip.text.y = element_blank(), legend.position = "none") 

p <- ans[(ans$key == "Coverage (%)")&(ans$param_r=="r3"),] %>% mutate(key="r3 Coverage (%)", key=factor(key))
levels(p$key) <- c("r3 Coverage (%)" = TeX("$\\gamma_3\\;Coverage (\\%)$"))
p4 <- ggplot(p, aes(value, n, color=CI)) + 
  geom_point(aes(shape=CI)) + 
  facet_grid(r~ key,labeller = label_parsed) + xlab(" ") + 
  scale_color_manual(values=c("purple","black")) +
  scale_shape_manual(values=c(4, 16)) + 
  ylab(" ") + 
  scale_x_continuous(limits = c(88,100), breaks = c(92,95,98),minor_breaks = c(92,95,98)) +
  theme_bw()+ 
  theme(legend.title=element_blank(), legend.position = "none", axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y.right = element_text(angle = 0))

ggpubr::ggarrange(p1, p2,p3,p4,ncol=4, widths=c(1.4,1.2,1.2,1.7))


```



```{r figure3.1, fig.height=10, fig.width=7.5}
p <- ans[(ans$key == "Coverage (%)")&(ans$param_r=="r2")&(ans$CI=="None"),] %>% mutate(key="r2 Coverage (%)", key=factor(key))
levels(p$key) <- c("r2 Coverage (%)" = TeX("$\\gamma_2\\;Coverage (\\%)$"))
p2 <- ggplot(p, aes(value, n)) +
  geom_point() +
  facet_grid(r~key,labeller = label_parsed) + xlab(" ") +
  ylab(" ") +
  scale_x_continuous(limits = c(90,100), breaks = c(92,95,98),minor_breaks = c(92,95,98)) +
  theme_bw() +
  theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(), strip.text.y = element_blank(), legend.position = "none")

p <- ans[(ans$key == "Coverage (%)")&(ans$param_r=="r3")&(ans$CI=="None"),] %>% mutate(key="r3 Coverage (%)", key=factor(key))
levels(p$key) <- c("r3 Coverage (%)" = TeX("$\\gamma_3\\;Coverage (\\%)$"))
p4 <- ggplot(p, aes(value, n)) +
  geom_point() +
  facet_grid(r~ key,labeller = label_parsed) + xlab(" ") +
  ylab(" ") +
  scale_x_continuous(limits = c(88,100), breaks = c(92,95,98),minor_breaks = c(92,95,98)) +
  theme_bw()+
  theme(legend.title=element_blank(), legend.position = "none", axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y.right = element_text(angle = 0))

ggpubr::ggarrange(p1, p2,p3,p4,ncol=4, widths=c(1.4,1.2,1.2,1.7))
```

### The sample size (the number of level-3 units) is 200. 

```{r figure3.2S, fig.height=10, fig.width=7.5}
load("data/RankICC/output-ICC3-varCLS-n200.RData")
v3s <- c(0, 4, 4, 4, 10, 10, 16, 2)
v2s <- c(0, 1, 7, 13, 1, 7, 1, 0)
v1s <- c(1, 15, 9, 3, 9, 3, 3, 0)
r3 <- v3s / (v3s + v2s + v1s)
r2 <- (v3s + v2s) / (v3s + v2s + v1s)
r3 <- 6 * asin(r3/2)/pi 
r2 <- 6 * asin(r2/2)/pi 
l_coverage <- l_bias <- list()
l_empSE <- l_estSE <- list()
cll <- c("(2,2)", "(15,2)","(2,15)","(15,15)")
for(i in seq_along(cll)){
  est <- do.call(rbind, lapply(output[[i]], function(x) colMeans(x[,c(1,3)])))
  l_bias[[i]] <- est - cbind(r2, r3)
  p <- matrix(NA, ncol=4, nrow = length(r2))
  for(j in seq_along(r2)){
    estj <- output[[i]][[j]]
    p[j,1:2] <- CI_coverage(r2[j], estj[,1], estj[,2])
    p[j,3:4] <- CI_coverage(r3[j], estj[,3], estj[,4])
  }
  l_coverage[[i]] <- p * 100
}
ans <- data.frame(do.call(rbind, l_bias),do.call(rbind, l_coverage))
colnames(ans) <- c("r2.bias","r3.bias","r2.CI", "r2.fisherCI","r3.CI", "r3.fisherCI")
ans$cll <- rep(cll, each=length(r2))
r <- paste("(",round(r2,2),",",round(r3,2),")",sep="")
ans$r <- rep(r, length(cll))
ans <- rbind(ans %>% select(cll, r, r2.bias, r2.CI, r2.fisherCI) %>% 
        rename(Bias=r2.bias, CI=r2.CI, fisher=r2.fisherCI) %>% 
        gather(type, value,"Bias":"fisher") %>% 
        mutate(param_r = "r2"),
        ans %>% select(cll, r, r3.bias, r3.CI, r3.fisherCI) %>% 
        rename(Bias=r3.bias, CI=r3.CI, fisher=r3.fisherCI) %>% 
        gather(type, value,"Bias":"fisher") %>% 
        mutate(param_r = "r3"))
ans <- ans %>% mutate(key = ifelse(type=="Bias","Bias", "Coverage (%)"))
# ans <- ans %>% mutate(key = ifelse(type=="Bias","Bias", "Coverage (%)")) %>% 
#   filter(r != "(1,1)")
ans$r <- factor(ans$r, levels = c("(0,0)","(0.24,0.19)","(0.53,0.19)","(0.84,0.19)","(0.53,0.48)","(0.84,0.48)","(0.84,0.79)","(1,1)"))
ans$type <- factor(ans$type, levels = c("Bias", "CI", "fisher"))
ans <- ans %>% filter(r != "(1,1)")       

levels(ans$r) <- c("(0,0)" = TeX("$(0,0)$"),"(0.24,0.19)" = TeX("$(0.24,0.19)$"), "(0.53,0.19" = TeX("$(0.53,0.19)$"),"(0.84,0.19)" = TeX("$(0.84,0.19)$"), "(0.53,0.48)" = TeX("$(0.53,0.48)$"), "(0.84,0.48)" = TeX("$(0.84,0.48)$"), "(0.84,0.79)" = TeX("$(0.84,0.79)$"), "(1,1)" = TeX("$(1,1)$"))

p <- ans[(ans$key == "Bias")&(ans$param_r=="r2"),] %>% mutate(key="r2 Bias", key=factor(key))
levels(p$key) <- c("r2 Bias" = TeX("$\\gamma_2\\;Bias$"))
p1 <- ggplot(p, aes(value, cll)) + 
  geom_point() + 
  facet_grid(r~key, labeller = label_parsed) + xlab(" ") +
  ylab("Cluster size") + 
  scale_x_continuous(limits = c(-0.05,0.05), breaks = c(-0.03,0,0.03),minor_breaks = c(-0.03,0,0.03)) + 
  theme_bw() + theme(strip.text.y = element_blank())

p <- ans[(ans$key == "Coverage (%)")&(ans$param_r=="r2"),] %>% mutate(key="r2 Coverage (%)", key=factor(key))
levels(p$key) <- c("r2 Coverage (%)" = TeX("$\\gamma_2\\;Coverage (\\%)$"))
p2 <- ggplot(p, aes(value, cll, color=type, shape=type)) + 
  geom_point() + 
  facet_grid(r~key, labeller = label_parsed) + xlab(" ") + 
  ylab(" ") + scale_color_manual(values=c("black","purple")) +
  scale_shape_manual(values=c(16, 4)) + 
   scale_x_continuous(limits = c(90,100), breaks = c(92,95,98),minor_breaks = c(92,95,98)) +
  theme_bw() + theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(), strip.text.y = element_blank(), legend.position = "none") 

p <- ans[(ans$key == "Bias")&(ans$param_r=="r3"),] %>% mutate(key="r3 Bias", key=factor(key))
levels(p$key) <- c("r3 Bias" = TeX("$\\gamma_3\\;Bias$"))
p3 <- ggplot(p , aes(value, cll)) + 
  geom_point() + 
  facet_grid(r~key, labeller = label_parsed) + xlab(" ") + ylab(" ") + 
  scale_x_continuous(limits = c(-0.05,0.05), breaks = c(-0.03,0,0.03),minor_breaks = c(-0.03,0,0.03))  + 
  theme_bw() + theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y = element_blank()) 


p <- ans[(ans$key == "Coverage (%)")&(ans$param_r=="r3"),] %>% mutate(key="r3 Coverage (%)", key=factor(key))
levels(p$key) <- c("r3 Coverage (%)" = TeX("$\\gamma_3\\;Coverage (\\%)$"))
p4 <- ggplot(p, aes(value, cll, color=type, shape=type)) + 
  geom_point() + 
  facet_grid(r~key, labeller = label_parsed) + xlab(" ") + 
  ylab(" ") +  scale_color_manual(values=c("black","purple")) +
  scale_shape_manual(values=c(16, 4)) + 
  scale_x_continuous(limits = c(90,100), breaks = c(92,95,98),minor_breaks = c(92,95,98))+
  theme_bw() +  theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y.right = element_text(angle = 0), legend.position = "none") 
  
ggpubr::ggarrange(p1, p2,p3,p4,ncol=4, widths=c(1.6,1.2,1.2,1.7))

```

```{r figure3.2, fig.height=10, fig.width=7.5}
p <-ans[(ans$key == "Coverage (%)")&(ans$param_r=="r2")&(ans$type=="CI"),] %>% mutate(key="r2 Coverage (%)", key=factor(key))
levels(p$key) <- c("r2 Coverage (%)" = TeX("$\\gamma_2\\;Coverage (\\%)$"))
p2 <- ggplot(p, aes(value, cll)) +
  geom_point() +
  facet_grid(r~key, labeller = label_parsed) + xlab(" ") +
  ylab(" ") +
   scale_x_continuous(limits = c(90,100), breaks = c(92,95,98),minor_breaks = c(92,95,98)) +
  theme_bw() + theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(), strip.text.y = element_blank(), legend.position = "none")

p <- ans[(ans$key == "Coverage (%)")&(ans$param_r=="r3")&(ans$type=="CI"),] %>% mutate(key="r3 Coverage (%)", key=factor(key))
levels(p$key) <- c("r3 Coverage (%)" = TeX("$\\gamma_3\\;Coverage (\\%)$"))
p4 <- ggplot(p, aes(value, cll)) +
  geom_point() +
  facet_grid(r~key,labeller = label_parsed) + xlab(" ") +
  ylab(" ") +
  scale_x_continuous(limits = c(90,100), breaks = c(92,95,98),minor_breaks = c(92,95,98))+
  theme_bw() +  theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y.right = element_text(angle = 0), legend.position = "none")
ggpubr::ggarrange(p1, p2,p3,p4,ncol=4, widths=c(1.6,1.2,1.2,1.7))
```


### Unequal cluster sizes

```{r figure3.3S, fig.height=10, fig.width=7.5}
load("data/RankICC/output-ICC3-varCLS-unequal-n200.RData")
v3s <- c(0, 4, 4, 4, 10, 10, 16, 2)
v2s <- c(0, 1, 7, 13, 1, 7, 1, 0)
v1s <- c(1, 15, 9, 3, 9, 3, 3, 0)
r3 <- v3s / (v3s + v2s + v1s)
r2 <- (v3s + v2s) / (v3s + v2s + v1s)
r3 <- 6 * asin(r3/2)/pi 
r2 <- 6 * asin(r2/2)/pi 
l_coverage3 <- l_bias3 <- list()
l_coverage2 <- l_bias2 <- list()
l_coverage1 <- l_bias1 <- list()
cll <- c("(2-15, 2)", "(2/15, 2)","(2, 2-15)","(2, 2/15)", "(2/15, 2/15)")
for(i in 1:5){
  #equal 3
  est <- do.call(rbind, lapply(output[[i]], function(x) colMeans(x[,c(1,3)])))
  l_bias3[[i]] <- est - cbind(r2, r3)
  p <- matrix(NA, ncol=2, nrow = length(r2))
  for(j in seq_along(r2)){
    estj <- output[[i]][[j]]
    p[j,1] <- CI_coverage(r2[j], estj[,1], estj[,2], fisher = F)
    p[j,2] <- CI_coverage(r3[j], estj[,3], estj[,4], fisher = F)
  }
  l_coverage3[[i]] <- p * 100
  
  #equal 2
  est <- do.call(rbind, lapply(output[[i]], function(x) colMeans(x[,c(5,7)])))
  l_bias2[[i]] <- est - cbind(r2, r3)
  p <- matrix(NA, ncol=2, nrow = length(r2))
  for(j in seq_along(r2)){
    estj <- output[[i]][[j]]
    p[j,1] <- CI_coverage(r2[j], estj[,5], estj[,6], fisher = F)
    p[j,2] <- CI_coverage(r3[j], estj[,7], estj[,8], fisher = F)
  }
  l_coverage2[[i]] <- p * 100
  
  #equal 1
  est <- do.call(rbind, lapply(output[[i]], function(x) colMeans(x[,c(9,11)])))
  l_bias1[[i]] <- est - cbind(r2, r3)
  p <- matrix(NA, ncol=2, nrow = length(r2))
  for(j in seq_along(r2)){
    estj <- output[[i]][[j]]
    p[j,1] <- CI_coverage(r2[j], estj[,9], estj[,10], fisher = F)
    p[j,2] <- CI_coverage(r3[j], estj[,11], estj[,12], fisher = F)
  }
  l_coverage1[[i]] <- p * 100
}
ans <- data.frame(rbind(do.call(rbind, l_bias1),do.call(rbind, l_bias2),do.call(rbind, l_bias3)),
                  rbind(do.call(rbind, l_coverage1), do.call(rbind, l_coverage2), do.call(rbind, l_coverage3)))
colnames(ans) <- c("r2.bias","r3.bias","r2.CI", "r3.CI")
ans$cll <- rep(rep(cll, each=length(r2)), 3)
ans$Weights <- rep(c("Equal level-1", "Equal level-2", "Equal level-3"), each = length(cll) * length(r2))
r <- paste("(",round(r2,2),",",round(r3,2),")",sep="")
ans$r <- rep(rep(r, length(cll)), 3)
ans <- rbind(ans %>% select(cll, r, r2.bias, r2.CI, Weights) %>% 
        rename(Bias=r2.bias, CI=r2.CI) %>% 
        gather(type, value,"Bias":"CI") %>% 
        mutate(param_r = "r2"),
        ans %>% select(cll, r, r3.bias, r3.CI, Weights) %>% 
        rename(Bias=r3.bias, CI=r3.CI) %>% 
        gather(type, value,"Bias":"CI") %>% 
        mutate(param_r = "r3"))
ans <- ans %>% mutate(key = ifelse(type=="Bias","Bias", "Coverage (%)"))
ans$r <- factor(ans$r, levels = c("(0,0)","(0.24,0.19)","(0.53,0.19)","(0.84,0.19)","(0.53,0.48)","(0.84,0.48)","(0.84,0.79)","(1,1)"))
ans$cll<- factor(ans$cll, levels =  rev(c("(2-15, 2)", "(2/15, 2)","(2, 2-15)","(2, 2/15)", "(2/15, 2/15)")))
# ans$type <- factor(ans$type, levels = c("Bias", "CI", "fisher"))
ans <- ans %>% filter(r != "(1,1)")          
levels(ans$r) <- c("(0,0)" = TeX("$(0,0)$"),"(0.24,0.19)" = TeX("$(0.24,0.19)$"), "(0.53,0.19" = TeX("$(0.53,0.19)$"),"(0.84,0.19)" = TeX("$(0.84,0.19)$"), "(0.53,0.48)" = TeX("$(0.53,0.48)$"), "(0.84,0.48)" = TeX("$(0.84,0.48)$"), "(0.84,0.79)" = TeX("$(0.84,0.79)$"), "(1,1)" = TeX("$(1,1)$"))

p <- ans[(ans$key == "Bias")&(ans$param_r=="r2"),] %>% mutate(key="r2 Bias", key=factor(key))
levels(p$key) <- c("r2 Bias" = TeX("$\\gamma_2\\;Bias$"))
p1 <- ggplot(p, aes(value, cll)) + 
  geom_point(aes(color=Weights, shape=Weights)) + 
  facet_grid(r~key, labeller = label_parsed) + xlab(" ") +
  scale_color_manual(values=c("red", "green", "blue")) +
  scale_shape_manual(values=c( 15, 3, 10)) +
  ylab("Cluster size") + 
  scale_x_continuous(limits = c(-0.02,0.02), breaks = c(-0.01,0,0.01),minor_breaks = c(-0.01,0,0.01)) + 
  theme_bw() + theme(strip.text.y = element_blank())

p <- ans[(ans$key == "Coverage (%)")&(ans$param_r=="r2"),] %>% mutate(key="r2 Coverage (%)", key=factor(key))
levels(p$key) <- c("r2 Coverage (%)" = TeX("$\\gamma_2\\;Coverage (\\%)$"))
p2 <- ggplot(p, aes(value, cll)) + 
  geom_point(aes(color=Weights, shape=Weights)) + 
  facet_grid(r~key,labeller = label_parsed) + xlab(" ") + 
  ylab(" ") + 
  scale_color_manual(values=c("red", "green", "blue")) +
  scale_shape_manual(values=c( 15, 3, 10)) +
  scale_x_continuous(limits = c(90,100), breaks = c(92,95,98),minor_breaks = c(92,95,98)) +
  theme_bw() + theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(), strip.text.y = element_blank(), legend.position = "none") 

p <- ans[(ans$key == "Bias")&(ans$param_r=="r3"),] %>% mutate(key="r3 Bias", key=factor(key))
levels(p$key) <- c("r3 Bias" = TeX("$\\gamma_3\\;Bias$"))
p3 <- ggplot(p, aes(value, cll)) + 
  geom_point(aes(color=Weights, shape=Weights)) + 
  facet_grid(r~key,labeller = label_parsed) + xlab(" ") + ylab(" ") + 
  scale_color_manual(values=c("red", "green", "blue")) +
  scale_shape_manual(values=c( 15, 3, 10)) +
  scale_x_continuous(limits = c(-0.02,0.02), breaks = c(-0.01,0,0.01),minor_breaks = c(-0.01,0,0.01)) + 
  theme_bw() + theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y = element_blank()) 

p <- ans[(ans$key == "Coverage (%)")&(ans$param_r=="r3"),] %>% mutate(key="r3 Coverage (%)", key=factor(key))
levels(p$key) <- c("r3 Coverage (%)" = TeX("$\\gamma_3\\;Coverage (\\%)$"))
p4 <- ggplot(p, aes(value, cll)) + 
  geom_point(aes(color=Weights, shape=Weights)) + 
  facet_grid(r~key,labeller = label_parsed) + xlab(" ") + 
  ylab(" ") +  
  scale_color_manual(values=c("red", "green", "blue")) +
  scale_shape_manual(values=c( 15, 3, 10)) +
  scale_x_continuous(limits = c(90,100), breaks = c(92,95,98),minor_breaks = c(92,95,98))+
  theme_bw() +  theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y.right = element_text(angle = 0), legend.position = "none") 
  
ggpubr::ggarrange(p1, p2,p3,p4,ncol=4, widths=c(1.7,1.2,1.2,1.7), common.legend = T)

```


```{r figure3.3, fig.height=10, fig.width=7.5}
######Equal level 3 figure
ans <- ans %>% filter(Weights == "Equal level-3")

p <- ans[(ans$key == "Bias")&(ans$param_r=="r2"),] %>% mutate(key="r2 Bias", key=factor(key))
levels(p$key) <- c("r2 Bias" = TeX("$\\gamma_2\\;Bias$"))
p1 <- ggplot(p, aes(value, cll)) + 
  geom_point() + 
  facet_grid(r~key, labeller = label_parsed) + xlab(" ") +
  ylab("Cluster size") + 
  scale_x_continuous(limits = c(-0.05,0.05), breaks = c(-0.03,0,0.03),minor_breaks = c(-0.03,0,0.03))  + 
  theme_bw() + theme(strip.text.y = element_blank())

p <- ans[(ans$key == "Coverage (%)")&(ans$param_r=="r2"),] %>% mutate(key="r2 Coverage (%)", key=factor(key))
levels(p$key) <- c("r2 Coverage (%)" = TeX("$\\gamma_2\\;Coverage (\\%)$"))
p2 <- ggplot(p, aes(value, cll)) + 
  geom_point() + 
  facet_grid(r~key,labeller = label_parsed) + xlab(" ") + 
  ylab(" ") + 
  scale_x_continuous(limits = c(90,100), breaks = c(92,95,98),minor_breaks = c(92,95,98)) +
  theme_bw() + theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(), strip.text.y = element_blank(), legend.position = "none") 

p <- ans[(ans$key == "Bias")&(ans$param_r=="r3"),] %>% mutate(key="r3 Bias", key=factor(key))
levels(p$key) <- c("r3 Bias" = TeX("$\\gamma_3\\;Bias$"))
p3 <- ggplot(p, aes(value, cll)) + 
  geom_point() + 
  facet_grid(r~key,labeller = label_parsed) + xlab(" ") + ylab(" ") + 
  scale_x_continuous(limits = c(-0.05,0.05), breaks = c(-0.03,0,0.03),minor_breaks = c(-0.03,0,0.03)) + 
  theme_bw() + theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y = element_blank()) 

p <- ans[(ans$key == "Coverage (%)")&(ans$param_r=="r3"),] %>% mutate(key="r3 Coverage (%)", key=factor(key))
levels(p$key) <- c("r3 Coverage (%)" = TeX("$\\gamma_3\\;Coverage (\\%)$"))
p4 <- ggplot(p, aes(value, cll)) + 
  geom_point() + 
  facet_grid(r~key,labeller = label_parsed) + xlab(" ") + 
  ylab(" ") +  
  scale_x_continuous(limits = c(90,100), breaks = c(92,95,98),minor_breaks = c(92,95,98))+
  theme_bw() +  theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y.right = element_text(angle = 0), legend.position = "none") 
  
ggpubr::ggarrange(p1, p2,p3,p4,ncol=4, widths=c(1.7,1.2,1.2,1.7), common.legend = T)

```


### Performance of Bootstrap methods 

- $\gamma_2=0.53, \gamma_3=0.19$
- cluster sizes: 15 level-2 units per level-3 unit, 2 observations per level-2 unit
- 200 replicates per bootstrap, 1000 simulations

#### Results of $\gamma_2$

```{r}
load("data/RankICC/output-ICC3-kFix-15-2.RData")
output <- output[[3]]
load("data/RankICC/output-ICC3-Boot200-15-2-val3.RData")
n <- c(25, 50, 100, 200, 500, 1000)
r <- 6 * asin(c(0.55, 0.20)/2)/pi 
pA2 <- pA3 <- matrix(0, ncol = 2, nrow = length(n))
pB2 <- pB3 <- matrix(0, ncol = 6, nrow = length(n))
simest2 <- simest3 <- matrix(0, ncol = 6, nrow = length(n))
for(i in 1:length(n)){
  t <- output[[i]]
  pA2[i,] <- CI_coverage(r[1], t[,1], t[,2])
  tB <- lapply(outputBoot[[i]], function(x){
      c(sd(x[,1]), sd(x[,3]), sd(x[,5]),
        quantile(x[,1], c(0.025, 0.975)),
        quantile(x[,3], c(0.025, 0.975)),
        quantile(x[,5], c(0.025, 0.975)))
    })
  tB <- do.call(rbind, tB)
  pB2[i,] <- c(apply(tB[,1:3], 2, function(x) CI_coverage(r[1], t[,1], x, fisher = F)),
    mean((tB[,4]<=r[1])&(r[1]<=tB[,5])),
    mean((tB[,6]<=r[1])&(r[1]<=tB[,7])),
    mean((tB[,8]<=r[1])&(r[1]<=tB[,9])))

  simest2[i, ] <- c((mean(t[,1])-r[1])/r[1]*100, sd(t[,1]), 
                   mean(t[,2]), mean(tB[,1]), mean(tB[,2]), mean(tB[,3]))

  pA3[i,] <- CI_coverage(r[2], t[,3], t[,4])
  tB <- lapply(outputBoot[[i]], function(x){
      c(sd(x[,2]), sd(x[,4]), sd(x[,6]),
        quantile(x[,2], c(0.025, 0.975)),
        quantile(x[,4], c(0.025, 0.975)),
        quantile(x[,6], c(0.025, 0.975)))
    })
  tB <- do.call(rbind, tB)
  pB3[i,] <- c(apply(tB[,1:3], 2, function(x) CI_coverage(r[2], t[,3], x, fisher = F)),
    mean((tB[,4]<=r[2])&(r[2]<=tB[,5])),
    mean((tB[,6]<=r[2])&(r[2]<=tB[,7])),
    mean((tB[,8]<=r[2])&(r[2]<=tB[,9])))

  simest3[i, ] <- c((mean(t[,3])-r[2])/r[2]*100, sd(t[,3]), 
                   mean(t[,4]), mean(tB[,1]), mean(tB[,2]), mean(tB[,3]))
  
}
df2 <- cbind(n, pA2, pB2)
colnames(df2) <- c("Size", "Asymptotic SE", "Fisher transformation", "Cluster Bootstrap SE", "Two-stage Bootstrap SE", "Three-stage Bootstrap SE",
                   "Cluster Bootstrap Percentiles", "Two-stage Bootstrap Percentiles", "Three-stage Bootstrap Percentiles")
df2 %>%
  kbl(digits = 3, align = "c", full.width = F, caption = "Coverage probability") %>%
  kable_styling(full_width = F)
```                                                                                                        


```{r}
simest2 <- cbind(n, simest2)
colnames(simest2) <- c("Size","Percent Bias (%)","Emp.SE","AVG. Asymptotic SE","AVG. Cluster Bootstrap SE", "AVG. Two-stage Bootstrap SE", "AVG. Three-stage Bootstrap SE")
simest2 %>%
  kbl(digits = 3, align = "c", full.width = F) %>% 
  kable_styling(full_width = F)
```


```{r, fig.height=8}
n <- c(25, 50, 100, 200, 500, 1000)
par(mfrow=c(3,3))
for(j in seq_along(n)){
  m3 <- m2 <- m1 <- rep(NA, 1000)
  for(i in 1:1000){
    m1[i] <- median(outputBoot[[j]][[i]][,1])
    m2[i] <- median(outputBoot[[j]][[i]][,3])
    m3[i] <- median(outputBoot[[j]][[i]][,5])
  }
  hist(m1, breaks=25, xlab="Bootstrap Median", main = paste("n=",n[j],", Cluster bootstrap", sep=""), xlim=c(0.2,0.9))
  abline(v=r[1],col="red")
  abline(v=median(m1), col="green")
  
  hist(m2, breaks=25, xlab="Bootstrap Median", main = paste("n=",n[j],", Two-stage bootstrap", sep=""), xlim=c(0.2,0.9))
  abline(v=r[1],col="red")
  abline(v=median(m2), col="green")
  
  hist(m3, breaks=25, xlab="Bootstrap Median", main = paste("n=",n[j],", Three-stage bootstrap", sep=""), xlim=c(0.2,0.9))
  abline(v=r[1],col="red")
  abline(v=median(m3), col="green")
  
}
```


#### Results of $\gamma_3$

```{r}
df3 <- cbind(n, pA3, pB3)
colnames(df3) <- c("Size", "Asymptotic SE",  "Fisher transformation", "Cluster Bootstrap SE", "Two-stage Bootstrap SE", "Three-stage Bootstrap SE",
                   "Cluster Bootstrap Percentiles", "Two-stage Bootstrap Percentiles", "Three-stage Bootstrap Percentiles")
df3 %>%
  kbl(digits = 3, align = "c", full.width = F, caption = "Coverage probability")%>%
  kable_styling(full_width = F)
```


```{r}
simest3 <- cbind(n, simest3)
colnames(simest3) <- c("Size","Percent Bias (%)","Emp.SE","AVG. Asymptotic SE","AVG. Cluster Bootstrap SE", "AVG. Two-stage Bootstrap SE", "AVG. Three-stage Bootstrap SE")
simest3 %>%
  kbl(digits = 3, align = "c", full.width = F) %>% 
  kable_styling(full_width = F)
```



```{r, fig.height=8}
n <- c(25, 50, 100, 200, 500, 1000)
par(mfrow=c(3,3))
for(j in seq_along(n)){
  m3 <- m2 <- m1 <- rep(NA, 1000)
  for(i in 1:1000){
    m1[i] <- median(outputBoot[[j]][[i]][,2])
    m2[i] <- median(outputBoot[[j]][[i]][,4])
    m3[i] <- median(outputBoot[[j]][[i]][,6])
  }
  hist(m1, breaks=30, xlab="Bootstrap Median", main = paste("n=",n[j],", Cluster bootstrap", sep=""), xlim=c(0,0.6))
  abline(v=r[2],col="red")
  abline(v=median(m1), col="green")
  
  hist(m2, breaks=30, xlab="Bootstrap Median", main = paste("n=",n[j],", Two-stage bootstrap", sep=""), xlim=c(0,0.6))
  abline(v=r[2],col="red")
  abline(v=median(m2), col="green")
  
  hist(m3, breaks=30, xlab="Bootstrap Median", main = paste("n=",n[j],", Three-stage bootstrap", sep=""), xlim=c(0,0.6))
  abline(v=r[2],col="red")
  abline(v=median(m3), col="green")
  
}
```

```{r, fig.height=10, fig.width=7, eval=FALSE, include=FALSE}
#- Fixed cluster sizes: 15 level-2 units per level-3 unit, 15 observations per level-2 unit
load("data/RankICC/output-ICC3-Wrong-kFix-15-15.RData")
n <- c(100, 200, 500)
# r2 <- c(0, 0.25, 0.55, 0.85, 0.55, 0.85, 0.85, 1)
# r3 <- c(0, 0.20, 0.20, 0.20, 0.50, 0.50, 0.80, 1)
v3s <- c(0, 4, 4, 4, 10, 10, 16, 2)
v2s <- c(0, 1, 7, 13, 1, 7, 1, 0)
v1s <- c(1, 15, 9, 3, 9, 3, 3, 0)
r3 <- v3s / (v3s + v2s + v1s)
r2 <- (v3s + v2s) / (v3s + v2s + v1s)
r3 <- 6 * asin(r3/2)/pi 
r2 <- 6 * asin(r2/2)/pi 
l_coverage <- l_bias <- l_empSE <- l_avgSE <- l_est <- list()
for(i in seq_along(r2)){
  est <- do.call(rbind, lapply(output[[i]], function(x) colMeans(x[,1:2])))
  l_bias[[i]] <- cbind(est[,1] - r2[i], est[,2] - r3[i])
  p <- matrix(NA, ncol=8, nrow = length(n))
  p[,1:4]<- cbind(
    do.call(rbind, lapply(output[[i]], function(x) CI_coverage(r2[i], x[,1], x[,3], fisher=F))),
    do.call(rbind, lapply(output[[i]], function(x) CI_coverage(r2[i], x[,1],  sqrt(rowMeans(x[,3:7]^2)), fisher=F))),
    do.call(rbind, lapply(output[[i]], function(x) CI_coverage(r2[i], x[,1],  rowMeans(x[,3:7]), fisher=F))),
    do.call(rbind, lapply(output[[i]], function(x) CI_coverage(r2[i], x[,1],  sqrt(rowMeans(x[,3:7]^2) + apply(x[,13:17], 1, var)), fisher=F)))
  )
  p[,5:8]<- cbind(
    do.call(rbind, lapply(output[[i]], function(x) CI_coverage(r3[i], x[,2], x[,8], fisher=F))),
    do.call(rbind, lapply(output[[i]], function(x) CI_coverage(r3[i], x[,2],  sqrt(rowMeans(x[,8:12]^2)), fisher=F))),
    do.call(rbind, lapply(output[[i]], function(x) CI_coverage(r3[i], x[,2],  rowMeans(x[,8:12]), fisher=F))),
    do.call(rbind, lapply(output[[i]], function(x) CI_coverage(r3[i], x[,2],  sqrt(rowMeans(x[,8:12]^2) + apply(x[,18:22], 1, var)), fisher=F)))
  )
  
  l_avgSE[[i]] <- do.call(rbind, lapply(output[[i]], function(x) colMeans(x[, c(3,8)])))
  l_est[[i]] <- do.call(rbind, lapply(output[[i]], function(x) colMeans(x[, c(1,2)])))  
  l_empSE[[i]] <- do.call(rbind, lapply(output[[i]], function(x) apply(x[,c(1,2)], 2, sd)))
  
  l_coverage[[i]] <- p * 100
}
r <- paste("(",round(r2,2),",",round(r3,2),")",sep="")
ans <- data.frame(rep(n, length(r2)),
                  rep(r, each=length(n)),
                  do.call(rbind, l_bias),
                  do.call(rbind, l_coverage))
colnames(ans) <- c("n","r",rep("Bias",2), rep(c("One REP", "AVR of VAR", "AVR of SE", "AVR of VAR + VAR of EST"), 2))
ans <- rbind(ans[, c(1:2, 3, 5:8)] %>%
               gather(Type, "Coverage (%)", "One REP":"AVR of VAR + VAR of EST") %>% 
               mutate(param_r = "r2"),
            ans[, c(1:2, 4, 9:12)] %>%
              gather(Type, "Coverage (%)", "One REP":"AVR of VAR + VAR of EST") %>% 
              mutate(param_r = "r3"))
ans$n <- factor(ans$n, levels=sort(n,decreasing = T))
ans$r <- factor(ans$r, levels = c("(0,0)","(0.24,0.19)","(0.53,0.19)","(0.84,0.19)","(0.53,0.48)","(0.84,0.48)","(0.84,0.79)", "(1,1)"))
ans$Type <- factor(ans$Type, levels = c("One REP", "AVR of VAR", "AVR of SE", "AVR of VAR + VAR of EST"))
ans <- ans %>% gather(key, value, c("Bias", "Coverage (%)"))
                
p1 <- ggplot(ans[(ans$key == "Bias")&(ans$param_r=="r2"),], aes(value, n)) + 
  geom_point() + 
  facet_grid(r~param_r + key,labeller = label_wrap_gen(multi_line=FALSE))  + xlab(" ") +
  ylab("Sample size") + 
  scale_x_continuous(limits = c(-0.02,0.02), breaks = c(-0.01,0,0.01),minor_breaks = c(-0.01,0,0.01)) + 
  theme_bw() + theme(strip.text.y = element_blank())

p2 <- ggplot(ans[(ans$key == "Coverage (%)")&(ans$param_r=="r2"),], aes(value, n)) + 
  geom_point(aes(color=Type, shape=Type)) + 
  facet_grid(r~param_r + key,labeller = label_wrap_gen(multi_line=FALSE))  + xlab(" ") + 
  ylab(" ") + scale_x_continuous(limits = c(90,100), breaks = c(92,95,98),minor_breaks = c(92,95,98)) +
  theme_bw() + theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(), strip.text.y = element_blank(), legend.position = "none") 

p3 <- ggplot(ans[(ans$key == "Bias")&(ans$param_r=="r3"),], aes(value, n)) + 
  geom_point() + 
  facet_grid(r~param_r + key,labeller = label_wrap_gen(multi_line=FALSE)) + xlab(" ") +
  ylab(" ") + 
  scale_x_continuous(limits = c(-0.02,0.02), breaks = c(-0.01,0,0.01),minor_breaks = c(-0.01,0,0.01)) + 
  theme_bw() +  theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(), strip.text.y = element_blank(), legend.position = "none") 

p4 <- ggplot(ans[(ans$key == "Coverage (%)")&(ans$param_r=="r3"),], aes(value, n)) + 
  geom_point(aes(color=Type, shape=Type)) + 
  facet_grid(r~param_r + key,labeller = label_wrap_gen(multi_line=FALSE))  + xlab(" ") + 
  ylab(" ") + scale_x_continuous(limits = c(90,100), breaks = c(92,95,98),minor_breaks = c(92,95,98)) +
  theme_bw()+  theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y.right = element_text(angle = 0), legend.position = "bottom") +theme(legend.title = element_text("Type"))
  
ggpubr::ggarrange(p1, p2,p3,p4,ncol=4, widths=c(1.4,1.2,1.2,1.7), common.legend = T)

# ans.est <- data.frame("n"=rep(n, length(r2)),
#                   "r2"=rep(round(r2,2), each=length(n)),
#                   "r3"=rep(round(r3,2), each=length(n)),
#                   do.call(rbind, l_coverage)[,c(1,5)],
#                   do.call(rbind, l_bias),
#                   do.call(rbind, l_avgSE),
#                   do.call(rbind, l_empSE))
# colnames(ans.est) <- c("n","r2","r3","r2 Coverage (%)", "r3 Coverage (%)", "Bias r2", "Bias r3", "est.SE r2", "est.SE r3", "emp.SE r2", "emp.SE r3")
# ans.est[,c("n","r2","Bias r2","r2 Coverage (%)", "est.SE r2", "emp.SE r2","r3","Bias r3", "r3 Coverage (%)", "est.SE r3", "emp.SE r3")] %>% kbl(digits = 4) %>% kable_styling() %>% 
#   collapse_rows(columns = c(2,7), valign = "middle")
```
```{r, fig.height=10, fig.width=7, eval=FALSE, include=FALSE}
# - The sample size (the number of level-3 units) is 200. 
load("data/RankICC/output-ICC3-varCLS-n200.RData")
v3s <- c(0, 4, 4, 4, 10, 10, 16, 2)
v2s <- c(0, 1, 7, 13, 1, 7, 1, 0)
v1s <- c(1, 15, 9, 3, 9, 3, 3, 0)
r3 <- v3s / (v3s + v2s + v1s)
r2 <- (v3s + v2s) / (v3s + v2s + v1s)
r3 <- 6 * asin(r3/2)/pi 
r2 <- 6 * asin(r2/2)/pi 
l_coverage <- l_bias <- list()
l_empSE <- l_estSE <- list()
cll <- c("(2,2)", "(15,2)","(2,15)","(15,15)")
for(i in seq_along(cll)){
  est <- do.call(rbind, lapply(output[[i]], function(x) colMeans(x[,1:2])))
  l_bias[[i]] <- est - cbind(r2, r3)
  l_estSE[[i]] <- do.call(rbind, lapply(output[[i]], function(x) colMeans(x[,3:4])))
  l_empSE[[i]] <- do.call(rbind, lapply(output[[i]], function(x) apply(x[,1:2], 2, sd)))
  p <- matrix(NA, ncol=4, nrow = length(r2))
  for(j in seq_along(r2)){
    estj <- output[[i]][[j]]
    p[j,1:2] <- CI_coverage(r2[j], estj[,1], estj[,3])
    p[j,3:4] <- CI_coverage(r3[j], estj[,2], estj[,4])
  }
  l_coverage[[i]] <- p * 100
}
ans <- data.frame(do.call(rbind, l_bias),do.call(rbind, l_coverage))
colnames(ans) <- c("r2.bias","r3.bias","r2.CI", "r2.fisherCI","r3.CI", "r3.fisherCI")
ans$cll <- rep(cll, each=length(r2))
r <- paste("(",round(r2,2),",",round(r3,2),")",sep="")
ans$r <- rep(r, length(cll))
ans <- rbind(ans %>% select(cll, r, r2.bias, r2.CI, r2.fisherCI) %>% 
        rename(Bias=r2.bias, CI=r2.CI, fisher=r2.fisherCI) %>% 
        gather(type, value,"Bias":"fisher") %>% 
        mutate(param_r = "r2"),
        ans %>% select(cll, r, r3.bias, r3.CI, r3.fisherCI) %>% 
        rename(Bias=r3.bias, CI=r3.CI, fisher=r3.fisherCI) %>% 
        gather(type, value,"Bias":"fisher") %>% 
        mutate(param_r = "r3"))
ans <- ans %>% mutate(key = ifelse(type=="Bias","Bias", "Coverage (%)"))
# ans <- ans %>% mutate(key = ifelse(type=="Bias","Bias", "Coverage (%)")) %>% 
#   filter(r != "(1,1)")
ans$r <- factor(ans$r, levels = c("(0,0)","(0.24,0.19)","(0.53,0.19)","(0.84,0.19)","(0.53,0.48)","(0.84,0.48)","(0.84,0.79)","(1,1)"))
ans$type <- factor(ans$type, levels = c("Bias", "CI", "fisher"))
                
p1 <- ggplot(ans[(ans$key == "Bias")&(ans$param_r=="r2"),] %>% mutate(key="r2 Bias"), aes(value, cll)) + 
  geom_point() + 
  facet_grid(r~key) + xlab(" ") +
  ylab("Cluster size") + 
  scale_x_continuous(limits = c(-0.02,0.02), breaks = c(-0.01,0,0.01),minor_breaks = c(-0.01,0,0.01)) + 
  theme_bw() + theme(strip.text.y = element_blank())

p2 <- ggplot(ans[(ans$key == "Coverage (%)")&(ans$param_r=="r2"),] %>% mutate(key="r2 Coverage (%)"), aes(value, cll, color=type, shape=type)) + 
  geom_point() + 
  facet_grid(r~key) + xlab(" ") + 
  ylab(" ") + scale_color_manual(values=c("black","purple")) +
  scale_shape_manual(values=c(16, 4)) + 
   scale_x_continuous(limits = c(90,100), breaks = c(92,95,98),minor_breaks = c(92,95,98)) +
  theme_bw() + theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(), strip.text.y = element_blank(), legend.position = "none") 

p3 <- ggplot(ans[(ans$key == "Bias")&(ans$param_r=="r3"),] %>% mutate(key="r3 Bias") , aes(value, cll)) + 
  geom_point() + 
  facet_grid(r~key) + xlab(" ") + ylab(" ") + 
  scale_x_continuous(limits = c(-0.02,0.02), breaks = c(-0.01,0,0.01),minor_breaks = c(-0.01,0,0.01)) + 
  theme_bw() + theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y = element_blank()) 

p4 <- ggplot(ans[(ans$key == "Coverage (%)")&(ans$param_r=="r3"),]%>% mutate(key="r3 Coverage (%)"), aes(value, cll, color=type, shape=type)) + 
  geom_point() + 
  facet_grid(r~key) + xlab(" ") + 
  ylab(" ") +  scale_color_manual(values=c("black","purple")) +
  scale_shape_manual(values=c(16, 4)) + 
  scale_x_continuous(limits = c(90,100), breaks = c(92,95,98),minor_breaks = c(92,95,98))+
  theme_bw() +  theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(),strip.text.y.right = element_text(angle = 0), legend.position = "none") 
  
ggpubr::ggarrange(p1, p2,p3,p4,ncol=4, widths=c(1.6,1.2,1.2,1.7))

ans.est <- data.frame(
  "cll" = rep(cll, each = length(r2)),
  "r2" = rep(round(r2,2), length(cll)),
  "r3" = rep(round(r3,2), length(cll)),
  do.call(rbind, l_coverage)[, c(1,3)],
  do.call(rbind, l_bias),
  do.call(rbind, l_estSE),
  do.call(rbind, l_empSE))
colnames(ans.est) <- c("Cluster size","r2","r3","r2 Coverage (%)", "r3 Coverage (%)", "Bias r2", "Bias r3", "est.SE r2", "est.SE r3", "emp.SE r2", "emp.SE r3")
ans.est[,c("Cluster size","r2","Bias r2","r2 Coverage (%)", "est.SE r2", "emp.SE r2","r3","Bias r3", "r3 Coverage (%)", "est.SE r3", "emp.SE r3")] %>% kbl(digits = 4) %>% kable_styling() %>% 
  collapse_rows(columns = 1, valign = "middle")

# ans %>% mutate(type = paste(param_r, type, sep=" ")) %>%
#   filter(grepl('fisher',type,fixed=TRUE) == FALSE) %>% 
#   select(-key,-param_r) %>%
#   spread(key=type, value=value) %>% 
#   rename("r2 Coverage (%)"="r2 CI", "r3 Coverage (%)"="r3 CI", "Cluster size"="cll", "(r2, r3)"="r") %>% 
#   arrange(desc(`Cluster size`), `(r2, r3)`) %>% 
#   kbl(digits = 4) %>%  kable_styling(full_width = F,bootstrap_options = "striped") 
```


#### Unequal cluster sizes

The size of level-3 units uniformly ranges from 2 to 15, the size of level-2 units is 2. 

#### Results of $\gamma_2$

```{r}
load("data/RankICC/output-ICC3-kFix-n1-2-n2-2-15-val3.RData")
load("data/RankICC/output-ICC3-Boot200-n1-2-n2-2-15-val3.RData")
n <- c(25, 50, 100, 200, 500, 1000)
r <- 6 * asin(c(0.55, 0.20)/2)/pi 
pA2 <- pA3 <- matrix(0, ncol = 2, nrow = length(n))
pB2 <- pB3 <- matrix(0, ncol = 4, nrow = length(n))
simest2 <- simest3 <- matrix(0, ncol = 8, nrow = length(n))
for(i in 1:length(n)){
  t <- output[[i]]
  #####gamma2
  pA2[i,] <- c(CI_coverage(r[1], t[,1], t[,2], fisher = F), 
               CI_coverage(r[1], t[,5], t[,6], fisher = F))
  tB <- lapply(outputBoot[[i]], function(x){
      c(sd(x[,1]), sd(x[,3]),
        quantile(x[,1], c(0.025, 0.975)),
        quantile(x[,3], c(0.025, 0.975)))
    })
  tB <- do.call(rbind, tB)
  pB2[i,] <- c(CI_coverage(r[1], t[,1], tB[,1], fisher = F),
               CI_coverage(r[1], t[,5], tB[,2], fisher = F),
               mean((tB[,3]<=r[1])&(r[1]<=tB[,4])),
               mean((tB[,5]<=r[1])&(r[1]<=tB[,6])))

  simest2[i, ] <- c((mean(t[,1])-r[1])/r[1]*100, sd(t[,1]),
                   mean(t[,2]), mean(tB[,1]),
                   (mean(t[,5])-r[1])/r[1]*100, sd(t[,5]),
                   mean(t[,6]), mean(tB[,2]))

  ######gamma3
  pA3[i,] <- c(CI_coverage(r[2], t[,3], t[,4], fisher = F),
               CI_coverage(r[2], t[,7], t[,8], fisher = F))
  tB <- lapply(outputBoot[[i]], function(x){
      c(sd(x[,2]), sd(x[,4]),
        quantile(x[,2], c(0.025, 0.975)),
        quantile(x[,4], c(0.025, 0.975)))
    })
  tB <- do.call(rbind, tB)
  pB3[i,] <- c(CI_coverage(r[2], t[,3], tB[,1], fisher = F),
               CI_coverage(r[2], t[,7], tB[,2], fisher = F),
              mean((tB[,3]<=r[2])&(r[2]<=tB[,4])),
              mean((tB[,5]<=r[2])&(r[2]<=tB[,6])))

  simest3[i, ] <- c((mean(t[,3])-r[2])/r[2]*100, sd(t[,3]),
                   mean(t[,4]), mean(tB[,1]),
                   (mean(t[,7])-r[2])/r[2]*100, sd(t[,7]),
                   mean(t[,8]), mean(tB[,2]))

}
df2 <- cbind(n, simest2[,1], pA2[,1], pB2[,c(1,3)], simest2[,5], pA2[,2], pB2[,c(2,4)])

colnames(df2) <- c("Size", rep(c("Bias (%)", "Asymptotic SE", "Cluster Bootstrap SE", "Cluster Bootstrap Percentiles"),2))
df2 %>%
  kbl(digits = 3, align = "c", full.width = F, caption = "Coverage probability") %>%
  kable_styling(full_width = F) %>% 
  add_header_above(c(" "=1, "Equal level-3 units"=4,"Equal level-2/1 units"=4))

```


#### Results of $\gamma_3$


```{r}
df3 <- cbind(n, simest3[,1], pA3[,1], pB3[,c(1,3)], simest3[,5], pA3[,2], pB3[,c(2,4)])

colnames(df3) <- c("Size", rep(c("Bias (%)","Asymptotic SE", "Cluster Bootstrap SE", "Cluster Bootstrap Percentiles"),2))
df3 %>%
  kbl(digits = 3, align = "c", full.width = F, caption = "Coverage probability") %>%
  kable_styling(full_width = F) %>% 
  add_header_above(c(" "=1, "Equal level-3 units"=4,"Equal level-2/1 units"=4))
```

